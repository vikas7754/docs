{"name":"sap-aws","title":"SAP Amazon Web Services compliance profile","maintainer":"SAP Multi-Cloud Security","copyright":"SAP Multi-Cloud Security","copyright_email":"DL_5FA91E5D1DFE00027E55AD91@global.corp.sap","license":"Apache-2.0","summary":"SAP Amazon Web Services compliance profile","version":"4.21.0","supports":[{"platform":"aws"}],"depends":[{"name":"inspec-aws","url":"https://github.com/inspec/inspec-aws/archive/v1.83.44.tar.gz","status":"loaded"}],"inputs":[],"controls":[{"title":"5.2 - AWS EMR cluster should be enabled with local disk encryption","desc":"This control enforces AWS EMR clusters to be enabled with local disk encryption. Applications using the local file system on each slave instance for intermediate data throughout workloads, where data could be spilled to disk when it overflows memory. With Local disk encryption in place, data at rest can be protected.","descriptions":{"default":"This control enforces AWS EMR clusters to be enabled with local disk encryption. Applications using the local file system on each slave instance for intermediate data throughout workloads, where data could be spilled to disk when it overflows memory. With Local disk encryption in place, data at rest can be protected."},"impact":0.5,"refs":[],"tags":{"sgs_wiki_url":"https://wiki.wdf.sap.corp/wiki/x/-0JAc","terraform_remediation":"  resource \"aws_emr_cluster\" \"example_cluster\" {\n    ...\n    security_configuration = aws_emr_security_configuration.emr_security_configuration\n    ...\n  }\n\n  resource \"aws_kms_key\" \"emr_kms_key\" {\n    description             = <key description>\n    deletion_window_in_days = <key deletion window>\n  }\n\n  resource \"aws_emr_security_configuration\" \"emr_security_configuration\" {\n  ...\n    configuration = <<CONFIG\n  {\n    \"EncryptionConfiguration\": {\n        \"LocalDiskEncryptionConfiguration\": {\n          \"EncryptionKeyProviderType\": \"AwsKms\",\n          \"AwsKmsKey\": \"${aws_kms_key.emr_kms_key.arn}\",\n          \"EnableEbsEncryption\": true\n        }\n      }\n    }\n  }\n  CONFIG\n  }\n","tested_tf_version":"1.0.11","remediation_steps":"  1.  Login to the AWS Console.\n  2.  Navigate to EMR dashboard (or search for EMR in the search bar).\n  3.  Click on Security configurations > Click Create.\n  4.  On the Create security configuration window, please do the following:\n\n        a.  In Name box, enter a name for the new EMR security configuration.\n\n        b.  Under Local disk encryption, check the box Enable at-rest encryption for local disks.\n\n        c.  Select the appropriate key provider type from the key provider type dropdown.\n\n        d.  Click Create.\n  5.  On the left menu of EMR dashboard, click Clusters.\n  6.  Click on the EMR cluster mentioned in the alert > Click on the Clone button.\n  7.  In the Cloning popup, choose Yes > Click Clone.\n  8.  On the Create Cluster page, under the Security Options section, click on security configuration.\n  9.  From the  Security configuration drop down, select the name of the security configuration created at step #4 > Click Create Cluster.\n  10. Once the new cluster is set up > Confirm that it is working > terminate the original cluster.\n  11. On the left menu of EMR dashboard, click clusters > Select the source cluster which was mentioned in the alert.\n  12. Click on the Terminate button from the top menu > On the Terminate clusters pop-up, click Terminate.\n"},"code":"control '5_02_emr_cluster_local_disk_encryption' do\r\n  title '5.2 - AWS EMR cluster should be enabled with local disk encryption'\r\n  impact 0.5\r\n  desc 'This control enforces AWS EMR clusters to be enabled with local disk encryption. Applications using the local file system on each slave instance for intermediate data throughout workloads, where data could be spilled to disk when it overflows memory. With Local disk encryption in place, data at rest can be protected.'\r\n  tag sgs_wiki_url: 'https://wiki.wdf.sap.corp/wiki/x/-0JAc'\r\n  tag terraform_remediation: <<-EOF\r\n  resource \"aws_emr_cluster\" \"example_cluster\" {\r\n    ...\r\n    security_configuration = aws_emr_security_configuration.emr_security_configuration\r\n    ...\r\n  }\r\n\r\n  resource \"aws_kms_key\" \"emr_kms_key\" {\r\n    description             = <key description>\r\n    deletion_window_in_days = <key deletion window>\r\n  }\r\n\r\n  resource \"aws_emr_security_configuration\" \"emr_security_configuration\" {\r\n  ...\r\n    configuration = <<CONFIG\r\n  {\r\n    \"EncryptionConfiguration\": {\r\n        \"LocalDiskEncryptionConfiguration\": {\r\n          \"EncryptionKeyProviderType\": \"AwsKms\",\r\n          \"AwsKmsKey\": \"${aws_kms_key.emr_kms_key.arn}\",\r\n          \"EnableEbsEncryption\": true\r\n        }\r\n      }\r\n    }\r\n  }\r\n  CONFIG\r\n  }\r\n  EOF\r\n  tag tested_tf_version: '1.0.11'\r\n\r\n  tag remediation_steps: <<-EOF\r\n  1.  Login to the AWS Console.\r\n  2.  Navigate to EMR dashboard (or search for EMR in the search bar).\r\n  3.  Click on Security configurations > Click Create.\r\n  4.  On the Create security configuration window, please do the following:\r\n\r\n        a.  In Name box, enter a name for the new EMR security configuration.\r\n\r\n        b.  Under Local disk encryption, check the box Enable at-rest encryption for local disks.\r\n\r\n        c.  Select the appropriate key provider type from the key provider type dropdown.\r\n\r\n        d.  Click Create.\r\n  5.  On the left menu of EMR dashboard, click Clusters.\r\n  6.  Click on the EMR cluster mentioned in the alert > Click on the Clone button.\r\n  7.  In the Cloning popup, choose Yes > Click Clone.\r\n  8.  On the Create Cluster page, under the Security Options section, click on security configuration.\r\n  9.  From the  Security configuration drop down, select the name of the security configuration created at step #4 > Click Create Cluster.\r\n  10. Once the new cluster is set up > Confirm that it is working > terminate the original cluster.\r\n  11. On the left menu of EMR dashboard, click clusters > Select the source cluster which was mentioned in the alert.\r\n  12. Click on the Terminate button from the top menu > On the Terminate clusters pop-up, click Terminate.\r\n  EOF\r\n\r\n  aws_regions.region_names.each do |region_name|\r\n    aws_emr_clusters(aws_region: region_name).where(status_state: /RUNNING|WAITING|BOOTSTRAPPING|STARTING/).cluster_ids.each do |emr_cluster_id|\r\n      emr_cluster = aws_emr_cluster(aws_region: region_name, cluster_id: emr_cluster_id)\r\n      security_configuration = emr_cluster.security_configuration_name\r\n      describe emr_cluster do\r\n        its('security_configuration_name') { should_not be_nil }\r\n      end\r\n\r\n      next unless emr_cluster.security_configuration_name.nil? == false\r\n\r\n      describe aws_emr_security_configuration(security_configuration_name: security_configuration) do\r\n        its('local_disk_encryption') { should eq true }\r\n      end\r\n    end\r\n  end\r\nend\r\n","source_location":{"ref":"./controls/aws_elastic/5_02_aws_elastic.rb","line":1},"id":"5_02_emr_cluster_local_disk_encryption"},{"title":"5.2 - AWS EMR cluster should be enabled with data encryption at rest","desc":"This control enforces AWS EMR clusters data encryption at rest to be enabled. Encryption of data at rest is required to prevent unauthorized users from accessing the sensitive information available on your EMR clusters and associated storage systems.","descriptions":{"default":"This control enforces AWS EMR clusters data encryption at rest to be enabled. Encryption of data at rest is required to prevent unauthorized users from accessing the sensitive information available on your EMR clusters and associated storage systems."},"impact":0.5,"refs":[],"tags":{"sgs_wiki_url":"https://wiki.wdf.sap.corp/wiki/x/-0JAc","terraform_remediation":"  resource \"aws_emr_cluster\" \"example_cluster\" {\n    ...\n    security_configuration = aws_emr_security_configuration.emr_security_configuration\n    ...\n  }\n\n  resource \"aws_kms_key\" \"emr_kms_key\" {\n    description             = <key description>\n    deletion_window_in_days = <key deletion window>\n  }\n\n  resource \"aws_emr_security_configuration\" \"emr_security_configuration\" {\n  ...\n    configuration = <<CONFIG\n    {\n      \"EncryptionConfiguration\": {\n        \"EnableAtRestEncryption\": true\n      }\n    }\n  CONFIG\n  }\n","tested_tf_version":"1.0.11","remediation_steps":"  To enable at rest encryption for your current AWS EMR clusters, you must create an EMR security configuration then re-create the current clusters with the new security configuration. To fix the alert(s) for this control, please implement the following steps:\n\n  1.\tLogin to the AWS Management Console.\n  2.\tNavigate to EMR dashboard (or search for EMR in the search bar).\n  3.\tIn the navigation panel, click Security configurations > Click Create.\n  4.\tOn the Create security configuration page, please do the following steps:\n\n        a.  In Name box, enter a unique name for the new EMR security configuration.\n\n        b.  Select At-rest encryption checkbox to enable at-rest encryption for data stored within the cluster file system. To configure data-at-rest encryption, perform the following:\n            * Under S3 encryption, pick a value from Encryption mode dropdown list. To select the right encryption mode to encrypt your EMR data, refer to the official AWS documentation page.\n            * Under Local disk encryption, from Key provider type dropdown list > Choose the default AWS KMS key or custom key provider.\n\n        c.  Click Create.\n\n  5.\tIn the navigation panel, under Amazon EMR, click Clusters to access your AWS EMR clusters.\n  6.\tSelect the EMR cluster that you want to reconfigure > Click on the Clone button from the dashboard top menu.\n  7.\tInside the Cloning dialog box > Choose Yes to include the steps from the original cluster into the cloned (new) cluster > Click Clone.\n  8.\tOn the Create Cluster page, in the Security Options section > Click Authentication and encryption.\n  9.\tSelect the name of the security configuration created at step #4 from the Security configuration dropdown list > Click Create Cluster to provision your new Amazon EMR cluster.\n  10.\tOnce you have moved the existing data and verified that your new EMR cluster is working with the new security configuration > Terminate the original cluster to stop incurring charges for it. To terminate the unencrypted, original AWS EMR cluster, please do the following steps:\n\n        a.  Go back to the navigation panel and under Amazon EMR > Choose Cluster list.\n\n        b.  Select the AWS EMR cluster that you want to shut down > Click on the Terminate button from the dashboard top menu.\n\n        c.  In the Terminate clusters confirmation box, review the original cluster details > Click Terminate.\n"},"code":"control '5_02_emr_cluster_encryption_at_rest' do\r\n  title '5.2 - AWS EMR cluster should be enabled with data encryption at rest'\r\n  impact 0.5\r\n  desc 'This control enforces AWS EMR clusters data encryption at rest to be enabled. Encryption of data at rest is required to prevent unauthorized users from accessing the sensitive information available on your EMR clusters and associated storage systems.'\r\n  tag sgs_wiki_url: 'https://wiki.wdf.sap.corp/wiki/x/-0JAc'\r\n  tag terraform_remediation: <<-EOF\r\n  resource \"aws_emr_cluster\" \"example_cluster\" {\r\n    ...\r\n    security_configuration = aws_emr_security_configuration.emr_security_configuration\r\n    ...\r\n  }\r\n\r\n  resource \"aws_kms_key\" \"emr_kms_key\" {\r\n    description             = <key description>\r\n    deletion_window_in_days = <key deletion window>\r\n  }\r\n\r\n  resource \"aws_emr_security_configuration\" \"emr_security_configuration\" {\r\n  ...\r\n    configuration = <<CONFIG\r\n    {\r\n      \"EncryptionConfiguration\": {\r\n        \"EnableAtRestEncryption\": true\r\n      }\r\n    }\r\n  CONFIG\r\n  }\r\n  EOF\r\n  tag tested_tf_version: '1.0.11'\r\n\r\n  tag remediation_steps: <<-EOF\r\n  To enable at rest encryption for your current AWS EMR clusters, you must create an EMR security configuration then re-create the current clusters with the new security configuration. To fix the alert(s) for this control, please implement the following steps:\r\n\r\n  1.\tLogin to the AWS Management Console.\r\n  2.\tNavigate to EMR dashboard (or search for EMR in the search bar).\r\n  3.\tIn the navigation panel, click Security configurations > Click Create.\r\n  4.\tOn the Create security configuration page, please do the following steps:\r\n\r\n        a.  In Name box, enter a unique name for the new EMR security configuration.\r\n\r\n        b.  Select At-rest encryption checkbox to enable at-rest encryption for data stored within the cluster file system. To configure data-at-rest encryption, perform the following:\r\n            * Under S3 encryption, pick a value from Encryption mode dropdown list. To select the right encryption mode to encrypt your EMR data, refer to the official AWS documentation page.\r\n            * Under Local disk encryption, from Key provider type dropdown list > Choose the default AWS KMS key or custom key provider.\r\n\r\n        c.  Click Create.\r\n\r\n  5.\tIn the navigation panel, under Amazon EMR, click Clusters to access your AWS EMR clusters.\r\n  6.\tSelect the EMR cluster that you want to reconfigure > Click on the Clone button from the dashboard top menu.\r\n  7.\tInside the Cloning dialog box > Choose Yes to include the steps from the original cluster into the cloned (new) cluster > Click Clone.\r\n  8.\tOn the Create Cluster page, in the Security Options section > Click Authentication and encryption.\r\n  9.\tSelect the name of the security configuration created at step #4 from the Security configuration dropdown list > Click Create Cluster to provision your new Amazon EMR cluster.\r\n  10.\tOnce you have moved the existing data and verified that your new EMR cluster is working with the new security configuration > Terminate the original cluster to stop incurring charges for it. To terminate the unencrypted, original AWS EMR cluster, please do the following steps:\r\n\r\n        a.  Go back to the navigation panel and under Amazon EMR > Choose Cluster list.\r\n\r\n        b.  Select the AWS EMR cluster that you want to shut down > Click on the Terminate button from the dashboard top menu.\r\n\r\n        c.  In the Terminate clusters confirmation box, review the original cluster details > Click Terminate.\r\n  EOF\r\n\r\n  aws_regions.region_names.each do |region_name|\r\n    aws_emr_clusters(aws_region: region_name).where(status_state: /RUNNING|WAITING|BOOTSTRAPPING|STARTING/).cluster_ids.each do |emr_cluster_id|\r\n      emr_cluster = aws_emr_cluster(aws_region: region_name, cluster_id: emr_cluster_id)\r\n      security_configuration = emr_cluster.security_configuration_name\r\n      describe emr_cluster do\r\n        its('security_configuration_name') { should_not be_nil }\r\n      end\r\n\r\n      next unless emr_cluster.security_configuration_name.nil? == false\r\n\r\n      describe aws_emr_security_configuration(security_configuration_name: security_configuration) do\r\n        its('encryption_at_rest') { should eq true }\r\n      end\r\n    end\r\n  end\r\nend\r\n","source_location":{"ref":"./controls/aws_elastic/5_02_aws_elastic.rb","line":76},"id":"5_02_emr_cluster_encryption_at_rest"},{"title":"5.2 - AWS EMR cluster should be enabled with data encryption in transit","desc":"This control enforces AWS EMR clusters to be enabled with data encryption in transit. It is highly recommended to implement in-transit encryption in order to protect data from unauthorized access as it travels through the network, between clients and storage server. Enabling data encryption in-transit helps prevent unauthorized users from reading sensitive data between your EMR clusters and their associated storage systems.","descriptions":{"default":"This control enforces AWS EMR clusters to be enabled with data encryption in transit. It is highly recommended to implement in-transit encryption in order to protect data from unauthorized access as it travels through the network, between clients and storage server. Enabling data encryption in-transit helps prevent unauthorized users from reading sensitive data between your EMR clusters and their associated storage systems."},"impact":0.5,"refs":[],"tags":{"sgs_wiki_url":"https://wiki.wdf.sap.corp/wiki/x/-0JAc","terraform_remediation":"  resource \"aws_emr_cluster\" \"example_cluster\" {\n    ...\n    security_configuration = aws_emr_security_configuration.emr_security_configuration\n    ...\n  }\n\n  resource \"aws_kms_key\" \"emr_kms_key\" {\n    description             = <key description>\n    deletion_window_in_days = <key deletion window>\n  }\n\n  resource \"aws_emr_security_configuration\" \"emr_security_configuration\" {\n  ...\n    configuration = <<CONFIG\n    {\n      \"EncryptionConfiguration\": {\n        \"EnableInTransitEncryption\": false\n      }\n    }\n  CONFIG\n  }\n","tested_tf_version":"1.0.11","remediation_steps":"\n  To enable in-transit encryption for your current AWS EMR clusters, you must create an EMR security configuration then re-create the current clusters with the new security configuration. To fix the alert(s) for this control, please implement the following steps:\n\n  1.  Login to the AWS Management Console.\n  2.\tNavigate to EMR dashboard (or search for EMR in the search bar).\n  3.\tIn the navigation panel, click Security configurations > Click Create.\n  4.\tOn the Create security configuration page, please do the following steps:\n\n        a.  In Name box, enter a unique name for the new EMR security configuration.\n\n        b.\tSelect In-transit encryption checkbox to enable the open-source TLS encryption features for EMR in-transit data. To configure in-transit encryption, perform the following:\n\n        c.\tUnder TLS certificate provider, in Certificate provider type dropdown list, choose PEM. Two items should be available in your zip file: a PrivateKey.pem file and a CertificateChain.pem file (refer to Providing Certificates for In-Transit Data Encryption with Amazon EMR Encryption page for more details). In the S3 object box, enter the location of the zip file that contains your certificate PEM files. If you choose Custom from the Certificate provider type dropdown list > specify a custom certificate provider and specify the AWS S3 location of the custom certificate-provider file. In Certificate provider class box > type the full name of a class declared in your EMR application that implements the TLSArtifactsProvider interface.\n\n        d.\tClick Create.\n  5.\tIn the navigation panel, under Amazon EMR > Click Clusters to access your AWS EMR clusters.\n  6.\tSelect the EMR cluster that you want to reconfigure > click on the Clone button from the dashboard top menu.\n  7.\tInside the Cloning dialog box > Choose Yes to include the steps from the original cluster into the cloned (new) cluster > Click Clone.\n  8.\tOn the Create Cluster page, in the Security Options section > Click Authentication and encryption.\n  9.\tSelect the name of the security configuration created at step #4 from the Security configuration dropdown list > Click Create Cluster to provision your new Amazon EMR cluster.\n  10.\tOnce you have moved the existing data and verified that your new EMR cluster is working with the new security configuration > Terminate the original cluster to stop incurring charges for it. To terminate the unencrypted, original AWS EMR cluster, please do the following steps:\n\n          a.  Go back to the navigation panel and under Amazon EMR > Choose Cluster list.\n\n          b.\tSelect the AWS EMR cluster that you want to shut down > Click on the Terminate button from the dashboard top menu.\n\n          c.\tIn the Terminate clusters confirmation box, review the original cluster details > Click Terminate.\n"},"code":"control '5_02_emr_cluster_encryption_in_transit' do\r\n  title '5.2 - AWS EMR cluster should be enabled with data encryption in transit'\r\n  impact 0.5\r\n  desc 'This control enforces AWS EMR clusters to be enabled with data encryption in transit. It is highly recommended to implement in-transit encryption in order to protect data from unauthorized access as it travels through the network, between clients and storage server. Enabling data encryption in-transit helps prevent unauthorized users from reading sensitive data between your EMR clusters and their associated storage systems.'\r\n  tag sgs_wiki_url: 'https://wiki.wdf.sap.corp/wiki/x/-0JAc'\r\n  tag terraform_remediation: <<-EOF\r\n  resource \"aws_emr_cluster\" \"example_cluster\" {\r\n    ...\r\n    security_configuration = aws_emr_security_configuration.emr_security_configuration\r\n    ...\r\n  }\r\n\r\n  resource \"aws_kms_key\" \"emr_kms_key\" {\r\n    description             = <key description>\r\n    deletion_window_in_days = <key deletion window>\r\n  }\r\n\r\n  resource \"aws_emr_security_configuration\" \"emr_security_configuration\" {\r\n  ...\r\n    configuration = <<CONFIG\r\n    {\r\n      \"EncryptionConfiguration\": {\r\n        \"EnableInTransitEncryption\": false\r\n      }\r\n    }\r\n  CONFIG\r\n  }\r\n  EOF\r\n  tag tested_tf_version: '1.0.11'\r\n\r\n  tag remediation_steps: <<-EOF\r\n\r\n  To enable in-transit encryption for your current AWS EMR clusters, you must create an EMR security configuration then re-create the current clusters with the new security configuration. To fix the alert(s) for this control, please implement the following steps:\r\n\r\n  1.  Login to the AWS Management Console.\r\n  2.\tNavigate to EMR dashboard (or search for EMR in the search bar).\r\n  3.\tIn the navigation panel, click Security configurations > Click Create.\r\n  4.\tOn the Create security configuration page, please do the following steps:\r\n\r\n        a.  In Name box, enter a unique name for the new EMR security configuration.\r\n\r\n        b.\tSelect In-transit encryption checkbox to enable the open-source TLS encryption features for EMR in-transit data. To configure in-transit encryption, perform the following:\r\n\r\n        c.\tUnder TLS certificate provider, in Certificate provider type dropdown list, choose PEM. Two items should be available in your zip file: a PrivateKey.pem file and a CertificateChain.pem file (refer to Providing Certificates for In-Transit Data Encryption with Amazon EMR Encryption page for more details). In the S3 object box, enter the location of the zip file that contains your certificate PEM files. If you choose Custom from the Certificate provider type dropdown list > specify a custom certificate provider and specify the AWS S3 location of the custom certificate-provider file. In Certificate provider class box > type the full name of a class declared in your EMR application that implements the TLSArtifactsProvider interface.\r\n\r\n        d.\tClick Create.\r\n  5.\tIn the navigation panel, under Amazon EMR > Click Clusters to access your AWS EMR clusters.\r\n  6.\tSelect the EMR cluster that you want to reconfigure > click on the Clone button from the dashboard top menu.\r\n  7.\tInside the Cloning dialog box > Choose Yes to include the steps from the original cluster into the cloned (new) cluster > Click Clone.\r\n  8.\tOn the Create Cluster page, in the Security Options section > Click Authentication and encryption.\r\n  9.\tSelect the name of the security configuration created at step #4 from the Security configuration dropdown list > Click Create Cluster to provision your new Amazon EMR cluster.\r\n  10.\tOnce you have moved the existing data and verified that your new EMR cluster is working with the new security configuration > Terminate the original cluster to stop incurring charges for it. To terminate the unencrypted, original AWS EMR cluster, please do the following steps:\r\n\r\n          a.  Go back to the navigation panel and under Amazon EMR > Choose Cluster list.\r\n\r\n          b.\tSelect the AWS EMR cluster that you want to shut down > Click on the Terminate button from the dashboard top menu.\r\n\r\n          c.\tIn the Terminate clusters confirmation box, review the original cluster details > Click Terminate.\r\n  EOF\r\n\r\n  aws_regions.region_names.each do |region_name|\r\n    aws_emr_clusters(aws_region: region_name).where(status_state: /RUNNING|WAITING|BOOTSTRAPPING|STARTING/).cluster_ids.each do |emr_cluster_id|\r\n      emr_cluster = aws_emr_cluster(aws_region: region_name, cluster_id: emr_cluster_id)\r\n      security_configuration = emr_cluster.security_configuration_name\r\n      describe emr_cluster do\r\n        its('security_configuration_name') { should_not be_nil }\r\n      end\r\n\r\n      next unless emr_cluster.security_configuration_name.nil? == false\r\n\r\n      describe aws_emr_security_configuration(security_configuration_name: security_configuration) do\r\n        its('encryption_in_transit') { should eq true }\r\n      end\r\n    end\r\n  end\r\nend\r\n","source_location":{"ref":"./controls/aws_elastic/5_02_aws_elastic.rb","line":154},"id":"5_02_emr_cluster_encryption_in_transit"},{"title":"8.1 - AWS ElastiCache Redis cluster should have encryption for data at rest enabled","desc":"This policy identifies ElastiCache Redis clusters which have encryption\n  for data at rest(at-rest) disabled. It is highly recommended to\n  implement at-rest encryption in order to prevent unauthorized users from\n  reading sensitive data saved to persistent media available on your Redis clusters\n  and their associated cache storage systems.","descriptions":{"default":"This policy identifies ElastiCache Redis clusters which have encryption\n  for data at rest(at-rest) disabled. It is highly recommended to\n  implement at-rest encryption in order to prevent unauthorized users from\n  reading sensitive data saved to persistent media available on your Redis clusters\n  and their associated cache storage systems."},"impact":0.5,"refs":[],"tags":{"sgs_wiki_url":"https://wiki.wdf.sap.corp/wiki/x/-0JAc","terraform_remediation":"  resource \"aws_elasticache_replication_group\" \"example_rg\" {\n    ...\n    at_rest_encryption_enabled    = true\n    ...\n  }\n","tested_tf_version":"1.0.11","remediation_steps":"  AWS ElastiCache Redis cluster at-rest encryption can be set only at the time of the creation of the cluster. In order to resolve the alert for this control, you will need to create a new cluster with at-rest encryption, then migrate all required ElastiCache Redis cluster data from the reported ElastiCache Redis cluster that caused the alert to the new cluster and delete old ElastiCache Redis cluster.\n\n  To create new ElastiCache Redis cluster with In-transit encryption set, please do the following:\n  1.  Sign into the AWS console > Select the specific region from region drop down on the top right corner, that caused the alert.\n  2.  Go to the ElastiCache Dashboard (or search for ElastiCache Dashboard in the search bar).\n  3.  In the left-hand menu, Click on Redis > Click on Create button.\n  4.  Select or enter the following information:\n\n        a.  Select 'Redis' cache engine type.\n        b.  Enter a name for the new cache cluster.\n        c.  Select Redis engine version from Engine version compatibility dropdown list.\n        d.  Click on Advanced Redis settings to expand the cluster advanced settings panel.\n        e.  Select Encryption at-rest checkbox to enable encryption along with other necessary options.\n  5.  Click on Create button to start your ElastiCache Redis cluster.\n\n  To delete reported ElastiCache Redis cluster, please do the following:\n  1.  Sign into the AWS console > Select the specific region from region drop down on the top right corner, that caused the alert.\n  2.  Go to the ElastiCache Dashboard (or search for ElastiCache Dashboard in the search bar).\n  3.  In the left-hand menu, click on Redis.\n  4.  Select the Redis cluster that caused the alert.\n  5.  Click on Delete button.\n  6.  In the Delete Cluster dialog box, if you'd like to backup for your cluster, select Yes from the Create final backup dropdown menu, enter a name for the cluster backup > click on Delete.\n"},"code":"control '8_01_elasticache_cluster_at_rest_encryption' do\r\n  title '8.1 - AWS ElastiCache Redis cluster should have encryption for data at rest enabled'\r\n  impact 0.5\r\n  desc 'This policy identifies ElastiCache Redis clusters which have encryption\r\n  for data at rest(at-rest) disabled. It is highly recommended to\r\n  implement at-rest encryption in order to prevent unauthorized users from\r\n  reading sensitive data saved to persistent media available on your Redis clusters\r\n  and their associated cache storage systems.'\r\n  tag sgs_wiki_url: 'https://wiki.wdf.sap.corp/wiki/x/-0JAc'\r\n  tag terraform_remediation: <<-EOF\r\n  resource \"aws_elasticache_replication_group\" \"example_rg\" {\r\n    ...\r\n    at_rest_encryption_enabled    = true\r\n    ...\r\n  }\r\n  EOF\r\n  tag tested_tf_version: '1.0.11'\r\n\r\n  tag remediation_steps: <<-EOF\r\n  AWS ElastiCache Redis cluster at-rest encryption can be set only at the time of the creation of the cluster. In order to resolve the alert for this control, you will need to create a new cluster with at-rest encryption, then migrate all required ElastiCache Redis cluster data from the reported ElastiCache Redis cluster that caused the alert to the new cluster and delete old ElastiCache Redis cluster.\r\n\r\n  To create new ElastiCache Redis cluster with In-transit encryption set, please do the following:\r\n  1.  Sign into the AWS console > Select the specific region from region drop down on the top right corner, that caused the alert.\r\n  2.  Go to the ElastiCache Dashboard (or search for ElastiCache Dashboard in the search bar).\r\n  3.  In the left-hand menu, Click on Redis > Click on Create button.\r\n  4.  Select or enter the following information:\r\n\r\n        a.  Select 'Redis' cache engine type.\r\n        b.  Enter a name for the new cache cluster.\r\n        c.  Select Redis engine version from Engine version compatibility dropdown list.\r\n        d.  Click on Advanced Redis settings to expand the cluster advanced settings panel.\r\n        e.  Select Encryption at-rest checkbox to enable encryption along with other necessary options.\r\n  5.  Click on Create button to start your ElastiCache Redis cluster.\r\n\r\n  To delete reported ElastiCache Redis cluster, please do the following:\r\n  1.  Sign into the AWS console > Select the specific region from region drop down on the top right corner, that caused the alert.\r\n  2.  Go to the ElastiCache Dashboard (or search for ElastiCache Dashboard in the search bar).\r\n  3.  In the left-hand menu, click on Redis.\r\n  4.  Select the Redis cluster that caused the alert.\r\n  5.  Click on Delete button.\r\n  6.  In the Delete Cluster dialog box, if you'd like to backup for your cluster, select Yes from the Create final backup dropdown menu, enter a name for the cluster backup > click on Delete.\r\n  EOF\r\n\r\n  aws_regions.region_names.each do |region_name|\r\n    aws_elasticache_replication_groups(aws_region: region_name).ids.each do |replication_group_id|\r\n      describe aws_elasticache_replication_group(aws_region: region_name, replication_group_id: replication_group_id) do\r\n        it { should be_encrypted_at_rest }\r\n      end\r\n    end\r\n  end\r\nend\r\n","source_location":{"ref":"./controls/aws_elastic/8_01_aws_elastic.rb","line":1},"id":"8_01_elasticache_cluster_at_rest_encryption"},{"title":"8.1 - AWS ElastiCache Redis cluster should have in-transit encryption enabled","desc":"This policy identifies ElastiCache Redis clusters which have in-transit encryption disabled.\n  It is highly recommended to implement in-transit encryption in order to protect data from\n  unauthorized access as it travels through the network, between clients and cache servers.\n  Enabling data encryption in-transit helps prevent unauthorized users from reading\n  sensitive data between your Redis clusters and their associated cache storage systems.","descriptions":{"default":"This policy identifies ElastiCache Redis clusters which have in-transit encryption disabled.\n  It is highly recommended to implement in-transit encryption in order to protect data from\n  unauthorized access as it travels through the network, between clients and cache servers.\n  Enabling data encryption in-transit helps prevent unauthorized users from reading\n  sensitive data between your Redis clusters and their associated cache storage systems."},"impact":0.5,"refs":[],"tags":{"sgs_wiki_url":"https://wiki.wdf.sap.corp/wiki/x/-0JAc","terraform_remediation":"  resource \"aws_elasticache_replication_group\" \"example_rg\" {\n    ...\n    transit_encryption_enabled    = true\n    ...\n  }\n","tested_tf_version":"1.0.11","remediation_steps":"  AWS ElastiCache Redis cluster in-transit encryption can be set when creating the cluster. In order to resolve the alert for this control, you will need to create a new cluster with in-transit encryption enabled, then migrate all required ElastiCache Redis cluster data from the ElastiCache Redis cluster that caused the alert to the new cluster and delete old ElastiCache Redis cluster.\n\n  To create new ElastiCache Redis cluster with In-transit encryption set, please do the following:\n  1. Sign into the AWS console > Select the specific region from region drop down on the top right corner, that caused the alert.\n  2. Go to the ElastiCache Dashboard (or search for ElastiCache Dashboard in the search bar).\n  3. In the left-hand menu, Click on Redis > Click on Create button.\n  4. Select or enter the following information:\n\n      a.  Select 'Redis' cache engine type.\n      b.  Enter a name for the new cache cluster.\n      c.  Select Redis engine version from Engine version compatibility dropdown list.\n      d.  Click on Advanced Redis settings to expand the cluster advanced settings panel.\n      e.  Select Encryption in-transit checkbox to enable encryption along with other necessary options\n  5. Click on Create button to start your ElastiCache Redis cluster.\n\n  To delete reported ElastiCache Redis cluster, please do the following:\n  1. Sign into the AWS console > Select the specific region from region drop down on the top right corner, that caused the alert.\n  2. Go to the ElastiCache Dashboard (or search for ElastiCache Dashboard in the search bar).\n  3. In the left-hand menu, Click on Redis.\n  4. Select original Redis cluster.\n  5. Click on Delete button.\n  6. In the Delete Cluster dialog box, if you'd like to backup for your cluster, select Yes from the Create final backup dropdown menu, enter a name for the cluster backup > click on Delete.\n"},"code":"control '8_01_elasticache_cluster_in_transit_encryption' do\r\n  title '8.1 - AWS ElastiCache Redis cluster should have in-transit encryption enabled'\r\n  impact 0.5\r\n  desc 'This policy identifies ElastiCache Redis clusters which have in-transit encryption disabled.\r\n  It is highly recommended to implement in-transit encryption in order to protect data from\r\n  unauthorized access as it travels through the network, between clients and cache servers.\r\n  Enabling data encryption in-transit helps prevent unauthorized users from reading\r\n  sensitive data between your Redis clusters and their associated cache storage systems.'\r\n  tag sgs_wiki_url: 'https://wiki.wdf.sap.corp/wiki/x/-0JAc'\r\n  tag terraform_remediation: <<-EOF\r\n  resource \"aws_elasticache_replication_group\" \"example_rg\" {\r\n    ...\r\n    transit_encryption_enabled    = true\r\n    ...\r\n  }\r\n  EOF\r\n  tag tested_tf_version: '1.0.11'\r\n\r\n  tag remediation_steps: <<-EOF\r\n  AWS ElastiCache Redis cluster in-transit encryption can be set when creating the cluster. In order to resolve the alert for this control, you will need to create a new cluster with in-transit encryption enabled, then migrate all required ElastiCache Redis cluster data from the ElastiCache Redis cluster that caused the alert to the new cluster and delete old ElastiCache Redis cluster.\r\n\r\n  To create new ElastiCache Redis cluster with In-transit encryption set, please do the following:\r\n  1. Sign into the AWS console > Select the specific region from region drop down on the top right corner, that caused the alert.\r\n  2. Go to the ElastiCache Dashboard (or search for ElastiCache Dashboard in the search bar).\r\n  3. In the left-hand menu, Click on Redis > Click on Create button.\r\n  4. Select or enter the following information:\r\n\r\n      a.  Select 'Redis' cache engine type.\r\n      b.  Enter a name for the new cache cluster.\r\n      c.  Select Redis engine version from Engine version compatibility dropdown list.\r\n      d.  Click on Advanced Redis settings to expand the cluster advanced settings panel.\r\n      e.  Select Encryption in-transit checkbox to enable encryption along with other necessary options\r\n  5. Click on Create button to start your ElastiCache Redis cluster.\r\n\r\n  To delete reported ElastiCache Redis cluster, please do the following:\r\n  1. Sign into the AWS console > Select the specific region from region drop down on the top right corner, that caused the alert.\r\n  2. Go to the ElastiCache Dashboard (or search for ElastiCache Dashboard in the search bar).\r\n  3. In the left-hand menu, Click on Redis.\r\n  4. Select original Redis cluster.\r\n  5. Click on Delete button.\r\n  6. In the Delete Cluster dialog box, if you'd like to backup for your cluster, select Yes from the Create final backup dropdown menu, enter a name for the cluster backup > click on Delete.\r\n  EOF\r\n\r\n  aws_regions.region_names.each do |region_name|\r\n    aws_elasticache_replication_groups(aws_region: region_name).ids.each do |replication_group_id|\r\n      describe aws_elasticache_replication_group(aws_region: region_name, replication_group_id: replication_group_id) do\r\n        it { should be_encrypted_at_transit }\r\n      end\r\n    end\r\n  end\r\nend\r\n","source_location":{"ref":"./controls/aws_elastic/8_01_aws_elastic.rb","line":53},"id":"8_01_elasticache_cluster_in_transit_encryption"},{"title":"8.2 - AWS Elasticsearch domain should not be publicly accessible","desc":"The AWS ElasticSearch Service (ES) domain policy should not be usable for everyone by using the \"*\" principal. Otherwise the Elastic Search cluster may be open to any AWS account and user.","descriptions":{"default":"The AWS ElasticSearch Service (ES) domain policy should not be usable for everyone by using the \"*\" principal. Otherwise the Elastic Search cluster may be open to any AWS account and user."},"impact":0.5,"refs":[],"tags":{"sgs_wiki_url":"https://wiki.wdf.sap.corp/wiki/x/-0JAc","terraform_remediation":"  resource \"aws_elasticsearch_domain_policy\" \"example_domain_policy\" {\n    domain_name = <your elasticsearch domain>\n\n    access_policies = <<POLICIES\n  {\n      \"Version\": \"2012-10-17\",\n      \"Statement\": [\n           {\n              \"Effect\": \"Allow\",\n              \"Principal\": {\n                \"AWS\": [\n                  \"<arn of a policy principal user>\",\n                  \"<arn of another policy principal user>\"\n                ]\n              },\n              \"Action\": [\n                \"es:*\"\n              ],\n              \"Resource\": \"<arn of your elasticsearch domain>/*\"\n            }\n      ]\n  }\n  POLICIES\n  }\n","tested_tf_version":"1.0.11","terraform_remediation_note":"The policy principal must not include all users \"*\"","remediation_steps":"  1.  Login into the AWS Management Console.\n  2.  Navigate to Elasticsearch (OpenSearch) dashboard, which is now known as Amazon OpenSearch Service (successor to Amazon Elasticsearch) (or search for OpenSearch in the search bar).\n  3.  Click on the ES domain that caused the alert.\n  4.  On the reported domain description page > click the Modify access policy button from the dashboard top menu.\n  5.  On the Modify the access policy page for the domain in question > select one of the policy templates from the Set the domain access policy to dropdown list:\n\n        a.\tSelect Allow or deny access to one or multiple AWS accounts/IAM users and then provide the relevant AWS account ID/ARN or IAM user ARN to limit the access to a particular AWS account/IAM user.\n\n        b.\tSelect Allow access to the domain from specific IP(s) and enter an IP address (or multiple IP addresses, separated by commas) to limit the access to that particular IP address or multiple IP addresses.\n\n        c.\tSelect Copy an access policy from another domain and choose/enter another ES domain name to copy its access policy.\n\n        d.\tSelect Deny access to the domain to block all access to the selected ES domain.\n  6.  Click Submit.\n  7.  In the Change your access policy dialog box > click OK (The domain status should change from Active to Processing; it should then return to Active before your changed access policy takes effect).\n"},"code":"control '8_02_domain_publicly_available' do\r\n  title '8.2 - AWS Elasticsearch domain should not be publicly accessible'\r\n  impact 0.5\r\n  desc 'The AWS ElasticSearch Service (ES) domain policy should not be usable for everyone by using the \"*\" principal. Otherwise the Elastic Search cluster may be open to any AWS account and user.'\r\n  tag sgs_wiki_url: 'https://wiki.wdf.sap.corp/wiki/x/-0JAc'\r\n  tag terraform_remediation: <<-EOF\r\n  resource \"aws_elasticsearch_domain_policy\" \"example_domain_policy\" {\r\n    domain_name = <your elasticsearch domain>\r\n\r\n    access_policies = <<POLICIES\r\n  {\r\n      \"Version\": \"2012-10-17\",\r\n      \"Statement\": [\r\n           {\r\n              \"Effect\": \"Allow\",\r\n              \"Principal\": {\r\n                \"AWS\": [\r\n                  \"<arn of a policy principal user>\",\r\n                  \"<arn of another policy principal user>\"\r\n                ]\r\n              },\r\n              \"Action\": [\r\n                \"es:*\"\r\n              ],\r\n              \"Resource\": \"<arn of your elasticsearch domain>/*\"\r\n            }\r\n      ]\r\n  }\r\n  POLICIES\r\n  }\r\n  EOF\r\n  tag tested_tf_version: '1.0.11'\r\n  tag terraform_remediation_note: 'The policy principal must not include all users \"*\"'\r\n\r\n  tag remediation_steps: <<-EOF\r\n  1.  Login into the AWS Management Console.\r\n  2.  Navigate to Elasticsearch (OpenSearch) dashboard, which is now known as Amazon OpenSearch Service (successor to Amazon Elasticsearch) (or search for OpenSearch in the search bar).\r\n  3.  Click on the ES domain that caused the alert.\r\n  4.  On the reported domain description page > click the Modify access policy button from the dashboard top menu.\r\n  5.  On the Modify the access policy page for the domain in question > select one of the policy templates from the Set the domain access policy to dropdown list:\r\n\r\n        a.\tSelect Allow or deny access to one or multiple AWS accounts/IAM users and then provide the relevant AWS account ID/ARN or IAM user ARN to limit the access to a particular AWS account/IAM user.\r\n\r\n        b.\tSelect Allow access to the domain from specific IP(s) and enter an IP address (or multiple IP addresses, separated by commas) to limit the access to that particular IP address or multiple IP addresses.\r\n\r\n        c.\tSelect Copy an access policy from another domain and choose/enter another ES domain name to copy its access policy.\r\n\r\n        d.\tSelect Deny access to the domain to block all access to the selected ES domain.\r\n  6.  Click Submit.\r\n  7.  In the Change your access policy dialog box > click OK (The domain status should change from Active to Processing; it should then return to Active before your changed access policy takes effect).\r\n  EOF\r\n\r\n  aws_regions.region_names.each do |aws_region|\r\n    aws_elasticsearchservice_domains(aws_region: aws_region).domain_names.each do |es_domain_name|\r\n      es_domain = aws_elasticsearchservice_domain(aws_region: aws_region, domain_name: es_domain_name)\r\n      es_domain_policies = es_domain.access_policies\r\n\r\n      describe \"Elasticsearch Service Domain #{es_domain_name} should have attached IAM policies to limit access. Domain policies\" do\r\n        subject { es_domain_policies }\r\n        it { should_not be_empty }\r\n      end\r\n\r\n      next if es_domain_policies == ''\r\n      statements = JSON.parse(es_domain_policies)['Statement']\r\n\r\n      statements.each do |policy_statement|\r\n        domain_policy_principal = policy_statement['Principal']\r\n        describe \"Elasticsearch Service Domain #{es_domain_name} policy principal\" do\r\n          subject { domain_policy_principal }\r\n          it { should_not eq '*' }\r\n        end\r\n      end\r\n    end\r\n  end\r\nend\r\n","source_location":{"ref":"./controls/aws_elastic/8_02_aws_elastic.rb","line":1},"id":"8_02_domain_publicly_available"},{"title":"8.2 - AWS Elasticsearch domain should have encryption for data at rest enabled","desc":"In Order to prevent unauthorized users from reading sensitive data e.g. (file systems, primary and replica indices, log files, memory swap files and automated snapshots) available on the ElasticSearch domains, the data should be encrypted at REST.","descriptions":{"default":"In Order to prevent unauthorized users from reading sensitive data e.g. (file systems, primary and replica indices, log files, memory swap files and automated snapshots) available on the ElasticSearch domains, the data should be encrypted at REST."},"impact":0.5,"refs":[],"tags":{"sgs_wiki_url":"https://wiki.wdf.sap.corp/wiki/x/-0JAc","terraform_remediation":"  resource \"aws_elasticsearch_domain\" \"example_encrypted_domain\" {\n      ...\n       encrypt_at_rest {\n         enabled = true\n       }\n  }\n","tested_tf_version":"1.0.11","remediation_steps":"  To enable at-rest encryption for your existing AWS ElasticSearch domains, you must re-create them with the preferred encryption configuration. To fix the ES domain(s) in question, please implement the following steps:\n\n  1.\tLogin into the AWS Management Console.\n  2.\t Navigate to Elasticsearch (OpenSearch) dashboard, which is now known as Amazon OpenSearch Service (successor to Amazon Elasticsearch) (or search for OpenSearch in the search bar).\n  3.\tClick on the ES domain that caused the alert.\n  4.\tOn the domain configuration page, perform the following actions:\n\n        a.\tClick on the Overview tab > Copy the domain configuration information (information like Instance count, Instance type, Dedicated master instance type, Dedicated master instance count, Storage Type, EBS volume type, EBS volume size, etc.).\n\n        b.\tClick on the VPC tab > Copy the network configuration information (information like VPC ID, Security groups ID(s), IAM role name and AZs and Subnets IDs, etc.).\n\n        c.\tClick on Modify access policy button from the dashboard top menu > Copy the entire policy document available in the Add or edit the access policy textbox.\n  5.\tGo back to the AWS ElasticSearch (OpenSearch) service dashboard > Click Create new domain.\n  6.\tOn the Define domain page, please do the following steps:\n\n        a.\tEnter a unique name for the new domain in the Elasticsearch domain name box.\n\n        b.\tChoose the right version of the Elasticsearch engine from the Elasticsearch version dropdown list > Click Next.\n  7.\tOn the Configure cluster page, please do the following steps:\n\n        a.\tInput/paste the new domain options using the configuration details copied at step #4a.\n\n        b.\tSelect Enable encryption at rest checkbox to enable data-at-rest encryption. In the KMS master key dropdown list > Choose your AWS KMS Key OR Select Enter a key ARN from the dropdown list and paste a new CMK ARN into the ARN / ID box > Click Next.\n  8.\tOn the Set up access page, configure the network access to the new domain by using the same factors copied at step #4b; paste the access policy copied at step #4c into the Add or edit the access policy textbox > Click Next.\n  9.\tOn the Review page, verify the domain configuration details > Click Confirm.\n  10. Once the new AWS ES domain is created, upload the data from the original  domain to the new ES cluster.\n  11. You can now safely remove the original unencrypted ElasticSearch domain. To delete the unencrypted domain, please do the following steps:\n\n        a.\tClick on the name of the domain that you want to remove.\n\n        b.\tClick Delete domain.\n\n        c.\tWithin Delete domain dialog box, check Delete the domain > Click Delete.\n"},"code":"control '8_02_domain_encrypted_at_rest' do\r\n  title '8.2 - AWS Elasticsearch domain should have encryption for data at rest enabled'\r\n  impact 0.5\r\n  desc 'In Order to prevent unauthorized users from reading sensitive data e.g. (file systems, primary and replica indices, log files, memory swap files and automated snapshots) available on the ElasticSearch domains, the data should be encrypted at REST.'\r\n  tag sgs_wiki_url: 'https://wiki.wdf.sap.corp/wiki/x/-0JAc'\r\n  tag terraform_remediation: <<-EOF\r\n  resource \"aws_elasticsearch_domain\" \"example_encrypted_domain\" {\r\n      ...\r\n       encrypt_at_rest {\r\n         enabled = true\r\n       }\r\n  }\r\n  EOF\r\n  tag tested_tf_version: '1.0.11'\r\n\r\n  tag remediation_steps: <<-EOF\r\n  To enable at-rest encryption for your existing AWS ElasticSearch domains, you must re-create them with the preferred encryption configuration. To fix the ES domain(s) in question, please implement the following steps:\r\n\r\n  1.\tLogin into the AWS Management Console.\r\n  2.\t Navigate to Elasticsearch (OpenSearch) dashboard, which is now known as Amazon OpenSearch Service (successor to Amazon Elasticsearch) (or search for OpenSearch in the search bar).\r\n  3.\tClick on the ES domain that caused the alert.\r\n  4.\tOn the domain configuration page, perform the following actions:\r\n\r\n        a.\tClick on the Overview tab > Copy the domain configuration information (information like Instance count, Instance type, Dedicated master instance type, Dedicated master instance count, Storage Type, EBS volume type, EBS volume size, etc.).\r\n\r\n        b.\tClick on the VPC tab > Copy the network configuration information (information like VPC ID, Security groups ID(s), IAM role name and AZs and Subnets IDs, etc.).\r\n\r\n        c.\tClick on Modify access policy button from the dashboard top menu > Copy the entire policy document available in the Add or edit the access policy textbox.\r\n  5.\tGo back to the AWS ElasticSearch (OpenSearch) service dashboard > Click Create new domain.\r\n  6.\tOn the Define domain page, please do the following steps:\r\n\r\n        a.\tEnter a unique name for the new domain in the Elasticsearch domain name box.\r\n\r\n        b.\tChoose the right version of the Elasticsearch engine from the Elasticsearch version dropdown list > Click Next.\r\n  7.\tOn the Configure cluster page, please do the following steps:\r\n\r\n        a.\tInput/paste the new domain options using the configuration details copied at step #4a.\r\n\r\n        b.\tSelect Enable encryption at rest checkbox to enable data-at-rest encryption. In the KMS master key dropdown list > Choose your AWS KMS Key OR Select Enter a key ARN from the dropdown list and paste a new CMK ARN into the ARN / ID box > Click Next.\r\n  8.\tOn the Set up access page, configure the network access to the new domain by using the same factors copied at step #4b; paste the access policy copied at step #4c into the Add or edit the access policy textbox > Click Next.\r\n  9.\tOn the Review page, verify the domain configuration details > Click Confirm.\r\n  10. Once the new AWS ES domain is created, upload the data from the original  domain to the new ES cluster.\r\n  11. You can now safely remove the original unencrypted ElasticSearch domain. To delete the unencrypted domain, please do the following steps:\r\n\r\n        a.\tClick on the name of the domain that you want to remove.\r\n\r\n        b.\tClick Delete domain.\r\n\r\n        c.\tWithin Delete domain dialog box, check Delete the domain > Click Delete.\r\n    EOF\r\n\r\n  aws_regions.region_names.each do |aws_region|\r\n    aws_elasticsearchservice_domains(aws_region: aws_region).domain_names.each do |es_domain_name|\r\n      es_domain = aws_elasticsearchservice_domain(aws_region: aws_region, domain_name: es_domain_name)\r\n\r\n      describe es_domain do\r\n        its('encryption_at_rest_options.enabled') { should be true }\r\n      end\r\n    end\r\n  end\r\nend\r\n","source_location":{"ref":"./controls/aws_elastic/8_02_aws_elastic.rb","line":77},"id":"8_02_domain_encrypted_at_rest"},{"title":"8.2 - AWS Elasticsearch IAM policy should not be overly permissive to all traffic","desc":"Elasticsearch domains should not be accessible over the internet. An IAM policy should be defined with CIDR/IP-ranges that are allowed to use the Elastic Search service, or the Elastic Search Service should be in a VPC.","descriptions":{"default":"Elasticsearch domains should not be accessible over the internet. An IAM policy should be defined with CIDR/IP-ranges that are allowed to use the Elastic Search service, or the Elastic Search Service should be in a VPC."},"impact":0.5,"refs":[],"tags":{"sgs_wiki_url":"https://wiki.wdf.sap.corp/wiki/x/-0JAc","terraform_remediation":"  resource \"aws_elasticsearch_domain\" \"example_domain_in_vpc\" {\n      ...\n      vpc_options {\n          subnet_ids = <array of subnets>\n          security_group_ids = <array of applied security groups>\n        }\n  }\n","tested_tf_version":"1.0.11","remediation_steps":"  1.  Log into AWS console.\n  2.  Go to the IAM Services (or search for IAM in the search bar).\n  3.  Click on Policies in the left-hand panel.\n  4.  Search for the policy which caused the alert to be generated > Click on the name of the policy.\n  5.  Under the Permissions tab, click on Edit policy.\n  6.  Under the Visual editor, for each of the Elasticsearch Service, click little arrow/triangle to expand and please do the following:\n\n        a.  Click to expand Request conditions.\n\n        b.  Under the Source IP, remove the row with the entry '0.0.0.0/0' or '::/0' > Add condition with restrictive IP ranges.\n  7.  Click on Review policy > Save changes.\n"},"code":"control '8_02_domain_in_vpc_or_access_based_on_ip_allow_list' do\r\n  title '8.2 - AWS Elasticsearch IAM policy should not be overly permissive to all traffic'\r\n  impact 0.5\r\n  desc 'Elasticsearch domains should not be accessible over the internet. An IAM policy should be defined with CIDR/IP-ranges that are allowed to use the Elastic Search service, or the Elastic Search Service should be in a VPC.'\r\n  tag sgs_wiki_url: 'https://wiki.wdf.sap.corp/wiki/x/-0JAc'\r\n  tag terraform_remediation: <<-EOF\r\n  resource \"aws_elasticsearch_domain\" \"example_domain_in_vpc\" {\r\n      ...\r\n      vpc_options {\r\n          subnet_ids = <array of subnets>\r\n          security_group_ids = <array of applied security groups>\r\n        }\r\n  }\r\n  EOF\r\n  tag tested_tf_version: '1.0.11'\r\n\r\n  tag remediation_steps: <<-EOF\r\n  1.  Log into AWS console.\r\n  2.  Go to the IAM Services (or search for IAM in the search bar).\r\n  3.  Click on Policies in the left-hand panel.\r\n  4.  Search for the policy which caused the alert to be generated > Click on the name of the policy.\r\n  5.  Under the Permissions tab, click on Edit policy.\r\n  6.  Under the Visual editor, for each of the Elasticsearch Service, click little arrow/triangle to expand and please do the following:\r\n\r\n        a.  Click to expand Request conditions.\r\n\r\n        b.  Under the Source IP, remove the row with the entry '0.0.0.0/0' or '::/0' > Add condition with restrictive IP ranges.\r\n  7.  Click on Review policy > Save changes.\r\n  EOF\r\n\r\n  aws_regions.region_names.each do |aws_region|\r\n    aws_elasticsearchservice_domains(aws_region: aws_region).domain_names.each do |es_domain_name|\r\n      es_domain = aws_elasticsearchservice_domain(aws_region: aws_region, domain_name: es_domain_name)\r\n      es_domain_policies = es_domain.access_policies\r\n      describe \"Elasticsearch Service Domain #{es_domain_name} should have attached IAM policies to limit access. Domain policies\" do\r\n        subject { es_domain_policies }\r\n        it { should_not be_empty }\r\n      end\r\n      next if es_domain_policies == ''\r\n      statements = JSON.parse(es_domain_policies)['Statement']\r\n      statements.each do |policy_statement|\r\n        describe.one do\r\n          describe \"Elasticsearch Service Domain #{es_domain_name} should be in a VPC\" do\r\n            subject { es_domain }\r\n            its('vpc_options.nil?') { should eq false }\r\n          end\r\n          if (policy_statement['Effect'] == 'Allow') && !policy_statement['Condition'].nil?\r\n            if !policy_statement['Condition']['IpAddress'].nil? || !policy_statement['Condition']['IpAddress']['aws:SourceIp'].nil?\r\n              if policy_statement['Condition']['IpAddress']['aws:SourceIp'].is_a?(Array)\r\n                policy_statement['Condition']['IpAddress']['aws:SourceIp'].each do |ip_range|\r\n                  describe \"Elasticsearch Service Domain #{es_domain_name} policy IpAddress condition should not be overly permissive to all ip traffic. It\" do\r\n                    subject { ip_range }\r\n                    it { should_not eq '0.0.0.0/0' }\r\n                    it { should_not eq '::/0' }\r\n                  end\r\n                end\r\n              elsif policy_statement['Condition']['IpAddress']['aws:SourceIp'].is_a?(String)\r\n                describe \"Elasticsearch Service Domain #{es_domain_name} policy IpAddress condition should not be overly permissive to all ip traffic. It\" do\r\n                  subject { policy_statement['Condition']['IpAddress']['aws:SourceIp'] }\r\n                  it { should_not eq '0.0.0.0/0' }\r\n                  it { should_not eq '::/0' }\r\n                end\r\n              end\r\n            end\r\n          end\r\n        end\r\n      end\r\n    end\r\n  end\r\nend\r\n","source_location":{"ref":"./controls/aws_elastic/8_02_aws_elastic.rb","line":139},"id":"8_02_domain_in_vpc_or_access_based_on_ip_allow_list"},{"title":"8.2 - AWS Elasticsearch domain should be configured within a VPC","desc":"The AWS ES cluster should be configured within a VPC to have an extra\n          layer of security. As a positive side effect, the VPC setup ensures,\n          that the traffic between other services and Amazon ES stays entirely\n          within the AWS network, isolated from the public Internet.","descriptions":{"default":"The AWS ES cluster should be configured within a VPC to have an extra\n          layer of security. As a positive side effect, the VPC setup ensures,\n          that the traffic between other services and Amazon ES stays entirely\n          within the AWS network, isolated from the public Internet."},"impact":0.5,"refs":[],"tags":{"sgs_wiki_url":"https://wiki.wdf.sap.corp/wiki/x/-0JAc","terraform_remediation":"  resource \"aws_elasticsearch_domain\" \"example_domain_in_vpc\" {\n      ...\n      vpc_options {\n          subnet_ids = <array of subnets>\n          security_group_ids = <array of applied security groups>\n        }\n  }\n","tested_tf_version":"1.0.11","remediation_steps":"  A VPC for AWS Elasticsearch domain can only be set at the time of the creation of domain. In order to remediate this alert, please create a new domain with VPC. Once that is done, migrate all Elasticsearch domain data from the Elasticsearch domain that was mentioned in the alert to this new domain and then, delete the old Elasticsearch domain.\n\n  In order to set up the new ES domain with VPC, please do the following steps:\n  1.  Sign into the AWS console.\n  2.  Navigate to Elasticsearch Service Dashboard (or search OpenSearch (aka Elasticsearch) in the search bar) > Click on Dashboard > Click on Create domain.\n  3.  On the 'Define domain' page, enter the Elasticsearch domain name, Elasticsearch version > Click Next.\n  4.  On the 'Configure cluster' page, enter the new domain options (which would be the same as the domain configuration that mentioned in the alert).\n  5.  On the 'Set up access' page, please do the following steps:\n\n        5a.   Under 'Network configuration' section, select 'VPC access (Recommended)'.\n\n        5b.   Click on the desired VPC, Subnet and Security Group from the drop-down list > Click on 'Next'.\n  6.  On the 'Review' page, double check and review the domain configuration details.\n  7.  Click 'Confirm'.\n  8.  Once the new AWS ES domain is created, upload the data from the original domain to the new ES domain.\n\n  To delete ES domain mentioned in the alert, please perform the following steps:\n  1.  Sign into the AWS console.\n  2.  Navigate to Elasticsearch Service Dashboard (or search OpenSearch (aka Elasticsearch) in the search bar).\n  3.  Choose Elasticsearch domain mentioned in the alert > Click 'Delete Domain'.\n  4.  On 'Delete Domain' dialog popup, check the 'Delete the domain' > Click 'Delete'.\n"},"code":"control '8_02_domain_in_vpc' do\r\n  title '8.2 - AWS Elasticsearch domain should be configured within a VPC'\r\n  desc 'The AWS ES cluster should be configured within a VPC to have an extra\r\n          layer of security. As a positive side effect, the VPC setup ensures,\r\n          that the traffic between other services and Amazon ES stays entirely\r\n          within the AWS network, isolated from the public Internet.'\r\n  impact 0.5\r\n  tag sgs_wiki_url: 'https://wiki.wdf.sap.corp/wiki/x/-0JAc'\r\n  tag terraform_remediation: <<-EOF\r\n  resource \"aws_elasticsearch_domain\" \"example_domain_in_vpc\" {\r\n      ...\r\n      vpc_options {\r\n          subnet_ids = <array of subnets>\r\n          security_group_ids = <array of applied security groups>\r\n        }\r\n  }\r\n  EOF\r\n  tag tested_tf_version: '1.0.11'\r\n\r\n  tag remediation_steps: <<-EOF\r\n  A VPC for AWS Elasticsearch domain can only be set at the time of the creation of domain. In order to remediate this alert, please create a new domain with VPC. Once that is done, migrate all Elasticsearch domain data from the Elasticsearch domain that was mentioned in the alert to this new domain and then, delete the old Elasticsearch domain.\r\n\r\n  In order to set up the new ES domain with VPC, please do the following steps:\r\n  1.  Sign into the AWS console.\r\n  2.  Navigate to Elasticsearch Service Dashboard (or search OpenSearch (aka Elasticsearch) in the search bar) > Click on Dashboard > Click on Create domain.\r\n  3.  On the 'Define domain' page, enter the Elasticsearch domain name, Elasticsearch version > Click Next.\r\n  4.  On the 'Configure cluster' page, enter the new domain options (which would be the same as the domain configuration that mentioned in the alert).\r\n  5.  On the 'Set up access' page, please do the following steps:\r\n\r\n        5a.   Under 'Network configuration' section, select 'VPC access (Recommended)'.\r\n\r\n        5b.   Click on the desired VPC, Subnet and Security Group from the drop-down list > Click on 'Next'.\r\n  6.  On the 'Review' page, double check and review the domain configuration details.\r\n  7.  Click 'Confirm'.\r\n  8.  Once the new AWS ES domain is created, upload the data from the original domain to the new ES domain.\r\n\r\n  To delete ES domain mentioned in the alert, please perform the following steps:\r\n  1.  Sign into the AWS console.\r\n  2.  Navigate to Elasticsearch Service Dashboard (or search OpenSearch (aka Elasticsearch) in the search bar).\r\n  3.  Choose Elasticsearch domain mentioned in the alert > Click 'Delete Domain'.\r\n  4.  On 'Delete Domain' dialog popup, check the 'Delete the domain' > Click 'Delete'.\r\n  EOF\r\n\r\n  aws_regions.region_names.each do |aws_region|\r\n    aws_elasticsearchservice_domains(aws_region: aws_region).domain_names.each do |es_domain_name|\r\n      es_domain = aws_elasticsearchservice_domain(aws_region: aws_region, domain_name: es_domain_name)\r\n\r\n      describe es_domain do\r\n        its('vpc_options.vpc_id.nil?') { should be false }\r\n      end\r\n    end\r\n  end\r\nend\r\n","source_location":{"ref":"./controls/aws_elastic/8_02_aws_elastic.rb","line":210},"id":"8_02_domain_in_vpc"},{"title":"7.4 - AWS EKS cluster security group must not be overly permissive to all traffic","desc":"This policy identifies EKS cluster Security groups that are overly permissive to all traffic.\n    Doing so, may allow a bad actor to brute force their way into the system and potentially get access\n    to the entire network. Review your list of security group rules to ensure that your resources are not exposed.\n    As a best practice, restrict traffic solely from known static IP addresses. Limit the access list to include known hosts,\n    services, or specific employees only.","descriptions":{"default":"This policy identifies EKS cluster Security groups that are overly permissive to all traffic.\n    Doing so, may allow a bad actor to brute force their way into the system and potentially get access\n    to the entire network. Review your list of security group rules to ensure that your resources are not exposed.\n    As a best practice, restrict traffic solely from known static IP addresses. Limit the access list to include known hosts,\n    services, or specific employees only."},"impact":0.8,"refs":[],"tags":{"sgs_wiki_url":"https://wiki.wdf.sap.corp/wiki/x/-0JAc","terraform_remediation":"  resource \"aws_security_group\" \"example_eks_security_group\" {\n    name        = <your security group name>\n    description = <your security group description>\n    vpc_id = <id of your vpc>\n  }\n\n  resource \"aws_security_group_rule\" \"eks_security_group_rule\" {\n    type      = \"ingress\"\n    from_port = <starting port for a range, or a single port>\n    to_port   = <ending port for a range, or a single port>\n    protocol  = <relevant protocol>\n    cidr_blocks = <list of allowed ipv4 IP CIDRs>\n    ipv6_cidr_blocks = <list of allowed ipv6 IP CIDRs>\n    security_group_id = aws_security_group.example_eks_security_group.id\n  }\n\n\n  resource \"aws_eks_cluster\" \"example_cluster\" {\n    ...\n    vpc_config {\n      ...\n      security_group_ids = [aws_security_group.eks_security_group.id]   \n      ...\n    }\n  }\n","tested_tf_version":"1.0.11","terraform_remediation_note":"The list of allowed IP CIDRs must be limited and must not include 0.0.0.0/0 or ::/0","remediation_steps":"  1.  Log in to the AWS console.\n  2.  Navigate to the VPC service (or search for VPC in the search bar).\n  3.  Click on Security Groups > Click on the name of the security group mentioned in the alert > Click on Inbound Rules > Remove the rule which mentions the source value as 0.0.0.0/0 or ::/0.\n"},"code":"control '7_04_eks_cluster_security_group_traffic_permissions' do\r\n  title '7.4 - AWS EKS cluster security group must not be overly permissive to all traffic'\r\n  impact 0.8\r\n  desc 'This policy identifies EKS cluster Security groups that are overly permissive to all traffic.\r\n    Doing so, may allow a bad actor to brute force their way into the system and potentially get access\r\n    to the entire network. Review your list of security group rules to ensure that your resources are not exposed.\r\n    As a best practice, restrict traffic solely from known static IP addresses. Limit the access list to include known hosts,\r\n    services, or specific employees only.'\r\n  tag sgs_wiki_url: 'https://wiki.wdf.sap.corp/wiki/x/-0JAc'\r\n  tag terraform_remediation: <<-EOF\r\n  resource \"aws_security_group\" \"example_eks_security_group\" {\r\n    name        = <your security group name>\r\n    description = <your security group description>\r\n    vpc_id = <id of your vpc>\r\n  }\r\n\r\n  resource \"aws_security_group_rule\" \"eks_security_group_rule\" {\r\n    type      = \"ingress\"\r\n    from_port = <starting port for a range, or a single port>\r\n    to_port   = <ending port for a range, or a single port>\r\n    protocol  = <relevant protocol>\r\n    cidr_blocks = <list of allowed ipv4 IP CIDRs>\r\n    ipv6_cidr_blocks = <list of allowed ipv6 IP CIDRs>\r\n    security_group_id = aws_security_group.example_eks_security_group.id\r\n  }\r\n\r\n\r\n  resource \"aws_eks_cluster\" \"example_cluster\" {\r\n    ...\r\n    vpc_config {\r\n      ...\r\n      security_group_ids = [aws_security_group.eks_security_group.id]#{'   '}\r\n      ...\r\n    }\r\n  }\r\n  EOF\r\n  tag tested_tf_version: '1.0.11'\r\n  tag terraform_remediation_note: 'The list of allowed IP CIDRs must be limited and must not include 0.0.0.0/0 or ::/0'\r\n\r\n  tag remediation_steps: <<-EOF\r\n  1.  Log in to the AWS console.\r\n  2.  Navigate to the VPC service (or search for VPC in the search bar).\r\n  3.  Click on Security Groups > Click on the name of the security group mentioned in the alert > Click on Inbound Rules > Remove the rule which mentions the source value as 0.0.0.0/0 or ::/0.\r\n  EOF\r\n\r\n  aws_regions.region_names.each do |region_name|\r\n    aws_eks_clusters(aws_region: region_name).names.each do |name|\r\n      cluster_security_groups = aws_eks_cluster(aws_region: region_name, cluster_name: name).security_group_ids\r\n      cluster_security_groups.each do |security_group_id|\r\n        describe aws_security_group(aws_region: region_name, group_id: security_group_id) do\r\n          it { should_not allow_in(ipv4_range: '0.0.0.0/0') }\r\n          it { should_not allow_in(ipv6_range: '::/0') }\r\n        end\r\n      end\r\n    end\r\n  end\r\nend\r\n","source_location":{"ref":"./controls/containers_and_kubernetes/7_04_k8s.rb","line":1},"id":"7_04_eks_cluster_security_group_traffic_permissions"},{"title":"7.4 - AWS EKS cluster should not use the default VPC","desc":"The deployment of an EKS cluster should be done in a VPC configuration based on security and networking requirements. Therefore, the EKS clusters should operate in a dedicated VPC instead of using the default VPC.","descriptions":{"default":"The deployment of an EKS cluster should be done in a VPC configuration based on security and networking requirements. Therefore, the EKS clusters should operate in a dedicated VPC instead of using the default VPC."},"impact":0.5,"refs":[],"tags":{"sgs_wiki_url":"https://wiki.wdf.sap.corp/wiki/x/-0JAc","terraform_remediation":"  resource \"aws_eks_cluster\" \"example_cluster\" {\n    ...\n    vpc_config {\n      subnet_ids = <list of subnet IDs in non-default vpc>\n      ...\n    }\n  }\n","tested_tf_version":"1.0.11","remediation_steps":"  Once an AWS EKS cluster VPC is created, it can't be modified. In order to remediate this alert, please create a new cluster with a custom VPC, then move all of the required cluster data from the cluster mentioned in the alert to the new cluster and then delete the original Kubernetes cluster.\n\n  1.  Open the Amazon EKS dashboard (or search for EKS in the search bar).\n  2.  Click Add cluster > Click Create cluster.\n  3.  On the Create cluster page, complete the following fields:\n\n        * Cluster name\n        * Kubernetes version\n        * Role name\n        * VPC - Choose your new custom VPC.\n        * Subnets\n        * Security Groups\n        * Endpoint private access\n        * Endpoint public access\n        * Logging\n  4.  Click Create.\n"},"code":"control '7_04_eks_cluster_using_default_vpc' do\r\n  title '7.4 - AWS EKS cluster should not use the default VPC'\r\n  impact 0.5\r\n  desc 'The deployment of an EKS cluster should be done in a VPC configuration based on security and networking requirements. Therefore, the EKS clusters should operate in a dedicated VPC instead of using the default VPC.'\r\n  tag sgs_wiki_url: 'https://wiki.wdf.sap.corp/wiki/x/-0JAc'\r\n  tag terraform_remediation: <<-EOF\r\n  resource \"aws_eks_cluster\" \"example_cluster\" {\r\n    ...\r\n    vpc_config {\r\n      subnet_ids = <list of subnet IDs in non-default vpc>\r\n      ...\r\n    }\r\n  }\r\n  EOF\r\n  tag tested_tf_version: '1.0.11'\r\n\r\n  tag remediation_steps: <<-EOF\r\n  Once an AWS EKS cluster VPC is created, it can't be modified. In order to remediate this alert, please create a new cluster with a custom VPC, then move all of the required cluster data from the cluster mentioned in the alert to the new cluster and then delete the original Kubernetes cluster.\r\n\r\n  1.  Open the Amazon EKS dashboard (or search for EKS in the search bar).\r\n  2.  Click Add cluster > Click Create cluster.\r\n  3.  On the Create cluster page, complete the following fields:\r\n\r\n        * Cluster name\r\n        * Kubernetes version\r\n        * Role name\r\n        * VPC - Choose your new custom VPC.\r\n        * Subnets\r\n        * Security Groups\r\n        * Endpoint private access\r\n        * Endpoint public access\r\n        * Logging\r\n  4.  Click Create.\r\n  EOF\r\n\r\n  aws_regions.region_names.each do |region_name|\r\n    aws_eks_clusters(aws_region: region_name).names.each do |name|\r\n      vpc = aws_eks_cluster(aws_region: region_name, cluster_name: name).vpc_id\r\n      describe \"VPC for EKS Cluster #{name} in region #{region_name}\" do\r\n        subject { aws_vpc(aws_region: region_name, vpc_id: vpc) }\r\n        it { should_not be_default }\r\n      end\r\n    end\r\n  end\r\nend\r\n","source_location":{"ref":"./controls/containers_and_kubernetes/7_04_k8s.rb","line":59},"id":"7_04_eks_cluster_using_default_vpc"},{"title":"7.12 - AWS EKS cluster endpoint public access should be disabled","desc":"By default, the Kubernetes API server which is used to communicate to the cluster is public exposed to the internet. To secure the API, public access should be set to false, and private access should be set to true.","descriptions":{"default":"By default, the Kubernetes API server which is used to communicate to the cluster is public exposed to the internet. To secure the API, public access should be set to false, and private access should be set to true."},"impact":0.5,"refs":[],"tags":{"sgs_wiki_url":"https://wiki.wdf.sap.corp/wiki/x/-0JAc","terraform_remediation":"  resource \"aws_eks_cluster\" \"example_cluster\" {\n    ...\n    vpc_config {\n    ...\n    endpoint_private_access = true\n    endpoint_public_access = false\n    }\n  }\n","tested_tf_version":"1.0.11","remediation_steps":"  1.  Login to AWS Console.\n  2.  Navigate to the Amazon EKS dashboard.\n  3.  Choose the name of the cluster to display your cluster information.\n  4.  Click on the Configuration tab > Click on the Networking tab.\n  5.  Under Networking, click Manage networking.\n  6.  Select Private.\n  7.  Click Save Changes.\n"},"code":"control '7_12_eks_cluster_api_publicly_accessible' do\r\n  title '7.12 - AWS EKS cluster endpoint public access should be disabled'\r\n  impact 0.5\r\n  desc 'By default, the Kubernetes API server which is used to communicate to the cluster is public exposed to the internet. To secure the API, public access should be set to false, and private access should be set to true.'\r\n  tag sgs_wiki_url: 'https://wiki.wdf.sap.corp/wiki/x/-0JAc'\r\n  tag terraform_remediation: <<-EOF\r\n  resource \"aws_eks_cluster\" \"example_cluster\" {\r\n    ...\r\n    vpc_config {\r\n    ...\r\n    endpoint_private_access = true\r\n    endpoint_public_access = false\r\n    }\r\n  }\r\n  EOF\r\n  tag tested_tf_version: '1.0.11'\r\n\r\n  tag remediation_steps: <<-EOF\r\n  1.  Login to AWS Console.\r\n  2.  Navigate to the Amazon EKS dashboard.\r\n  3.  Choose the name of the cluster to display your cluster information.\r\n  4.  Click on the Configuration tab > Click on the Networking tab.\r\n  5.  Under Networking, click Manage networking.\r\n  6.  Select Private.\r\n  7.  Click Save Changes.\r\n  EOF\r\n\r\n  aws_regions.region_names.each do |region_name|\r\n    aws_eks_clusters(aws_region: region_name).names.each do |name|\r\n      describe \"API for EKS Cluster #{name} in region #{region_name}\" do\r\n        subject { aws_eks_cluster(aws_region: region_name, cluster_name: name) }\r\n        its('resources_vpc_config.endpoint_public_access') { should eq false }\r\n        its('resources_vpc_config.endpoint_private_access') { should eq true }\r\n      end\r\n    end\r\n  end\r\nend\r\n","source_location":{"ref":"./controls/containers_and_kubernetes/7_12_k8s.rb","line":1},"id":"7_12_eks_cluster_api_publicly_accessible"},{"title":"2.1 - AWS access keys must be used in the last 90 days","desc":"This policy identifies access keys which have not been used within the\n    last 90 days. Rotating access keys will reduce the window of opportunity\n    for an access key that is associated with a compromised or terminated\n    account to be used. According to the SGS policy : \"Ensure all active keys\n    have been used within the last 90 days. Access keys are used to sign API requests to AWS.\n    As a security best practice, it is recommended that all access keys are\n    regularly used. This is to ensure that unused keys are deleted, so that\n    in the event of key compromise, unused or outdated keys cannot be used to\n    access AWS services.","descriptions":{"default":"This policy identifies access keys which have not been used within the\n    last 90 days. Rotating access keys will reduce the window of opportunity\n    for an access key that is associated with a compromised or terminated\n    account to be used. According to the SGS policy : \"Ensure all active keys\n    have been used within the last 90 days. Access keys are used to sign API requests to AWS.\n    As a security best practice, it is recommended that all access keys are\n    regularly used. This is to ensure that unused keys are deleted, so that\n    in the event of key compromise, unused or outdated keys cannot be used to\n    access AWS services."},"impact":0.8,"refs":[],"tags":{"sgs_wiki_url":"https://wiki.wdf.sap.corp/wiki/x/-0JAc","remediation_steps":"  1.  Log into to the AWS Admin Console > Access the IAM service (or search for IAM in the search bar).\n  2.  Navigate to the user in question > Click on the Security Credentials tab.\n  3.  Identify the Access Key that hasn't been used in 90 days  >  Delete that key (or Make Inactive).\n"},"code":"control '2_01_key_last_use' do\r\n  title '2.1 - AWS access keys must be used in the last 90 days'\r\n  impact 0.8\r\n  desc 'This policy identifies access keys which have not been used within the\r\n    last 90 days. Rotating access keys will reduce the window of opportunity\r\n    for an access key that is associated with a compromised or terminated\r\n    account to be used. According to the SGS policy : \"Ensure all active keys\r\n    have been used within the last 90 days. Access keys are used to sign API requests to AWS.\r\n    As a security best practice, it is recommended that all access keys are\r\n    regularly used. This is to ensure that unused keys are deleted, so that\r\n    in the event of key compromise, unused or outdated keys cannot be used to\r\n    access AWS services.'\r\n  tag sgs_wiki_url: 'https://wiki.wdf.sap.corp/wiki/x/-0JAc'\r\n\r\n  tag remediation_steps: <<-EOF\r\n  1.  Log into to the AWS Admin Console > Access the IAM service (or search for IAM in the search bar).\r\n  2.  Navigate to the user in question > Click on the Security Credentials tab.\r\n  3.  Identify the Access Key that hasn't been used in 90 days  >  Delete that key (or Make Inactive).\r\n  EOF\r\n\r\n  aws_iam_users.usernames.each do |user|\r\n    next if user == 'azure-sync-user'\r\n\r\n    keys = aws_iam_access_keys(username: user).where { created_days_ago > 90 }.where(active: true)\r\n\r\n    next if keys.count == 0\r\n    keys.entries.each do |access_key|\r\n      describe \"IAM access key #{access_key['access_key_id']} for user #{access_key['username']}\" do\r\n        subject { access_key.last_used_days_ago }\r\n        it { should be <= 90 }\r\n      end\r\n    end\r\n  end\r\nend\r\n","source_location":{"ref":"./controls/iam_and_keys/2_01_iam_and_keys.rb","line":1},"id":"2_01_key_last_use"},{"title":"2.1 - AWS IAM access keys must be rotated within 90 days of creation","desc":"This policy identifies IAM users for which access keys are not rotated for 90 days.\n    Access keys are used to sign API requests to AWS. According to the SGS policy: \"Access\n    keys MUST be rotated after 90 days at least\". As a security best practice, it is\n    recommended that all access keys are regularly rotated to make sure that in the event of key compromise,\n    unauthorized users are not able to gain access to your AWS services.","descriptions":{"default":"This policy identifies IAM users for which access keys are not rotated for 90 days.\n    Access keys are used to sign API requests to AWS. According to the SGS policy: \"Access\n    keys MUST be rotated after 90 days at least\". As a security best practice, it is\n    recommended that all access keys are regularly rotated to make sure that in the event of key compromise,\n    unauthorized users are not able to gain access to your AWS services."},"impact":0.8,"refs":[],"tags":{"sgs_wiki_url":"https://wiki.wdf.sap.corp/wiki/x/-0JAc","remediation_steps":"  1.  Navigate to the IAM service (or search for IAM in the search bar).\n  2.  Click on the user that was reported in the alert.\n  3.  Click on Security Credentials and for each Access Key, follow the instructions below to rotate the Access Keys that are older than 90 days:\n    <https://docs.aws.amazon.com/IAM/latest/UserGuide/id_credentials_access-keys.html#rotating_access_keys_console>\n"},"code":"control '2_01_key_rotation' do\r\n  title '2.1 - AWS IAM access keys must be rotated within 90 days of creation'\r\n  impact 0.8\r\n  desc 'This policy identifies IAM users for which access keys are not rotated for 90 days.\r\n    Access keys are used to sign API requests to AWS. According to the SGS policy: \"Access\r\n    keys MUST be rotated after 90 days at least\". As a security best practice, it is\r\n    recommended that all access keys are regularly rotated to make sure that in the event of key compromise,\r\n    unauthorized users are not able to gain access to your AWS services.'\r\n  tag sgs_wiki_url: 'https://wiki.wdf.sap.corp/wiki/x/-0JAc'\r\n\r\n  tag remediation_steps: <<-EOF\r\n  1.  Navigate to the IAM service (or search for IAM in the search bar).\r\n  2.  Click on the user that was reported in the alert.\r\n  3.  Click on Security Credentials and for each Access Key, follow the instructions below to rotate the Access Keys that are older than 90 days:\r\n    <https://docs.aws.amazon.com/IAM/latest/UserGuide/id_credentials_access-keys.html#rotating_access_keys_console>\r\n  EOF\r\n\r\n  aws_iam_users.usernames.each do |user|\r\n    next if user == 'azure-sync-user'\r\n\r\n    aws_iam_access_keys(username: user).where(active: true).entries.each do |access_key|\r\n      describe(\"IAM access key #{access_key['access_key_id']} for user #{access_key['username']}\") do\r\n        subject { access_key.created_days_ago }\r\n        it { should be <= 90 }\r\n      end\r\n    end\r\n  end\r\nend\r\n","source_location":{"ref":"./controls/iam_and_keys/2_01_iam_and_keys.rb","line":36},"id":"2_01_key_rotation"},{"title":"2.1 - AWS IAM SSH Keys should be rotated within 730 days for AWS CodeCommit","desc":"It should be ensured that key rotation is also applied for SSH keys used in AWS CodeCommit. These keys should be rotated min. every 2 years. Each key must have a well-defined lifetime in order to limit the damage or exposure of encrypted data if the key becomes compromised or computable.","descriptions":{"default":"It should be ensured that key rotation is also applied for SSH keys used in AWS CodeCommit. These keys should be rotated min. every 2 years. Each key must have a well-defined lifetime in order to limit the damage or exposure of encrypted data if the key becomes compromised or computable."},"impact":0.5,"refs":[],"tags":{"sgs_wiki_url":"https://wiki.wdf.sap.corp/wiki/x/-0JAc","remediation_steps":"  1.  Login to AWS Console.\n  2.  Go to IAM (or search for IAM in the search bar) > Select Users.\n  3.  Click on the user mentioned in the alert.\n  4.  Click on the Security Credentials tab.\n  5.  Delete the SSH Key ID > Upload a new SSH Key.\n    Please see the following link for details on key creation steps:\n    <https://docs.aws.amazon.com/codecommit/latest/userguide/setting-up-ssh-unixes.html>\n"},"code":"control '2_01_iam_ssh_key_age_rotation' do\r\n  title '2.1 - AWS IAM SSH Keys should be rotated within 730 days for AWS CodeCommit'\r\n  impact 0.5\r\n  desc 'It should be ensured that key rotation is also applied for SSH keys used in AWS CodeCommit. These keys should be rotated min. every 2 years. Each key must have a well-defined lifetime in order to limit the damage or exposure of encrypted data if the key becomes compromised or computable.'\r\n  tag sgs_wiki_url: 'https://wiki.wdf.sap.corp/wiki/x/-0JAc'\r\n\r\n  tag remediation_steps: <<-EOF\r\n  1.  Login to AWS Console.\r\n  2.  Go to IAM (or search for IAM in the search bar) > Select Users.\r\n  3.  Click on the user mentioned in the alert.\r\n  4.  Click on the Security Credentials tab.\r\n  5.  Delete the SSH Key ID > Upload a new SSH Key.\r\n    Please see the following link for details on key creation steps:\r\n    <https://docs.aws.amazon.com/codecommit/latest/userguide/setting-up-ssh-unixes.html>\r\n  EOF\r\n\r\n  aws_iam_users.usernames.each do |user_name|\r\n    aws_iam_ssh_public_keys(user_name: user_name).ssh_public_key_ids.each do |public_key_id|\r\n      describe aws_iam_ssh_public_key(user_name: user_name, ssh_public_key_id: public_key_id, encoding: 'SSH') do\r\n        its('ssh_key_age_valid') { should eq true }\r\n      end\r\n    end\r\n  end\r\nend\r\n","source_location":{"ref":"./controls/iam_and_keys/2_01_iam_and_keys.rb","line":65},"id":"2_01_iam_ssh_key_age_rotation"},{"title":"2.1 - AWS IAM SSL/TLS certificates should not be expired","desc":"This control enforces to delete expired SSL/TLS certificates. SSL/TLS server certificates are used to enable HTTPS connections to your website or application in AWS. Deleting expired SSL/TLS certificates eliminates risk of accidentally attaching an invalid certificate to AWS resource such as AWS Elastic Load Balancer (ELB) which can damage credibility of the application/website behind the ELB. As a security best practice, it is secured to delete expired certificates.","descriptions":{"default":"This control enforces to delete expired SSL/TLS certificates. SSL/TLS server certificates are used to enable HTTPS connections to your website or application in AWS. Deleting expired SSL/TLS certificates eliminates risk of accidentally attaching an invalid certificate to AWS resource such as AWS Elastic Load Balancer (ELB) which can damage credibility of the application/website behind the ELB. As a security best practice, it is secured to delete expired certificates."},"impact":0.5,"refs":[],"tags":{"sgs_wiki_url":"https://wiki.wdf.sap.corp/wiki/x/-0JAc","remediation_steps":"  Currently, removing invalid certificates cannot be done via the AWS Console. In order to delete SSL/TLS certificates stored in IAM, you must use the Command Line Interface (CLI).\n\n  Remediation CLI:\n\n  1.  Run the following describe-load-balancers command to make sure that the expired server certificate is not being used by any active load balancer:\n\n\t    aws elb describe-load-balancers --region <COMPUTE_REGION> --load-balancer-names <ELB_NAME> --query 'LoadBalancerDescriptions[*].ListenerDescriptions[*].Listener.SSLCertificateId'\n      This command output will return the Amazon Resource Name (ARN) for the SSL certificate currently used by the selected ELB:\n      [\n        [\n          \"\"arn:aws:iam::1234567890:server-certificate/MyCertificate\"\"\n        ]\n      ]\n\n  2.  If the load balancer listener using the expired certificate is not removed before the certificate, the ELB could continue to use the same expired certificate and not work properly. To delete the ELB listener that is using the expired SSL certificate, please run following command:\n\n      aws elb delete-load-balancer-listeners --region <COMPUTE_REGION> --load-balancer-name <ELB_NAME> --load-balancer-ports 443\n\n  3.  Now you can safely remove the expired SSL/TLS certificate from AWS IAM. To delete it, please run the following command:\n\n      aws iam delete-server-certificate --server-certificate-name <CERTIFICATE_NAME>\n"},"code":"control '2_01_iam_server_cert_expired' do\r\n  title '2.1 - AWS IAM SSL/TLS certificates should not be expired'\r\n  desc 'This control enforces to delete expired SSL/TLS certificates. SSL/TLS server certificates are used to enable HTTPS connections to your website or application in AWS. Deleting expired SSL/TLS certificates eliminates risk of accidentally attaching an invalid certificate to AWS resource such as AWS Elastic Load Balancer (ELB) which can damage credibility of the application/website behind the ELB. As a security best practice, it is secured to delete expired certificates.'\r\n  tag sgs_wiki_url: 'https://wiki.wdf.sap.corp/wiki/x/-0JAc'\r\n\r\n  tag remediation_steps: <<-EOF\r\n  Currently, removing invalid certificates cannot be done via the AWS Console. In order to delete SSL/TLS certificates stored in IAM, you must use the Command Line Interface (CLI).\r\n\r\n  Remediation CLI:\r\n\r\n  1.  Run the following describe-load-balancers command to make sure that the expired server certificate is not being used by any active load balancer:\r\n\r\n\t    aws elb describe-load-balancers --region <COMPUTE_REGION> --load-balancer-names <ELB_NAME> --query 'LoadBalancerDescriptions[*].ListenerDescriptions[*].Listener.SSLCertificateId'\r\n      This command output will return the Amazon Resource Name (ARN) for the SSL certificate currently used by the selected ELB:\r\n      [\r\n        [\r\n          \"\"arn:aws:iam::1234567890:server-certificate/MyCertificate\"\"\r\n        ]\r\n      ]\r\n\r\n  2.  If the load balancer listener using the expired certificate is not removed before the certificate, the ELB could continue to use the same expired certificate and not work properly. To delete the ELB listener that is using the expired SSL certificate, please run following command:\r\n\r\n      aws elb delete-load-balancer-listeners --region <COMPUTE_REGION> --load-balancer-name <ELB_NAME> --load-balancer-ports 443\r\n\r\n  3.  Now you can safely remove the expired SSL/TLS certificate from AWS IAM. To delete it, please run the following command:\r\n\r\n      aws iam delete-server-certificate --server-certificate-name <CERTIFICATE_NAME>\r\n  EOF\r\n\r\n  scan_date = ENV['MINERVA_SCHEDULED_SCAN_DATE'] ? Date.parse(ENV['MINERVA_SCHEDULED_SCAN_DATE']) : Date.today\r\n  aws_iam_server_certificates.entries.each do |iam_server_cert|\r\n    expiration_date = Date.parse(iam_server_cert.expiration_date.to_s)\r\n    describe \"Server Certificate Name: #{iam_server_cert.server_certificate_name} ID: #{iam_server_cert.server_certificate_id} Expiration Date: #{expiration_date}\" do\r\n      subject { expiration_date.to_s }\r\n      it { should be >= scan_date.to_s }\r\n    end\r\n  end\r\nend\r\n","source_location":{"ref":"./controls/iam_and_keys/2_01_iam_and_keys.rb","line":90},"id":"2_01_iam_server_cert_expired"},{"title":"2.2 - There should not be more than 1 AWS IAM Group with admin privileges.","desc":"This policy identifies IAM user groups which have attached\n  policies giving them admin access to resources and admin abilities to control\n  those resources. No more than 1 AWS IAM Group\n  should have administrator access permissions). The policy takes a list of all\n  groups on the system, and picks out policies that are attached to the group,\n  and then verifies that these policies do not grant admin actions for all\n  resources to more than one group on the system.","descriptions":{"default":"This policy identifies IAM user groups which have attached\n  policies giving them admin access to resources and admin abilities to control\n  those resources. No more than 1 AWS IAM Group\n  should have administrator access permissions). The policy takes a list of all\n  groups on the system, and picks out policies that are attached to the group,\n  and then verifies that these policies do not grant admin actions for all\n  resources to more than one group on the system."},"impact":0.5,"refs":[],"tags":{"sgs_wiki_url":"https://wiki.wdf.sap.corp/wiki/x/-0JAc","terraform_remediation":"  resource \"aws_iam_group_policy_attachment\" \"example_group_policy_attachment\" {\n    group      = <your group name>\n    policy_arn = <policy arn to attach with limited set of actions on limited resources>\n  }\n","tested_tf_version":"1.0.11","remediation_steps":"  1.  Log in to AWS console.\n  2.  Navigate to IAM service.\n  3.  Click on User Groups > AdminsGroup > Click on the Permissions tab > Click on AdministratorAccess > Click on the PolicyUsage Tab > Check the box in front of the AdminsGroup > Click on Detach OR Under 'Inline Policies' click on 'Edit Policy' or 'Remove Policy' and assign a limited permission.\n"},"code":"control '2_02_iam_group_admin_access' do\r\n  title '2.2 - There should not be more than 1 AWS IAM Group with admin privileges.'\r\n  desc 'This policy identifies IAM user groups which have attached\r\n  policies giving them admin access to resources and admin abilities to control\r\n  those resources. No more than 1 AWS IAM Group\r\n  should have administrator access permissions). The policy takes a list of all\r\n  groups on the system, and picks out policies that are attached to the group,\r\n  and then verifies that these policies do not grant admin actions for all\r\n  resources to more than one group on the system.'\r\n  tag sgs_wiki_url: 'https://wiki.wdf.sap.corp/wiki/x/-0JAc'\r\n  tag terraform_remediation: <<-EOF\r\n  resource \"aws_iam_group_policy_attachment\" \"example_group_policy_attachment\" {\r\n    group      = <your group name>\r\n    policy_arn = <policy arn to attach with limited set of actions on limited resources>\r\n  }\r\n  EOF\r\n  tag tested_tf_version: '1.0.11'\r\n\r\n  tag remediation_steps: <<-EOF\r\n  1.  Log in to AWS console.\r\n  2.  Navigate to IAM service.\r\n  3.  Click on User Groups > AdminsGroup > Click on the Permissions tab > Click on AdministratorAccess > Click on the PolicyUsage Tab > Check the box in front of the AdminsGroup > Click on Detach OR Under 'Inline Policies' click on 'Edit Policy' or 'Remove Policy' and assign a limited permission.\r\n  EOF\r\n\r\n  # List of groups with attached admin access policies\r\n  iam_admin_groups = []\r\n\r\n  aws_iam_groups.group_names.each do |group_name|\r\n    aws_iam_policies(only_attached: true).policy_names.each do |policy_name|\r\n      current_policy = aws_iam_policy(policy_name: policy_name)\r\n      next unless current_policy.attached_groups.include?(group_name)\r\n      if current_policy.has_statement?(Resource: '*', Action: '*', Effect: 'Allow')\r\n        iam_admin_groups.append(group_name)\r\n      end\r\n    end\r\n  end\r\n  describe iam_admin_groups do\r\n    its('count') { should be < 2 }\r\n  end\r\nend\r\n","source_location":{"ref":"./controls/iam_and_keys/2_02_iam_and_keys.rb","line":9},"id":"2_02_iam_group_admin_access"},{"title":"2.2 - AWS IAM Roles should not have administrator access permissions","desc":"This policy identifies IAM Roles which have attached and inline\n  policies giving them admin access to resources and admin abilities to control\n  those resources.","descriptions":{"default":"This policy identifies IAM Roles which have attached and inline\n  policies giving them admin access to resources and admin abilities to control\n  those resources."},"impact":0.5,"refs":[],"tags":{"sgs_wiki_url":"https://wiki.wdf.sap.corp/wiki/x/-0JAc","terraform_remediation":"  resource \"aws_iam_policy\" \"example_role_policy\" {\n    name = <your role name>\n\n    policy = jsonencode({\n      Version = \"2012-10-17\"\n      Statement = [\n        {\n          Action   = [<limited list of actions>]\n          Effect   = \"Allow\"\n          Resource = [<limited list of resources>]\n        },\n      ]\n    })\n  }\n","tested_tf_version":"1.0.11","remediation_steps":"  1.  Log in to AWS console.\n  2.  Navigate to IAM service (or search for IAM in the search bar).\n  3.  Click on Roles > Click on reported IAM role that caused the alert.\n  4.  Under Permissions policies, click on checkbox next to the permissions that has caused the alert > Click Remove.\n"},"code":"control '2_02_iam_role_admin_access' do\r\n  title '2.2 - AWS IAM Roles should not have administrator access permissions'\r\n  desc 'This policy identifies IAM Roles which have attached and inline\r\n  policies giving them admin access to resources and admin abilities to control\r\n  those resources.'\r\n  tag sgs_wiki_url: 'https://wiki.wdf.sap.corp/wiki/x/-0JAc'\r\n  tag terraform_remediation: <<-EOF\r\n  resource \"aws_iam_policy\" \"example_role_policy\" {\r\n    name = <your role name>\r\n\r\n    policy = jsonencode({\r\n      Version = \"2012-10-17\"\r\n      Statement = [\r\n        {\r\n          Action   = [<limited list of actions>]\r\n          Effect   = \"Allow\"\r\n          Resource = [<limited list of resources>]\r\n        },\r\n      ]\r\n    })\r\n  }\r\n  EOF\r\n  tag tested_tf_version: '1.0.11'\r\n\r\n  tag remediation_steps: <<-EOF\r\n  1.  Log in to AWS console.\r\n  2.  Navigate to IAM service (or search for IAM in the search bar).\r\n  3.  Click on Roles > Click on reported IAM role that caused the alert.\r\n  4.  Under Permissions policies, click on checkbox next to the permissions that has caused the alert > Click Remove.\r\n  EOF\r\n\r\n  excluded_roles = %w(stacksets-exec MsCrossAccountAccessRole OrganizationAccountAccessRole aws-sso-admin-role)\r\n\r\n  # Role Attached Policy\r\n  aws_iam_roles.where { excluded_roles.none? { |name| role_name.include?(name) } }.role_names.each do |role_name|\r\n    iam_role = aws_iam_role(role_name: role_name)\r\n    next if iam_role.attached_policy_names.nil? || iam_role.tags['BTP_IAM_Role'] == 'ADMIN'\r\n\r\n    iam_role.attached_policy_names.each do |policy_name|\r\n      describe aws_iam_policy(policy_name: policy_name) do\r\n        it { should_not have_statement(Resource: '*', Action: '*', Effect: 'Allow') }\r\n      end\r\n    end\r\n\r\n    # Role Inline Policy\r\n    iam_role.inline_policies.each do |policy_name|\r\n      describe aws_iam_inline_policy(role_name: role_name, policy_name: policy_name) do\r\n        it { should_not have_statement(Resource: '*', Action: '*', Effect: 'Allow') }\r\n      end\r\n    end\r\n  end\r\nend\r\n","source_location":{"ref":"./controls/iam_and_keys/2_02_iam_and_keys.rb","line":50},"id":"2_02_iam_role_admin_access"},{"title":"2.2 - AWS IAM Users should not have administrator access permissions","desc":"This policy identifies IAM users which have inline\n  policies giving them admin access to resources and admin abilities to control\n  those resources. According to the SGS policy: Ensure that your AWS users\n  do NOT have any administrative IAM permissions (either no IAM\n  access at all or only read-only IAM access).","descriptions":{"default":"This policy identifies IAM users which have inline\n  policies giving them admin access to resources and admin abilities to control\n  those resources. According to the SGS policy: Ensure that your AWS users\n  do NOT have any administrative IAM permissions (either no IAM\n  access at all or only read-only IAM access)."},"impact":0.5,"refs":[],"tags":{"sgs_wiki_url":"https://wiki.wdf.sap.corp/wiki/x/-0JAc","terraform_remediation":"  resource \"aws_iam_user_policy_attachment\" \"example_iam_user_policy_attachment\" {\n    user      = <iam user to attach policy to>\n    policy_arn = <policy arn to attach with limited set of actions on limited resources>\n  }\n","tested_tf_version":"1.0.11","remediation_steps":"  1.  Sign in to the AWS Management Console.\n  2.  Navigate to IAM dashboard (or search for IAM in the search bar).\n  3.  In the left navigation panel, select Users > Click on the privileged AWS IAM user that you want to reconfigure.\n  4.  On the IAM user Summary page, click on the Permissions tab.\n  5.  Find the AWS AdministratorAccess managed policy > Detach it from the selected IAM user by clicking the x icon next to the policy entry.\n  6.  Within the Detach policy dialog box, click Detach.\n"},"code":"control '2_02_iam_user_admin_access' do\r\n  title '2.2 - AWS IAM Users should not have administrator access permissions'\r\n  desc 'This policy identifies IAM users which have inline\r\n  policies giving them admin access to resources and admin abilities to control\r\n  those resources. According to the SGS policy: Ensure that your AWS users\r\n  do NOT have any administrative IAM permissions (either no IAM\r\n  access at all or only read-only IAM access).'\r\n  tag sgs_wiki_url: 'https://wiki.wdf.sap.corp/wiki/x/-0JAc'\r\n  tag terraform_remediation: <<-EOF\r\n  resource \"aws_iam_user_policy_attachment\" \"example_iam_user_policy_attachment\" {\r\n    user      = <iam user to attach policy to>\r\n    policy_arn = <policy arn to attach with limited set of actions on limited resources>\r\n  }\r\n  EOF\r\n  tag tested_tf_version: '1.0.11'\r\n\r\n  tag remediation_steps: <<-EOF\r\n  1.  Sign in to the AWS Management Console.\r\n  2.  Navigate to IAM dashboard (or search for IAM in the search bar).\r\n  3.  In the left navigation panel, select Users > Click on the privileged AWS IAM user that you want to reconfigure.\r\n  4.  On the IAM user Summary page, click on the Permissions tab.\r\n  5.  Find the AWS AdministratorAccess managed policy > Detach it from the selected IAM user by clicking the x icon next to the policy entry.\r\n  6.  Within the Detach policy dialog box, click Detach.\r\n  EOF\r\n\r\n  aws_iam_users.usernames.each do |user_name|\r\n    next if excluded_accounts.include?(user_name)\r\n\r\n    iam_user = aws_iam_user(user_name: user_name)\r\n    next if iam_user.inline_policy_names.empty?\r\n\r\n    iam_user.inline_policy_names.each do |policy_name|\r\n      describe aws_iam_inline_policy(user_name: user_name, policy_name: policy_name) do\r\n        it { should_not have_statement(Resource: '*', Action: '*', Effect: 'Allow') }\r\n      end\r\n    end\r\n  end\r\nend\r\n","source_location":{"ref":"./controls/iam_and_keys/2_02_iam_and_keys.rb","line":103},"id":"2_02_iam_user_admin_access"},{"title":"2.3 - AWS MFA should be enabled for IAM users","desc":"All root accounts/users and IAM administrators should have MFA enabled on their accounts","descriptions":{"default":"All root accounts/users and IAM administrators should have MFA enabled on their accounts"},"impact":0.5,"refs":[],"tags":{"sgs_control_hash":"8ae223887226fcbd01722703b9830086","sgs_wiki_url":"https://wiki.wdf.sap.corp/wiki/x/-0JAc","remediation_steps":"  1.  Sign in to AWS > Navigate to the IAM service (or search for IAM in the search bar).\n  2.  Under Access management > Click Users > Navigate to the user that was reported in the alert > Click on the user's name.\n  3.  Click on the Security Credentials tab > Under Security Credentials, check Assigned MFA Device (or click Manage) > Follow the instructions to enable MFA for the user.\n"},"code":"control '2_03_mfa_enabled' do\r\n  impact 0.5\r\n  title '2.3 - AWS MFA should be enabled for IAM users'\r\n  desc  'All root accounts/users and IAM administrators should have MFA enabled on their accounts\r\n'\r\n  tag sgs_control_hash: '8ae223887226fcbd01722703b9830086'\r\n  tag sgs_wiki_url: 'https://wiki.wdf.sap.corp/wiki/x/-0JAc'\r\n\r\n  tag remediation_steps: <<-EOF\r\n  1.  Sign in to AWS > Navigate to the IAM service (or search for IAM in the search bar).\r\n  2.  Under Access management > Click Users > Navigate to the user that was reported in the alert > Click on the user's name.\r\n  3.  Click on the Security Credentials tab > Under Security Credentials, check Assigned MFA Device (or click Manage) > Follow the instructions to enable MFA for the user.\r\n  EOF\r\n\r\n  # Retrieval of has_mfa_enabled\r\n  iam_users_lst = aws_iam_users\r\n  iam_users_lst.has_console_password\r\n  iam_users_lst.has_mfa_enabled\r\n\r\n  iam_users_lst.table.each do |user|\r\n    next unless user[:username] != 'azure-sync-user' && user[:has_console_password] == true\r\n    describe \"MFA device for #{user[:username]}\" do\r\n      subject { user[:mfa_devices][0] }\r\n      it { should_not be_empty }\r\n    end\r\n  end\r\nend\r\n","source_location":{"ref":"./controls/iam_and_keys/2_03_iam_and_keys.rb","line":3},"id":"2_03_mfa_enabled"},{"title":"3.6 - AWS Key Management Service (KMS) key rotation must be enabled","desc":"This control enforces for KMS keys to be rotated periodically. As a security best practice, it is recommended to rotate the keys\n  so that if a key is compromised, the underlying data encrypted with that key is still secure with new keys","descriptions":{"default":"This control enforces for KMS keys to be rotated periodically. As a security best practice, it is recommended to rotate the keys\n  so that if a key is compromised, the underlying data encrypted with that key is still secure with new keys"},"impact":0.8,"refs":[],"tags":{"sgs_wiki_url":"https://wiki.wdf.sap.corp/wiki/x/-0JAc","terraform_remediation":"  resource \"aws_kms_key\" \"example_key_rotation_enabled\" {\n    ...\n    enable_key_rotation     = true\n  }\n","tested_tf_version":"1.0.11","terraform_remediation_note":"Automation key rotation is not possible for asymmetric KMS keys. In this case, ensure that the key is manually rotated in alignment with SGS policies.","remediation_steps":"  1.  Login to AWS Console.\n  2.  Go to Key Management Services (or search for KMS in the search bar).\n  3.  In the left navigation pane, click Customer managed keys.\n  4.  Click on the key ID mentioned in the alert.\n  5.  Click on the Key Rotation tab.\n  6.  Select Rotate this key every year checkbox.\n  7.  Click Save.\n"},"code":"control '3_06_kms_key_rotation' do\r\n  title '3.6 - AWS Key Management Service (KMS) key rotation must be enabled'\r\n  impact 0.8\r\n  desc 'This control enforces for KMS keys to be rotated periodically. As a security best practice, it is recommended to rotate the keys\r\n  so that if a key is compromised, the underlying data encrypted with that key is still secure with new keys'\r\n  tag sgs_wiki_url: 'https://wiki.wdf.sap.corp/wiki/x/-0JAc'\r\n  tag terraform_remediation: <<-EOF\r\n  resource \"aws_kms_key\" \"example_key_rotation_enabled\" {\r\n    ...\r\n    enable_key_rotation     = true\r\n  }\r\n  EOF\r\n  tag tested_tf_version: '1.0.11'\r\n  tag terraform_remediation_note: 'Automation key rotation is not possible for asymmetric KMS keys. In this case, ensure that the key is manually rotated in alignment with SGS policies.'\r\n\r\n  tag remediation_steps: <<-EOF\r\n  1.  Login to AWS Console.\r\n  2.  Go to Key Management Services (or search for KMS in the search bar).\r\n  3.  In the left navigation pane, click Customer managed keys.\r\n  4.  Click on the key ID mentioned in the alert.\r\n  5.  Click on the Key Rotation tab.\r\n  6.  Select Rotate this key every year checkbox.\r\n  7.  Click Save.\r\n  EOF\r\n\r\n  aws_regions.region_names.each do |region_name|\r\n    aws_kms_keys(aws_region: region_name).key_ids.each do |key_id|\r\n      kms_key = aws_kms_key(aws_region: region_name, key_id: key_id)\r\n      next if (kms_key.enabled != true) ||\r\n              (kms_key.managed_by_aws? == true) ||\r\n              (kms_key.tags['policies.default.Id'] == 'DataCustodian')\r\n      if kms_key.external? ||\r\n         (kms_key.customer_master_key_spec != 'SYMMETRIC_DEFAULT') ||\r\n         (kms_key.origin == 'AWS_CLOUDHSM')\r\n        describe kms_key do\r\n          its('created_days_ago') { should be <= 365 }\r\n        end\r\n      else\r\n        describe kms_key do\r\n          it { should have_rotation_enabled }\r\n        end\r\n      end\r\n    end\r\n  end\r\nend\r\n","source_location":{"ref":"./controls/iam_and_keys/3_06_iam_and_keys.rb","line":1},"id":"3_06_kms_key_rotation"},{"title":"2 - SAP password policy must be enforced on Hyperscaler Org level","desc":"The Corporate Password policy (which is pushed by the SAP Multicloud Team into the Hyperscaler Account at creation time) must not be modified.\nTherefore all local users must have an \"SAP password policy\" compliant password.\nSetup the SAP Password Policy by configuring:\n  Check \"Requires at least one uppercase letter\"\n  Check \"Requires at least one lowercase letter\"\n  Check \"Requires at least one non-alphanumeric character\"\n  Check \"Requires at least one number\"\n  Set \"Minimum password length\" to 15 or greater\nSet the following settings if applicable for your use case:\n  Check \"Prevent password reuse\"\n  Set \"Number of passwords to remember\" to 15 or greater\n  Check \"Enable password expiration”\n  Set \"Password expiration period (in days):\" to 90 days or lesser","descriptions":{"default":"The Corporate Password policy (which is pushed by the SAP Multicloud Team into the Hyperscaler Account at creation time) must not be modified.\nTherefore all local users must have an \"SAP password policy\" compliant password.\nSetup the SAP Password Policy by configuring:\n  Check \"Requires at least one uppercase letter\"\n  Check \"Requires at least one lowercase letter\"\n  Check \"Requires at least one non-alphanumeric character\"\n  Check \"Requires at least one number\"\n  Set \"Minimum password length\" to 15 or greater\nSet the following settings if applicable for your use case:\n  Check \"Prevent password reuse\"\n  Set \"Number of passwords to remember\" to 15 or greater\n  Check \"Enable password expiration”\n  Set \"Password expiration period (in days):\" to 90 days or lesser"},"impact":0.8,"refs":[],"tags":{"sgs_control_hash":"8ae223887226fcbd01722703b9830002","sgs_wiki_url":"https://wiki.wdf.sap.corp/wiki/x/-0JAc","remediation_steps":"  All Hyperscaler Account's password policies are managed by Multicloud Hyperscaler Team.\n  Therefore any remediation action required for this policy should be contacted to Multicloud Hyperscaler Team via ServiceNow Ticket\n"},"code":"control 'ra_2_password_policy' do\r\n  impact 0.8\r\n  title '2 - SAP password policy must be enforced on Hyperscaler Org level'\r\n  desc 'The Corporate Password policy (which is pushed by the SAP Multicloud Team into the Hyperscaler Account at creation time) must not be modified.\r\nTherefore all local users must have an \"SAP password policy\" compliant password.\r\nSetup the SAP Password Policy by configuring:\r\n  Check \"Requires at least one uppercase letter\"\r\n  Check \"Requires at least one lowercase letter\"\r\n  Check \"Requires at least one non-alphanumeric character\"\r\n  Check \"Requires at least one number\"\r\n  Set \"Minimum password length\" to 15 or greater\r\nSet the following settings if applicable for your use case:\r\n  Check \"Prevent password reuse\"\r\n  Set \"Number of passwords to remember\" to 15 or greater\r\n  Check \"Enable password expiration”\r\n  Set \"Password expiration period (in days):\" to 90 days or lesser\r\n'\r\n  tag sgs_control_hash: '8ae223887226fcbd01722703b9830002'\r\n  tag sgs_wiki_url: 'https://wiki.wdf.sap.corp/wiki/x/-0JAc'\r\n\r\n  tag remediation_steps: <<-EOF\r\n  All Hyperscaler Account's password policies are managed by Multicloud Hyperscaler Team.\r\n  Therefore any remediation action required for this policy should be contacted to Multicloud Hyperscaler Team via ServiceNow Ticket\r\n  EOF\r\n\r\n  describe aws_iam_password_policy do\r\n    it { should exist }\r\n    it { should require_uppercase_characters }\r\n    it { should require_lowercase_characters }\r\n    it { should require_symbols }\r\n    it { should require_numbers }\r\n    its('minimum_password_length') { should be >= 15 }\r\n    it { should prevent_password_reuse }\r\n    its('number_of_passwords_to_remember') { should be >= 15 }\r\n    its('max_password_age_in_days') { should be <= 90 }\r\n  end\r\nend\r\n","source_location":{"ref":"./controls/iam_and_keys/ra_2_iam_and_keys.rb","line":1},"id":"ra_2_password_policy"},{"title":"5.3 - AWS SNS Subscription should use HTTPS Delivery Protocol","desc":"HTTPS as a delivery protocol should always be used by all AWS fully managed services like SNS subscriptions as well. This can be achieved by implementing secure SNS topic policies.","descriptions":{"default":"HTTPS as a delivery protocol should always be used by all AWS fully managed services like SNS subscriptions as well. This can be achieved by implementing secure SNS topic policies."},"impact":0.5,"refs":[],"tags":{"sgs_wiki_url":"https://wiki.wdf.sap.corp/wiki/x/-0JAc","terraform_remediation":"  resource \"aws_sns_topic_subscription\" \"example_subscription\" {\n    ...\n    protocol = <protocol here>\n    ...\n  }\n","tested_tf_version":"1.0.11","terraform_remediation_note":"The protocol listed above must not be http","remediation_steps":"  1.  Sign in to the AWS Management Console.\n  2.  Navigate to SNS dashboard (or search for SNS in the search bar).\n  3.  In the navigation panel, under SNS Dashboard, click Subscriptions.\n  4.  Click on the subscription ID that you want to change > Copy the Topic ARN value and the subscription Endpoint.\n  5.  Click Subscriptions > Click Create subscription button.\n  6.  Within Create subscription dialog box, please do the following steps:\n\n        a.  Inside the Topic ARN box, paste the SNS topic ARN that you copied at step #4.\n\n        b.  Select HTTPS from the Protocol dropdown list.\n\n        c.  Paste the URL endpoint that you copied at step #4 in the Endpoint box.\n\n        d.  Click Create Subscription to generate the new SNS subscription.\n\n        e.  Click Close.\n  7.  Once your new SNS subscription is confirmed, you can remove the original subscription by performing the following steps:\n\n        a.  Click the circle by the subscription ID that you want to delete.\n\n        b.  Click Delete.\n\n        c.  Inside the Delete dialog box, review the details > Click Delete.\n"},"code":"control '5_03_sns_subscription_using_secure_protocol' do\r\n  title '5.3 - AWS SNS Subscription should use HTTPS Delivery Protocol'\r\n  desc 'HTTPS as a delivery protocol should always be used by all AWS fully managed services like SNS subscriptions as well. This can be achieved by implementing secure SNS topic policies.'\r\n  tag sgs_wiki_url: 'https://wiki.wdf.sap.corp/wiki/x/-0JAc'\r\n  tag terraform_remediation: <<-EOF\r\n  resource \"aws_sns_topic_subscription\" \"example_subscription\" {\r\n    ...\r\n    protocol = <protocol here>\r\n    ...\r\n  }\r\n  EOF\r\n  tag tested_tf_version: '1.0.11'\r\n  tag terraform_remediation_note: 'The protocol listed above must not be http'\r\n\r\n  tag remediation_steps: <<-EOF\r\n  1.  Sign in to the AWS Management Console.\r\n  2.  Navigate to SNS dashboard (or search for SNS in the search bar).\r\n  3.  In the navigation panel, under SNS Dashboard, click Subscriptions.\r\n  4.  Click on the subscription ID that you want to change > Copy the Topic ARN value and the subscription Endpoint.\r\n  5.  Click Subscriptions > Click Create subscription button.\r\n  6.  Within Create subscription dialog box, please do the following steps:\r\n\r\n        a.  Inside the Topic ARN box, paste the SNS topic ARN that you copied at step #4.\r\n\r\n        b.  Select HTTPS from the Protocol dropdown list.\r\n\r\n        c.  Paste the URL endpoint that you copied at step #4 in the Endpoint box.\r\n\r\n        d.  Click Create Subscription to generate the new SNS subscription.\r\n\r\n        e.  Click Close.\r\n  7.  Once your new SNS subscription is confirmed, you can remove the original subscription by performing the following steps:\r\n\r\n        a.  Click the circle by the subscription ID that you want to delete.\r\n\r\n        b.  Click Delete.\r\n\r\n        c.  Inside the Delete dialog box, review the details > Click Delete.\r\n  EOF\r\n\r\n  aws_regions.region_names.each do |region_name|\r\n    aws_sns_subscriptions(aws_region: region_name).subscription_arns.each do |sub_arn|\r\n      describe aws_sns_subscription(aws_region: region_name, subscription_arn: sub_arn) do\r\n        its('protocol') { should_not cmp 'http' }\r\n      end\r\n    end\r\n  end\r\nend\r\n","source_location":{"ref":"./controls/networks/5_03_networks.rb","line":1},"id":"5_03_sns_subscription_using_secure_protocol"},{"title":"6.1.1 - AWS Security Group must restrict traffic from the internet to DB ports on the blocklist","desc":"This policy identifies all the security groups, which do not restrict inbound traffic to the\n  following ports: (1433, 1434, 1521, 3306, 4333, 5432, 27017).","descriptions":{"default":"This policy identifies all the security groups, which do not restrict inbound traffic to the\n  following ports: (1433, 1434, 1521, 3306, 4333, 5432, 27017)."},"impact":0.8,"refs":[],"tags":{"sgs_wiki_url":"https://wiki.wdf.sap.corp/wiki/x/-0JAc","terraform_remediation":"  resource \"aws_security_group\" \"example_security_group\" {\n    ...\n    vpc_id      = <vpc id of vpc to apply the security group to>\n  }\n\n  resource \"aws_security_group_rule\" \"example_security_group_rule\" {\n    type      = \"ingress\"\n    from_port = <relevant port>\n    to_port   = <relevant port>\n    protocol  = <specific protocol>\n    cidr_blocks = <list of allowed IP CIDRs>\n    security_group_id = aws_security_group.example_security_group.id\n  }\n","tested_tf_version":"1.0.11","terraform_remediation_note":"Any rules which allow ingress from the CIDR ranges 0.0.0.0/0 or ::/0 will fail this control. Be sure to base your ingress CIDR blocks only on IP addresses that are required.","remediation_steps":"  1.  Log into to the AWS Management Console > Go to Network & Security and select Security Groups (or search for Security Group in the search bar).\n  2.  Navigate to the security group for which the alert is raised.\n  3.  Navigate to the inbound rules > Click on Edit Inbound rules > Ensure CIDR block 0.0.0.0/0 or ::/0 is not bound to any of the following ports: 5432, 3306, 4333, 1521, 27017, 1433, 1434 OR any ports mentioned in [6.1.1 Firewall Rules for DB ports] SGS hardening guidelines > Save rules.\n"},"code":"control '6_01_01_db_ports' do\r\n  title '6.1.1 - AWS Security Group must restrict traffic from the internet to DB ports on the blocklist'\r\n  impact 0.8\r\n  desc 'This policy identifies all the security groups, which do not restrict inbound traffic to the\r\n  following ports: (1433, 1434, 1521, 3306, 4333, 5432, 27017).'\r\n  tag sgs_wiki_url: 'https://wiki.wdf.sap.corp/wiki/x/-0JAc'\r\n  tag terraform_remediation: <<-EOF\r\n  resource \"aws_security_group\" \"example_security_group\" {\r\n    ...\r\n    vpc_id      = <vpc id of vpc to apply the security group to>\r\n  }\r\n\r\n  resource \"aws_security_group_rule\" \"example_security_group_rule\" {\r\n    type      = \"ingress\"\r\n    from_port = <relevant port>\r\n    to_port   = <relevant port>\r\n    protocol  = <specific protocol>\r\n    cidr_blocks = <list of allowed IP CIDRs>\r\n    security_group_id = aws_security_group.example_security_group.id\r\n  }\r\n  EOF\r\n  tag tested_tf_version: '1.0.11'\r\n  tag terraform_remediation_note: 'Any rules which allow ingress from the CIDR ranges 0.0.0.0/0 or ::/0 will fail this control. Be sure to base your ingress CIDR blocks only on IP addresses that are required.'\r\n\r\n  tag remediation_steps: <<-EOF\r\n  1.  Log into to the AWS Management Console > Go to Network & Security and select Security Groups (or search for Security Group in the search bar).\r\n  2.  Navigate to the security group for which the alert is raised.\r\n  3.  Navigate to the inbound rules > Click on Edit Inbound rules > Ensure CIDR block 0.0.0.0/0 or ::/0 is not bound to any of the following ports: 5432, 3306, 4333, 1521, 27017, 1433, 1434 OR any ports mentioned in [6.1.1 Firewall Rules for DB ports] SGS hardening guidelines > Save rules.\r\n  EOF\r\n\r\n  aws_regions.region_names.each do |region_name|\r\n    aws_security_groups(aws_region: region_name).group_names.each do |group_name|\r\n      sg = aws_security_group(aws_region: region_name, group_name: group_name)\r\n      if sg.tags.any? && (sg.tags.keys).include?('sec-by-def-network-exception')\r\n        next if sg.tags['sec-by-def-network-exception'].match('PostgreSQL') || sg.tags['sec-by-def-network-exception'].match('MySQL') ||\r\n                sg.tags['sec-by-def-network-exception'].match('MSSQL') || sg.tags['sec-by-def-network-exception'].match('OracleSQL') ||\r\n                sg.tags['sec-by-def-network-exception'].match('MongoDB')\r\n      end\r\n      describe sg do\r\n        [5432, 3306, 4333, 1521, 27017, 1433, 1434].each do |db_port|\r\n          it { should_not allow_in(port: db_port, ipv4_range: '0.0.0.0/0') }\r\n          it { should_not allow_in(port: db_port, ipv6_range: '::/0') }\r\n        end\r\n      end\r\n    end\r\n  end\r\nend\r\n","source_location":{"ref":"./controls/networks/6_01_01_networks.rb","line":1},"id":"6_01_01_db_ports"},{"title":"6.1.2 - AWS Security Group must restrict traffic from the internet to admin ports on the blocklist","desc":"This policy identifies all the security groups, which do not restrict inbound traffic\n  to the following admin ports: (22, 3389, 135, 514, 5500, 5900).","descriptions":{"default":"This policy identifies all the security groups, which do not restrict inbound traffic\n  to the following admin ports: (22, 3389, 135, 514, 5500, 5900)."},"impact":0.8,"refs":[],"tags":{"sgs_wiki_url":"https://wiki.wdf.sap.corp/wiki/x/-0JAc","terraform_remediation":"  resource \"aws_security_group\" \"example_security_group\" {\n    ...\n    vpc_id      = <vpc id of vpc to apply the security group to>\n  }\n\n  resource \"aws_security_group_rule\" \"example_security_group_rule\" {\n    type      = \"ingress\"\n    from_port = <relevant port>\n    to_port   = <relevant port>\n    protocol  = <specific protocol>\n    cidr_blocks = <list of allowed IP CIDRs>\n    security_group_id = aws_security_group.example_security_group.id\n  }\n","tested_tf_version":"1.0.11","terraform_remediation_note":"Any rules which allow ingress from the CIDR ranges 0.0.0.0/0 or ::/0 will fail this control. Be sure to base your ingress CIDR blocks only on IP addresses that are required.","remediation_steps":"  1.  Log into to the AWS Management Console > Go to Network & Security and select Security Groups (or search for Security Group in the search bar).\n  2.  Navigate to the security group for which the alert is raised.\n  3.  Navigate to the inbound rules > Click on Edit Inbound rules > Ensure CIDR block 0.0.0.0/0 or ::/0 is not bound to any of the following ports: 3389, 22, 5500, 5900, 135, 514 OR any ports mentioned in [6.1.2 Firewall Rules for ADMIN ports] SGS hardening guidelines > Save rules.\n"},"code":"control '6_01_02_admin_ports' do\r\n  title '6.1.2 - AWS Security Group must restrict traffic from the internet to admin ports on the blocklist'\r\n  impact 0.8\r\n  desc 'This policy identifies all the security groups, which do not restrict inbound traffic\r\n  to the following admin ports: (22, 3389, 135, 514, 5500, 5900).'\r\n  tag sgs_wiki_url: 'https://wiki.wdf.sap.corp/wiki/x/-0JAc'\r\n  tag terraform_remediation: <<-EOF\r\n  resource \"aws_security_group\" \"example_security_group\" {\r\n    ...\r\n    vpc_id      = <vpc id of vpc to apply the security group to>\r\n  }\r\n\r\n  resource \"aws_security_group_rule\" \"example_security_group_rule\" {\r\n    type      = \"ingress\"\r\n    from_port = <relevant port>\r\n    to_port   = <relevant port>\r\n    protocol  = <specific protocol>\r\n    cidr_blocks = <list of allowed IP CIDRs>\r\n    security_group_id = aws_security_group.example_security_group.id\r\n  }\r\n  EOF\r\n  tag tested_tf_version: '1.0.11'\r\n  tag terraform_remediation_note: 'Any rules which allow ingress from the CIDR ranges 0.0.0.0/0 or ::/0 will fail this control. Be sure to base your ingress CIDR blocks only on IP addresses that are required.'\r\n\r\n  tag remediation_steps: <<-EOF\r\n  1.  Log into to the AWS Management Console > Go to Network & Security and select Security Groups (or search for Security Group in the search bar).\r\n  2.  Navigate to the security group for which the alert is raised.\r\n  3.  Navigate to the inbound rules > Click on Edit Inbound rules > Ensure CIDR block 0.0.0.0/0 or ::/0 is not bound to any of the following ports: 3389, 22, 5500, 5900, 135, 514 OR any ports mentioned in [6.1.2 Firewall Rules for ADMIN ports] SGS hardening guidelines > Save rules.\r\n  EOF\r\n\r\n  aws_regions.region_names.each do |region_name|\r\n    aws_security_groups(aws_region: region_name).group_names.each do |group_name|\r\n      sg = aws_security_group(aws_region: region_name, group_name: group_name)\r\n      if sg.tags.any? && (sg.tags.keys).include?('sec-by-def-network-exception')\r\n        next if sg.tags['sec-by-def-network-exception'].match('SSH') || sg.tags['sec-by-def-network-exception'].match('RDP') ||\r\n                sg.tags['sec-by-def-network-exception'].match('VNC') || sg.tags['sec-by-def-network-exception'].match('RPC') ||\r\n                sg.tags['sec-by-def-network-exception'].match('RSH')\r\n      end\r\n      describe sg do\r\n        [3389, 22, 5500, 5900, 135, 514].each do |admin_port|\r\n          it { should_not allow_in(port: admin_port, ipv4_range: '0.0.0.0/0') }\r\n          it { should_not allow_in(port: admin_port, ipv6_range: '::/0') }\r\n        end\r\n      end\r\n    end\r\n  end\r\nend\r\n","source_location":{"ref":"./controls/networks/6_01_02_networks.rb","line":1},"id":"6_01_02_admin_ports"},{"title":"6.1.3 - AWS Security Group should restrict traffic from the internet to infrastructure ports on the blocklist","desc":"This policy identifies all the security groups, which do not restrict inbound traffic\n  to the following ports: (25, 53, 67, 68, 110, 161, 162).","descriptions":{"default":"This policy identifies all the security groups, which do not restrict inbound traffic\n  to the following ports: (25, 53, 67, 68, 110, 161, 162)."},"impact":0.5,"refs":[],"tags":{"sgs_wiki_url":"https://wiki.wdf.sap.corp/wiki/x/-0JAc","terraform_remediation":"  resource \"aws_security_group\" \"example_security_group\" {\n    ...\n    vpc_id      = <vpc id of vpc to apply the security group to>\n  }\n\n  resource \"aws_security_group_rule\" \"example_security_group_rule\" {\n    type      = \"ingress\"\n    from_port = <relevant port>\n    to_port   = <relevant port>\n    protocol  = <specific protocol>\n    cidr_blocks = <list of allowed IP CIDRs>\n    security_group_id = aws_security_group.example_security_group.id\n  }\n","tested_tf_version":"1.0.11","terraform_remediation_note":"Any rules which allow ingress from the CIDR ranges 0.0.0.0/0 or ::/0 will fail this control. Be sure to base your ingress CIDR blocks only on IP addresses that are required.","remediation_steps":"  1.  Log into to the AWS Management Console > Go to Network & Security and select Security Groups (or search for Security Group in the search bar).\n  2.  Navigate to the security group for which the alert is raised.\n  3.  Navigate to the inbound rules > Click on Edit Inbound rules > Ensure CIDR block 0.0.0.0/0 or ::/0 is not bound to any of the following ports: 53, 110, 25, 67, 68, 161, 162 OR any ports mentioned in [6.1.3 Firewall Rules for Infrastructure ports] SGS hardening guidelines > Save rules.\n"},"code":"control '6_01_03_infra_ports' do\r\n  title '6.1.3 - AWS Security Group should restrict traffic from the internet to infrastructure ports on the blocklist'\r\n  impact 0.5\r\n  desc 'This policy identifies all the security groups, which do not restrict inbound traffic\r\n  to the following ports: (25, 53, 67, 68, 110, 161, 162).'\r\n  tag sgs_wiki_url: 'https://wiki.wdf.sap.corp/wiki/x/-0JAc'\r\n  tag terraform_remediation: <<-EOF\r\n  resource \"aws_security_group\" \"example_security_group\" {\r\n    ...\r\n    vpc_id      = <vpc id of vpc to apply the security group to>\r\n  }\r\n\r\n  resource \"aws_security_group_rule\" \"example_security_group_rule\" {\r\n    type      = \"ingress\"\r\n    from_port = <relevant port>\r\n    to_port   = <relevant port>\r\n    protocol  = <specific protocol>\r\n    cidr_blocks = <list of allowed IP CIDRs>\r\n    security_group_id = aws_security_group.example_security_group.id\r\n  }\r\n  EOF\r\n  tag tested_tf_version: '1.0.11'\r\n  tag terraform_remediation_note: 'Any rules which allow ingress from the CIDR ranges 0.0.0.0/0 or ::/0 will fail this control. Be sure to base your ingress CIDR blocks only on IP addresses that are required.'\r\n\r\n  tag remediation_steps: <<-EOF\r\n  1.  Log into to the AWS Management Console > Go to Network & Security and select Security Groups (or search for Security Group in the search bar).\r\n  2.  Navigate to the security group for which the alert is raised.\r\n  3.  Navigate to the inbound rules > Click on Edit Inbound rules > Ensure CIDR block 0.0.0.0/0 or ::/0 is not bound to any of the following ports: 53, 110, 25, 67, 68, 161, 162 OR any ports mentioned in [6.1.3 Firewall Rules for Infrastructure ports] SGS hardening guidelines > Save rules.\r\n  EOF\r\n\r\n  aws_regions.region_names.each do |region_name|\r\n    aws_security_groups(aws_region: region_name).group_names.each do |group_name|\r\n      sg = aws_security_group(aws_region: region_name, group_name: group_name)\r\n      if sg.tags.any? && (sg.tags.keys).include?('sec-by-def-network-exception')\r\n        next if sg.tags['sec-by-def-network-exception'].match('DNS')  || sg.tags['sec-by-def-network-exception'].match('HTTP') ||\r\n                sg.tags['sec-by-def-network-exception'].match('POP3') || sg.tags['sec-by-def-network-exception'].match('SMTP') ||\r\n                sg.tags['sec-by-def-network-exception'].match('DHCP') || sg.tags['sec-by-def-network-exception'].match('SNMP')\r\n      end\r\n      describe sg do\r\n        [53, 110, 25, 67, 68, 161, 162].each do |infra_port|\r\n          it { should_not allow_in(port: infra_port, ipv4_range: '0.0.0.0/0') }\r\n          it { should_not allow_in(port: infra_port, ipv6_range: '::/0') }\r\n        end\r\n      end\r\n    end\r\n  end\r\nend\r\n","source_location":{"ref":"./controls/networks/6_01_03_networks.rb","line":1},"id":"6_01_03_infra_ports"},{"title":"6.1.4 - AWS Security Group should restrict traffic from the internet to file sharing ports on the blocklist","desc":"This policy identifies all the security groups, which do not restrict inbound traffic\n  to the following ports: (139, 445, 21, 69).","descriptions":{"default":"This policy identifies all the security groups, which do not restrict inbound traffic\n  to the following ports: (139, 445, 21, 69)."},"impact":0.5,"refs":[],"tags":{"sgs_wiki_url":"https://wiki.wdf.sap.corp/wiki/x/-0JAc","terraform_remediation":"  resource \"aws_security_group\" \"example_security_group\" {\n    ...\n    vpc_id      = <vpc id of vpc to apply the security group to>\n  }\n\n  resource \"aws_security_group_rule\" \"example_security_group_rule\" {\n    type      = \"ingress\"\n    from_port = <relevant port>\n    to_port   = <relevant port>\n    protocol  = <specific protocol>\n    cidr_blocks = <list of allowed IP CIDRs>\n    security_group_id = aws_security_group.example_security_group.id\n  }\n","tested_tf_version":"1.0.11","terraform_remediation_note":"Any rules which allow ingress from the CIDR ranges 0.0.0.0/0 or ::/0 will fail this control. Be sure to base your ingress CIDR blocks only on IP addresses that are required.","remediation_steps":"  1.  Log into to the AWS Management Console > Go to Network & Security and select Security Groups (or search for Security Group in the search bar).\n  2.  Navigate to the security group for which the alert is raised.\n  3.  Navigate to the inbound rules > Click on Edit Inbound rules > Ensure CIDR block 0.0.0.0/0 or ::/0 is not bound to any of the following ports: 139, 445, 21, 69 OR any ports mentioned in [6.1.4 Firewall Rules for Fileshare ports] SGS hardening guidelines > Save rules.\n"},"code":"control '6_01_04_fileshare_ports' do\r\n  title '6.1.4 - AWS Security Group should restrict traffic from the internet to file sharing ports on the blocklist'\r\n  impact 0.5\r\n  desc 'This policy identifies all the security groups, which do not restrict inbound traffic\r\n  to the following ports: (139, 445, 21, 69).'\r\n  tag sgs_wiki_url: 'https://wiki.wdf.sap.corp/wiki/x/-0JAc'\r\n  tag terraform_remediation: <<-EOF\r\n  resource \"aws_security_group\" \"example_security_group\" {\r\n    ...\r\n    vpc_id      = <vpc id of vpc to apply the security group to>\r\n  }\r\n\r\n  resource \"aws_security_group_rule\" \"example_security_group_rule\" {\r\n    type      = \"ingress\"\r\n    from_port = <relevant port>\r\n    to_port   = <relevant port>\r\n    protocol  = <specific protocol>\r\n    cidr_blocks = <list of allowed IP CIDRs>\r\n    security_group_id = aws_security_group.example_security_group.id\r\n  }\r\n  EOF\r\n  tag tested_tf_version: '1.0.11'\r\n  tag terraform_remediation_note: 'Any rules which allow ingress from the CIDR ranges 0.0.0.0/0 or ::/0 will fail this control. Be sure to base your ingress CIDR blocks only on IP addresses that are required.'\r\n\r\n  tag remediation_steps: <<-EOF\r\n  1.  Log into to the AWS Management Console > Go to Network & Security and select Security Groups (or search for Security Group in the search bar).\r\n  2.  Navigate to the security group for which the alert is raised.\r\n  3.  Navigate to the inbound rules > Click on Edit Inbound rules > Ensure CIDR block 0.0.0.0/0 or ::/0 is not bound to any of the following ports: 139, 445, 21, 69 OR any ports mentioned in [6.1.4 Firewall Rules for Fileshare ports] SGS hardening guidelines > Save rules.\r\n  EOF\r\n\r\n  aws_regions.region_names.each do |region_name|\r\n    aws_security_groups(aws_region: region_name).group_names.each do |group_name|\r\n      sg = aws_security_group(aws_region: region_name, group_name: group_name)\r\n      if sg.tags.any? && (sg.tags.keys).include?('sec-by-def-network-exception')\r\n        next if sg.tags['sec-by-def-network-exception'].match('NetBIOS') || sg.tags['sec-by-def-network-exception'].match('SMB') ||\r\n                sg.tags['sec-by-def-network-exception'].match('FTP') || sg.tags['sec-by-def-network-exception'].match('TFTP')\r\n      end\r\n      describe sg do\r\n        [139, 445, 21, 69].each do |file_port|\r\n          it { should_not allow_in(port: file_port, ipv4_range: '0.0.0.0/0') }\r\n          it { should_not allow_in(port: file_port, ipv6_range: '::/0') }\r\n        end\r\n      end\r\n    end\r\n  end\r\nend\r\n","source_location":{"ref":"./controls/networks/6_01_04_networks.rb","line":1},"id":"6_01_04_fileshare_ports"},{"title":"6.1.5 - AWS Security Group must restrict traffic from the internet to telnet ports on the blocklist","desc":"This policy identifies all the security groups which do not restrict inbound traffic\n  to the following port: (23).","descriptions":{"default":"This policy identifies all the security groups which do not restrict inbound traffic\n  to the following port: (23)."},"impact":0.8,"refs":[],"tags":{"sgs_wiki_url":"https://wiki.wdf.sap.corp/wiki/x/-0JAc","terraform_remediation":"  resource \"aws_security_group\" \"example_security_group\" {\n    ...\n    vpc_id      = <vpc id of vpc to apply the security group to>\n  }\n\n  resource \"aws_security_group_rule\" \"example_security_group_rule\" {\n    type      = \"ingress\"\n    from_port = <relevant port>\n    to_port   = <relevant port>\n    protocol  = <specific protocol>\n    cidr_blocks = <list of allowed IP CIDRs>\n    security_group_id = aws_security_group.example_security_group.id\n  }\n","tested_tf_version":"1.0.11","terraform_remediation_note":"Any rules which allow ingress from the CIDR ranges 0.0.0.0/0 or ::/0 will fail this control. Be sure to base your ingress CIDR blocks only on IP addresses that are required.","remediation_steps":"  1.  Log into to the AWS Management Console > Go to Network & Security and select Security Groups (or search for Security Group in the search bar).\n  2.  Navigate to the security group for which the alert is raised.\n  3.  Navigate to the inbound rules > Click on Edit Inbound rules > Ensure CIDR block 0.0.0.0/0 or ::/0 is not bound to any of the following ports: 23 OR any ports mentioned in [6.1.5 Firewall Rules for telnet and rsh ports] SGS hardening guidelines > Save rules.\n"},"code":"control '6_01_05_telnet_ports' do\r\n  title '6.1.5 - AWS Security Group must restrict traffic from the internet to telnet ports on the blocklist'\r\n  impact 0.8\r\n  desc 'This policy identifies all the security groups which do not restrict inbound traffic\r\n  to the following port: (23).'\r\n  tag sgs_wiki_url: 'https://wiki.wdf.sap.corp/wiki/x/-0JAc'\r\n  tag terraform_remediation: <<-EOF\r\n  resource \"aws_security_group\" \"example_security_group\" {\r\n    ...\r\n    vpc_id      = <vpc id of vpc to apply the security group to>\r\n  }\r\n\r\n  resource \"aws_security_group_rule\" \"example_security_group_rule\" {\r\n    type      = \"ingress\"\r\n    from_port = <relevant port>\r\n    to_port   = <relevant port>\r\n    protocol  = <specific protocol>\r\n    cidr_blocks = <list of allowed IP CIDRs>\r\n    security_group_id = aws_security_group.example_security_group.id\r\n  }\r\n  EOF\r\n  tag tested_tf_version: '1.0.11'\r\n  tag terraform_remediation_note: 'Any rules which allow ingress from the CIDR ranges 0.0.0.0/0 or ::/0 will fail this control. Be sure to base your ingress CIDR blocks only on IP addresses that are required.'\r\n\r\n  tag remediation_steps: <<-EOF\r\n  1.  Log into to the AWS Management Console > Go to Network & Security and select Security Groups (or search for Security Group in the search bar).\r\n  2.  Navigate to the security group for which the alert is raised.\r\n  3.  Navigate to the inbound rules > Click on Edit Inbound rules > Ensure CIDR block 0.0.0.0/0 or ::/0 is not bound to any of the following ports: 23 OR any ports mentioned in [6.1.5 Firewall Rules for telnet and rsh ports] SGS hardening guidelines > Save rules.\r\n  EOF\r\n\r\n  aws_regions.region_names.each do |region_name|\r\n    aws_security_groups(aws_region: region_name).group_names.each do |group_name|\r\n      sg = aws_security_group(aws_region: region_name, group_name: group_name)\r\n      next if sg.tags['sec-by-def-network-exception'] == 'Telnet'\r\n      describe sg do\r\n        it { should_not allow_in(port: 23, ipv4_range: '0.0.0.0/0') }\r\n        it { should_not allow_in(port: 23, ipv6_range: '::/0') }\r\n      end\r\n    end\r\n  end\r\nend\r\n","source_location":{"ref":"./controls/networks/6_01_05_networks.rb","line":1},"id":"6_01_05_telnet_ports"},{"title":"6.3 - AWS Elastic Load Balancer (Classic) access log should be enabled","desc":"This control identifies Classic Elastic Load Balancers which have access log disabled.\n  When Access log enabled, Classic load balancer captures detailed information about requests sent to your load balancer. This information consists of\n  the client IP address, latencies, request paths, and server responses. These logs can be used to analyze traffic patterns and to troubleshoot issues.","descriptions":{"default":"This control identifies Classic Elastic Load Balancers which have access log disabled.\n  When Access log enabled, Classic load balancer captures detailed information about requests sent to your load balancer. This information consists of\n  the client IP address, latencies, request paths, and server responses. These logs can be used to analyze traffic patterns and to troubleshoot issues."},"impact":0.5,"refs":[],"tags":{"sgs_wiki_url":"https://wiki.wdf.sap.corp/wiki/x/-0JAc","terraform_remediation":"  resource \"aws_elb\" \"example_elb_access_log\" {\n    ...\n    \"access_logs\" {\n      bucket = <the logging bucket>\n      enabled = true\n    }\n  }\n","tested_tf_version":"1.0.11","remediation_steps":"  1.  Sign into the AWS console.\n  2.  Navigate to EC2 dashboard (or search for EC2 in the search bar).\n  3.  Click on Load Balancers on the left hand side of the screen > Click on the name of the Load Balancer that caused the alert.\n  4.  On the Description tab, click 'Configure Access Logs'.\n  5.  On the 'Configure Access Logs' popup dialog, please do the following steps:\n        5a.   Select 'Enable access logs'.\n        5b.   Choose Interval time; default is 60 minutes.\n        5c.   For S3 location, enter the name of your S3 bucket, including the prefix (for example, sap-loadbalancer-logs/my-app). You can enter the name of an existing bucket or enter a name for a new bucket.\n        Please note: If the bucket does not exist, select 'Create this location for me'. You must enter a name that is unique across all existing bucket names in Amazon S3 and it must also follow the DNS naming conventions. The new S3 bucket must be in the same region as the load balancer.\n  6.  Click 'Save'.\n"},"code":"control '6_03_elb_access_logging' do\r\n  title '6.3 - AWS Elastic Load Balancer (Classic) access log should be enabled'\r\n  impact 0.5\r\n  desc 'This control identifies Classic Elastic Load Balancers which have access log disabled.\r\n  When Access log enabled, Classic load balancer captures detailed information about requests sent to your load balancer. This information consists of\r\n  the client IP address, latencies, request paths, and server responses. These logs can be used to analyze traffic patterns and to troubleshoot issues.'\r\n  tag sgs_wiki_url: 'https://wiki.wdf.sap.corp/wiki/x/-0JAc'\r\n  tag terraform_remediation: <<-EOF\r\n  resource \"aws_elb\" \"example_elb_access_log\" {\r\n    ...\r\n    \"access_logs\" {\r\n      bucket = <the logging bucket>\r\n      enabled = true\r\n    }\r\n  }\r\n  EOF\r\n  tag tested_tf_version: '1.0.11'\r\n\r\n  tag remediation_steps: <<-EOF\r\n  1.  Sign into the AWS console.\r\n  2.  Navigate to EC2 dashboard (or search for EC2 in the search bar).\r\n  3.  Click on Load Balancers on the left hand side of the screen > Click on the name of the Load Balancer that caused the alert.\r\n  4.  On the Description tab, click 'Configure Access Logs'.\r\n  5.  On the 'Configure Access Logs' popup dialog, please do the following steps:\r\n        5a.   Select 'Enable access logs'.\r\n        5b.   Choose Interval time; default is 60 minutes.\r\n        5c.   For S3 location, enter the name of your S3 bucket, including the prefix (for example, sap-loadbalancer-logs/my-app). You can enter the name of an existing bucket or enter a name for a new bucket.\r\n        Please note: If the bucket does not exist, select 'Create this location for me'. You must enter a name that is unique across all existing bucket names in Amazon S3 and it must also follow the DNS naming conventions. The new S3 bucket must be in the same region as the load balancer.\r\n  6.  Click 'Save'.\r\n  EOF\r\n\r\n  aws_regions.region_names.each do |region_name|\r\n    aws_elbs(aws_region: region_name).load_balancer_names.each do |load_balancer|\r\n      elb = aws_elb(aws_region: region_name, load_balancer_name: load_balancer)\r\n      next if elb.certificate_id.count(nil) == elb.certificate_id.count\r\n\r\n      describe elb do\r\n        it { should be_access_log_enabled }\r\n      end\r\n    end\r\n  end\r\nend\r\n","source_location":{"ref":"./controls/networks/6_03_networks.rb","line":1},"id":"6_03_elb_access_logging"},{"title":"6.3 - AWS Elastic Load Balancer v2 access log should be enabled","desc":"This control identifies Elastic Load Balancers which have access log disabled. When Access log is enabled, ELBv2 load balancer captures detailed information about requests sent to your load balancer. This information consists of the client IP address, latencies, request paths, and server responses. These logs can be used to analyze traffic patterns and to troubleshoot issues.","descriptions":{"default":"This control identifies Elastic Load Balancers which have access log disabled. When Access log is enabled, ELBv2 load balancer captures detailed information about requests sent to your load balancer. This information consists of the client IP address, latencies, request paths, and server responses. These logs can be used to analyze traffic patterns and to troubleshoot issues."},"impact":0.5,"refs":[],"tags":{"sgs_wiki_url":"https://wiki.wdf.sap.corp/wiki/x/-0JAc","terraform_remediation":"  resource \"aws_lb\" \"example_alb_access_log\" {\n    ...\n    \"access_logs\" {\n      bucket = <the logging bucket>\n      enabled = true\n    }\n  }\n","tested_tf_version":"1.0.11","remediation_steps":"  1.  Sign into the AWS console.\n  2.  Navigate to EC2 dashboard (or search for EC2 in the search bar).\n  3.  Under LOAD BALANCING, click Load Balancers.\n  4.  Click the circle by the ELB mentioned in the alert.\n  5.  Click 'Actions'.\n  6.  Click 'Edit attributes'.\n  7.  In the 'Edit load balancer attributes' popup box, Click 'Enable' for 'Access logs' > Configure S3 location where you would to store ELB logs.\n  8.  Click 'Save'.\n"},"code":"control '6_03_alb_access_logging' do\r\n  title '6.3 - AWS Elastic Load Balancer v2 access log should be enabled'\r\n  desc 'This control identifies Elastic Load Balancers which have access log disabled. When Access log is enabled, ELBv2 load balancer captures detailed information about requests sent to your load balancer. This information consists of the client IP address, latencies, request paths, and server responses. These logs can be used to analyze traffic patterns and to troubleshoot issues.'\r\n  tag sgs_wiki_url: 'https://wiki.wdf.sap.corp/wiki/x/-0JAc'\r\n  tag terraform_remediation: <<-EOF\r\n  resource \"aws_lb\" \"example_alb_access_log\" {\r\n    ...\r\n    \"access_logs\" {\r\n      bucket = <the logging bucket>\r\n      enabled = true\r\n    }\r\n  }\r\n  EOF\r\n  tag tested_tf_version: '1.0.11'\r\n\r\n  tag remediation_steps: <<-EOF\r\n  1.  Sign into the AWS console.\r\n  2.  Navigate to EC2 dashboard (or search for EC2 in the search bar).\r\n  3.  Under LOAD BALANCING, click Load Balancers.\r\n  4.  Click the circle by the ELB mentioned in the alert.\r\n  5.  Click 'Actions'.\r\n  6.  Click 'Edit attributes'.\r\n  7.  In the 'Edit load balancer attributes' popup box, Click 'Enable' for 'Access logs' > Configure S3 location where you would to store ELB logs.\r\n  8.  Click 'Save'.\r\n  EOF\r\n\r\n  aws_regions.region_names.each do |region_name|\r\n    aws_albs(aws_region: region_name).load_balancer_arns.each do |load_balancer|\r\n      listners = aws_elasticloadbalancingv2_listeners(aws_region: region_name, load_balancer_arn: load_balancer)\r\n      next if listners.certificates.count([]) == listners.certificates.count\r\n\r\n      describe aws_alb(aws_region: region_name, load_balancer_arn: load_balancer) do\r\n        its('access_log_enabled') { should eq true }\r\n      end\r\n    end\r\n  end\r\nend\r\n","source_location":{"ref":"./controls/networks/6_03_networks.rb","line":44},"id":"6_03_alb_access_logging"},{"title":"6.3 - ElasticLoadbalancer (ELB) SSL listeners must use latest Security Policies","desc":"All configured ELB SSL listeners must use the latest reference policy provided by AWS.\nAll configured ELB SSL listeners must use the latest reference policy provided by AWS. This policy contains the allowed and usable encryption algorithm, handshake SSL protocols, signature or hashing algorithms.\nAmazon is updating this policy with a new version if such an algorithm or protocol becomes vulnerable or is seen no longer secure enough.\nOld ELB SSL listeners may still be assigned to such old and vulnerable reference policies. This must be monitored or prevented.\nFurther, it must be ensured that the SSL negotiation policy of the Elastic Load Balancer (Classic) does not contain a vulnerable SSL protocol. The SSL protocol establishes a secure connection between a\nclient and a server. SSL protocols use several SSL ciphers to encrypt data over the Internet. An SSL cipher is an encryption algorithm that uses encryption keys to create a coded message.\nTherefore, it must also be ensured that the used SSL policy having TLS 1.2 or higher.","descriptions":{"default":"All configured ELB SSL listeners must use the latest reference policy provided by AWS.\nAll configured ELB SSL listeners must use the latest reference policy provided by AWS. This policy contains the allowed and usable encryption algorithm, handshake SSL protocols, signature or hashing algorithms.\nAmazon is updating this policy with a new version if such an algorithm or protocol becomes vulnerable or is seen no longer secure enough.\nOld ELB SSL listeners may still be assigned to such old and vulnerable reference policies. This must be monitored or prevented.\nFurther, it must be ensured that the SSL negotiation policy of the Elastic Load Balancer (Classic) does not contain a vulnerable SSL protocol. The SSL protocol establishes a secure connection between a\nclient and a server. SSL protocols use several SSL ciphers to encrypt data over the Internet. An SSL cipher is an encryption algorithm that uses encryption keys to create a coded message.\nTherefore, it must also be ensured that the used SSL policy having TLS 1.2 or higher."},"impact":0.8,"refs":[],"tags":{"sgs_control_hash":"8ae223887226fcbd01722703b9830023","sgs_wiki_url":"https://wiki.wdf.sap.corp/wiki/x/-0JAc","terraform_remediation":"  resource \"aws_lb_listener\" \"example_lb_listener\" {\n    ...\n    ssl_policy        = <ELBSecurityPolicy-FS-1-2-Res-2019-08, ELBSecurityPolicy-TLS-1-2-2017-01, or ELBSecurityPolicy-FS-1-2-Res-2020-10>\n    ...\n  }\n  resource \"aws_elb\" \"example_elb\" {\n    ...\n    listener {\n      ...\n      lb_port           = 443\n      lb_protocol       = \"https\"\n    }\n  }\n","tested_tf_version":"1.0.11","terraform_remediation_note":"The terraform remediation listed is only relevant for the specific resource remediation (either alb or classic elb)","remediation_steps":"  1.  Login to the AWS Management Console.\n  2.  Navigate to EC2 dashboard (or search for EC2 in the search bar).\n  3.  Under LOAD BALANCING, click Load Balancers.\n  4.  Click on the Elastic Load Balancer that you want to examine.\n  5.  Click on the Listeners tab.\n  6.  In the Cipher column of the HTTPS/SSL listener, click Change.\n  7.  In the Select a Cipher dialog box, check Predefined Security Policy checkbox and select the first policy available in the dropdown list, ELBSecurityPolicy-FS-1-2-Res-2019-08, ELBSecurityPolicy-TLS-1-2-2017-01 or ELBSecurityPolicy-FS-1-2-Res-2020-10.\n  8.  Click Save.\n"},"code":"control '6_03_elb_security_policies' do\r\n  impact 0.8\r\n  title '6.3 - ElasticLoadbalancer (ELB) SSL listeners must use latest Security Policies'\r\n  desc 'All configured ELB SSL listeners must use the latest reference policy provided by AWS.\r\nAll configured ELB SSL listeners must use the latest reference policy provided by AWS. This policy contains the allowed and usable encryption algorithm, handshake SSL protocols, signature or hashing algorithms.\r\nAmazon is updating this policy with a new version if such an algorithm or protocol becomes vulnerable or is seen no longer secure enough.\r\nOld ELB SSL listeners may still be assigned to such old and vulnerable reference policies. This must be monitored or prevented.\r\nFurther, it must be ensured that the SSL negotiation policy of the Elastic Load Balancer (Classic) does not contain a vulnerable SSL protocol. The SSL protocol establishes a secure connection between a\r\nclient and a server. SSL protocols use several SSL ciphers to encrypt data over the Internet. An SSL cipher is an encryption algorithm that uses encryption keys to create a coded message.\r\nTherefore, it must also be ensured that the used SSL policy having TLS 1.2 or higher.'\r\n\r\n  tag sgs_control_hash: '8ae223887226fcbd01722703b9830023'\r\n  tag sgs_wiki_url: 'https://wiki.wdf.sap.corp/wiki/x/-0JAc'\r\n  tag terraform_remediation: <<-EOF\r\n  resource \"aws_lb_listener\" \"example_lb_listener\" {\r\n    ...\r\n    ssl_policy        = <ELBSecurityPolicy-FS-1-2-Res-2019-08, ELBSecurityPolicy-TLS-1-2-2017-01, or ELBSecurityPolicy-FS-1-2-Res-2020-10>\r\n    ...\r\n  }\r\n  resource \"aws_elb\" \"example_elb\" {\r\n    ...\r\n    listener {\r\n      ...\r\n      lb_port           = 443\r\n      lb_protocol       = \"https\"\r\n    }\r\n  }\r\n  EOF\r\n  tag tested_tf_version: '1.0.11'\r\n  tag terraform_remediation_note: 'The terraform remediation listed is only relevant for the specific resource remediation (either alb or classic elb)'\r\n\r\n  tag remediation_steps: <<-EOF\r\n  1.  Login to the AWS Management Console.\r\n  2.  Navigate to EC2 dashboard (or search for EC2 in the search bar).\r\n  3.  Under LOAD BALANCING, click Load Balancers.\r\n  4.  Click on the Elastic Load Balancer that you want to examine.\r\n  5.  Click on the Listeners tab.\r\n  6.  In the Cipher column of the HTTPS/SSL listener, click Change.\r\n  7.  In the Select a Cipher dialog box, check Predefined Security Policy checkbox and select the first policy available in the dropdown list, ELBSecurityPolicy-FS-1-2-Res-2019-08, ELBSecurityPolicy-TLS-1-2-2017-01 or ELBSecurityPolicy-FS-1-2-Res-2020-10.\r\n  8.  Click Save.\r\n  EOF\r\n\r\n  # Application Load Balancers can select the following pre-defined policies:\r\n  # https://docs.aws.amazon.com/elasticloadbalancing/latest/application/create-https-listener.html#describe-ssl-policies\r\n  # ELBSecurityPolicy-2015-05\r\n  # ELBSecurityPolicy-2016-08\r\n  # ELBSecurityPolicy-FS-1-1-2019-08\r\n  # ELBSecurityPolicy-FS-1-2-Res-2019-08\r\n  # ELBSecurityPolicy-FS-2018-06\r\n  # ELBSecurityPolicy-TLS-1-0-2015-04\r\n  # ELBSecurityPolicy-TLS-1-1-2017-01\r\n  # ELBSecurityPolicy-TLS-1-2-2017-01\r\n  # ELBSecurityPolicy-TLS-1-2-Ext-2018-06\r\n  #\r\n  # All policies that only permit TLS Protocol 1.2 are allowed\r\n  allowed_tls_policies = ['ELBSecurityPolicy-FS-1-2-Res-2019-08',\r\n                          'ELBSecurityPolicy-TLS-1-2-2017-01',\r\n                          'ELBSecurityPolicy-FS-1-2-Res-2020-10']\r\n  aws_regions.region_names.each do |region_name|\r\n    aws_albs(aws_region: region_name).load_balancer_arns.each do |load_balancer|\r\n      describe aws_alb(aws_region: region_name, load_balancer_arn: load_balancer) do\r\n        its('protocols') { should_not include 'HTTP' }\r\n        its('ssl_policies') { should be_in allowed_tls_policies }\r\n      end\r\n    end\r\n  end\r\n\r\n  # Elastic Load Balancers are configured by creating SSL policies, even if they are using a pre-defined reference policy\r\n  # https://docs.aws.amazon.com/elasticloadbalancing/latest/classic/ssl-config-update.html\r\n  # https://docs.aws.amazon.com/elasticloadbalancing/latest/classic/elb-ssl-security-policy.html\r\n  # Even if a pre-defined policy is selected, a custom policy is created from that template\r\n  # We therefore need to inspect the policies in-depth to check which TLS protocols they permit, in case an entirely custom\r\n  # policy has been defined\r\n  aws_regions.region_names.each do |region_name|\r\n    aws_elbs(aws_region: region_name).load_balancer_names.each do |load_balancer|\r\n      elb = aws_elb(aws_region: region_name, load_balancer_name: load_balancer)\r\n      describe elb do\r\n        its('protocols') { should_not include 'HTTP' }\r\n      end\r\n\r\n      elb.ssl_policies.each do |policy|\r\n        # ELB SSL Policy have a Reference-Security-Policy attribute only if they were created from a reference security policy\r\n        describe \"AWS ELB SSL Policy #{load_balancer} #{policy.policy_name} Reference-Security-Policy\" do\r\n          subject { policy.policy_attribute_descriptions.find { |a| a.attribute_name == 'Reference-Security-Policy' } }\r\n          its('attribute_value') { should be_in allowed_tls_policies }\r\n        end unless (policy.policy_attribute_descriptions.find { |a| a.attribute_name == 'Reference-Security-Policy' }).nil?\r\n\r\n        describe \"AWS ELB SSL Policy #{load_balancer} #{policy.policy_name} Protocol-TLSv1\" do\r\n          subject { policy.policy_attribute_descriptions.find { |a| a.attribute_name == 'Protocol-TLSv1' } }\r\n          its('attribute_value') { should cmp 'false' }\r\n        end unless (policy.policy_attribute_descriptions.find { |a| a.attribute_name == 'Protocol-TLSv1' }).nil?\r\n\r\n        describe \"AWS ELB SSL Policy #{load_balancer} #{policy.policy_name} Protocol-SSLv3\" do\r\n          subject { policy.policy_attribute_descriptions.find { |a| a.attribute_name == 'Protocol-SSLv3' } }\r\n          its('attribute_value') { should cmp 'false' }\r\n        end unless (policy.policy_attribute_descriptions.find { |a| a.attribute_name == 'Protocol-SSLv3' }).nil?\r\n\r\n        describe \"AWS ELB SSL Policy #{load_balancer} #{policy.policy_name} Protocol-TLSv1.1\" do\r\n          subject { policy.policy_attribute_descriptions.find { |a| a.attribute_name == 'Protocol-TLSv1.1' } }\r\n          its('attribute_value') { should cmp 'false' }\r\n        end unless (policy.policy_attribute_descriptions.find { |a| a.attribute_name == 'Protocol-TLSv1.1' }).nil?\r\n\r\n        describe \"AWS ELB SSL Policy #{load_balancer} #{policy.policy_name} Protocol-TLSv1.2\" do\r\n          subject { policy.policy_attribute_descriptions.find { |a| a.attribute_name == 'Protocol-TLSv1.2' } }\r\n          its('attribute_value') { should cmp 'true' }\r\n        end unless (policy.policy_attribute_descriptions.find { |a| a.attribute_name == 'Protocol-TLSv1.2' }).nil?\r\n      end\r\n    end\r\n  end\r\nend\r\n","source_location":{"ref":"./controls/networks/6_03_networks.rb","line":82},"id":"6_03_elb_security_policies"},{"title":"6.4 - AWS VPN must be configured with cryptographic algorithm","desc":"This control enforces that cryptographic algorithm must be configured for AWS VPNs. It is recommended to use custom IPsec/IKE policy with specific cryptographic algorithms and key strengths instead of AWS default policy sets. If cryptographic algorithms and parameters are not specified, AWS VPN gateways use a set of default protocols. It is secured to use custom policy sets and choose strong cryptography.","descriptions":{"default":"This control enforces that cryptographic algorithm must be configured for AWS VPNs. It is recommended to use custom IPsec/IKE policy with specific cryptographic algorithms and key strengths instead of AWS default policy sets. If cryptographic algorithms and parameters are not specified, AWS VPN gateways use a set of default protocols. It is secured to use custom policy sets and choose strong cryptography."},"impact":0.8,"refs":[],"tags":{"sgs_wiki_url":"https://wiki.wdf.sap.corp/wiki/x/-0JAc","terraform_remediation":"  resource \"aws_vpn_connection\" \"example_vpn_configuration\" {\n    ...\n    tunnel1_ike_versions = [\"ikev2\"] ## This array should not contain IKEv1 since it is outdated\n    tunnel2_ike_versions = [\"ikev2\"] ## This array should not contain IKEv1 since it is outdated\n  }\n","tested_tf_version":"1.0.11","remediation_steps":"  1.  Sign into the AWS console.\n  2.  Navigate to VPN connection dashboard.\n  3.  Remove IKEv1 from the advanced tunnel information\n"},"code":"control '6_04_aws_secure_vpn_setup' do\r\n  title '6.4 - AWS VPN must be configured with cryptographic algorithm'\r\n  impact 0.8\r\n  desc 'This control enforces that cryptographic algorithm must be configured for AWS VPNs. It is recommended to use custom IPsec/IKE policy with specific cryptographic algorithms and key strengths instead of AWS default policy sets. If cryptographic algorithms and parameters are not specified, AWS VPN gateways use a set of default protocols. It is secured to use custom policy sets and choose strong cryptography.'\r\n  tag sgs_wiki_url: 'https://wiki.wdf.sap.corp/wiki/x/-0JAc'\r\n  tag terraform_remediation: <<-EOF\r\n  resource \"aws_vpn_connection\" \"example_vpn_configuration\" {\r\n    ...\r\n    tunnel1_ike_versions = [\"ikev2\"] ## This array should not contain IKEv1 since it is outdated\r\n    tunnel2_ike_versions = [\"ikev2\"] ## This array should not contain IKEv1 since it is outdated\r\n  }\r\n  EOF\r\n  tag tested_tf_version: '1.0.11'\r\n\r\n  tag remediation_steps: <<-EOF\r\n  1.  Sign into the AWS console.\r\n  2.  Navigate to VPN connection dashboard.\r\n  3.  Remove IKEv1 from the advanced tunnel information\r\n  EOF\r\n\r\n  aws_regions.region_names.each do |region_name|\r\n    aws_vpn_connections(aws_region: region_name).vpn_connection_ids.each do |vpn_connection|\r\n      vpn = aws_vpn_connection(aws_region: region_name, vpn_connection_id: vpn_connection)\r\n      next unless vpn.state == 'available'\r\n\r\n      vpn.options.tunnel_options.each do |vpn_tunnel_option|\r\n        vpn_tunnel_option.ike_versions.each do |tunnel_ike_version|\r\n          describe \"IKEv1 vpn tunnel options for #{vpn_connection}\" do\r\n            subject { tunnel_ike_version.value }\r\n            it { should_not eq 'ikev1' }\r\n          end\r\n        end\r\n      end\r\n    end\r\n  end\r\nend\r\n","source_location":{"ref":"./controls/networks/6_04_networks.rb","line":1},"id":"6_04_aws_secure_vpn_setup"},{"title":"8.4 - AWS Route53 Public Zone should not have Private Records","desc":"The AWS route53 service should not have any private records configured in\n        a public zone. It is good design practice not to expose private records\n        or IP addresses in a public DNS record or zone to have a clear\n        separation and to prevent unnecessary information disclosure.","descriptions":{"default":"The AWS route53 service should not have any private records configured in\n        a public zone. It is good design practice not to expose private records\n        or IP addresses in a public DNS record or zone to have a clear\n        separation and to prevent unnecessary information disclosure."},"impact":0.5,"refs":[],"tags":{"sgs_wiki_url":"https://wiki.wdf.sap.corp/wiki/x/-0JAc","remediation_steps":"  1.  Sign in to the AWS Management console.\n  2.  Go to Route 53 console.\n  3.  Click Hosted Zones in the navigation pane.\n  4.  Click 'Create Hosted Zone'.\n  5.  Enter the domain name that you misconfigured as public > Choose 'Private hosted zone' under 'Type'.\n  6.  In the VPC ID list, choose the VPC that you want to associate with the hosted zone > Click 'Create hosted zone'.\n  7.  In the new zone you created, click 'Create record' > Input the records you once configured in the misconfigured public zone > Click 'Create records'.\n  8.  In the original misconfigured public zone, delete the records whose Type is other than NS or SOA, which are also the ones you created in the new zone > Click 'Delete zone'.\n"},"code":"control '8_04_public_zone_private_records' do\r\n  title '8.4 - AWS Route53 Public Zone should not have Private Records'\r\n  impact 0.5\r\n  desc 'The AWS route53 service should not have any private records configured in\r\n        a public zone. It is good design practice not to expose private records\r\n        or IP addresses in a public DNS record or zone to have a clear\r\n        separation and to prevent unnecessary information disclosure.'\r\n  tag sgs_wiki_url: 'https://wiki.wdf.sap.corp/wiki/x/-0JAc'\r\n\r\n  tag remediation_steps: <<-EOF\r\n  1.  Sign in to the AWS Management console.\r\n  2.  Go to Route 53 console.\r\n  3.  Click Hosted Zones in the navigation pane.\r\n  4.  Click 'Create Hosted Zone'.\r\n  5.  Enter the domain name that you misconfigured as public > Choose 'Private hosted zone' under 'Type'.\r\n  6.  In the VPC ID list, choose the VPC that you want to associate with the hosted zone > Click 'Create hosted zone'.\r\n  7.  In the new zone you created, click 'Create record' > Input the records you once configured in the misconfigured public zone > Click 'Create records'.\r\n  8.  In the original misconfigured public zone, delete the records whose Type is other than NS or SOA, which are also the ones you created in the new zone > Click 'Delete zone'.\r\n  EOF\r\n\r\n  records = []\r\n\r\n  aws_hosted_zones.names.each do |zone_name|\r\n    hosted_zone = aws_hosted_zone(zone_name)\r\n    next if hosted_zone.private_zone == true\r\n    list_of_ids = hosted_zone.ids.map { |id| id.split('/').last }.compact.uniq\r\n    list_of_ids.each do |zone_id|\r\n      aws_route53_record_sets(hosted_zone_id: zone_id).resource_records.each do |record_value|\r\n        next if record_value.nil?\r\n        records.append(record_value)\r\n      end\r\n    end\r\n  end\r\n  records = records.flatten.select { |i| i.match(/(^10\\.)|(^172\\.1[6-9]\\.)|(^172\\.2[0-9]\\.)|(^172\\.3[0-1]\\.)|(^192\\.168\\.)/) }\r\n  describe records do\r\n    its('count') { should eq 0 }\r\n  end\r\nend\r\n","source_location":{"ref":"./controls/networks/8_04_networks.rb","line":1},"id":"8_04_public_zone_private_records"},{"title":"8.5 - AWS CloudFront distribution must not use insecure SSL protocols for HTTPS communication","desc":"As per the security standards, it must be enforced the use of secure ciphers TLSv1.0, TLSv1.1, and/or TLSv1.2 in a CloudFront Distributions.\n  This policy scans for any violations from this practice.","descriptions":{"default":"As per the security standards, it must be enforced the use of secure ciphers TLSv1.0, TLSv1.1, and/or TLSv1.2 in a CloudFront Distributions.\n  This policy scans for any violations from this practice."},"impact":0.8,"refs":[],"tags":{"sgs_wiki_url":"https://wiki.wdf.sap.corp/wiki/x/-0JAc","terraform_remediation":"  resource \"aws_cloudfront_distribution\" \"example_distribution\" {\n    origin {\n      ...\n      custom_origin_config {\n        ...\n        origin_ssl_protocols = [\"TLSv1.2\"]\n      }\n    }\n  }\n","tested_tf_version":"1.0.11","remediation_steps":"  1.  Go to the AWS console.                                                                                                                                                                     '}\n  2.  Go to CloudFront dashboard (or search for CloudFront in the search bar).\n  3.  Click on your distribution ID.\n  4.  Select the Origins tab.\n  5.  Click the origin you want to modify > Click Edit.\n  6.  Under Origin SSL Protocols, uncheck SSLv3.\n  7.  Select Yes > Edit.\n"},"code":"control '8_05_cloudfront_ssl_protocol' do\r\n  title '8.5 - AWS CloudFront distribution must not use insecure SSL protocols for HTTPS communication'\r\n  impact 0.8\r\n  desc 'As per the security standards, it must be enforced the use of secure ciphers TLSv1.0, TLSv1.1, and/or TLSv1.2 in a CloudFront Distributions.\r\n  This policy scans for any violations from this practice.'\r\n  tag sgs_wiki_url: 'https://wiki.wdf.sap.corp/wiki/x/-0JAc'\r\n  tag terraform_remediation: <<-EOF\r\n  resource \"aws_cloudfront_distribution\" \"example_distribution\" {\r\n    origin {\r\n      ...\r\n      custom_origin_config {\r\n        ...\r\n        origin_ssl_protocols = [\"TLSv1.2\"]\r\n      }\r\n    }\r\n  }\r\n  EOF\r\n  tag tested_tf_version: '1.0.11'\r\n\r\n  tag remediation_steps: <<-EOF\r\n  1.  Go to the AWS console.                                                                                                                                                                     '}\r\n  2.  Go to CloudFront dashboard (or search for CloudFront in the search bar).\r\n  3.  Click on your distribution ID.\r\n  4.  Select the Origins tab.\r\n  5.  Click the origin you want to modify > Click Edit.\r\n  6.  Under Origin SSL Protocols, uncheck SSLv3.\r\n  7.  Select Yes > Edit.\r\n  EOF\r\n\r\n  aws_cloudfront_distributions.where(enabled: true).distribution_ids.each do |distribution_id|\r\n    describe aws_cloudfront_distribution(distribution_id) do\r\n      %w(SSLv3 TLSv1 TLSv1.1).each do |protocol|\r\n        its('custom_origin_ssl_protocols') { should_not include protocol }\r\n      end\r\n    end\r\n  end\r\nend\r\n","source_location":{"ref":"./controls/networks/8_05_networks.rb","line":1},"id":"8_05_cloudfront_ssl_protocol"},{"title":"8.5 - AWS CloudFront origin protocol policy does not enforce HTTPS-only","desc":"Enforce HTTPS-only traffic between a CloudFront distribution and the origin.\n  This policy checks for any distributions which does not enforce HTTPS-only.","descriptions":{"default":"Enforce HTTPS-only traffic between a CloudFront distribution and the origin.\n  This policy checks for any distributions which does not enforce HTTPS-only."},"impact":0.5,"refs":[],"tags":{"sgs_wiki_url":"https://wiki.wdf.sap.corp/wiki/x/-0JAc","terraform_remediation":"  resource \"aws_cloudfront_distribution\" \"example_distribution\" {\n    origin {\n      ...\n      custom_origin_config {\n        ...\n        origin_protocol_policy = \"https-only\"\n      }\n    }\n  }\n","tested_tf_version":"1.0.11","remediation_steps":"  1.  Go to the AWS console.\n  2.  Go to CloudFront dashboard (or search for CloudFront in the search bar).\n  3.  Click your distribution ID.\n  4.  Select the Origins tab.\n  5.  Click the origin you want to modify > Click Edit > Change the Origin Protocol Policy to https-only.\n  6.  Click Yes > Edit.\n"},"code":"control '8_05_cloudfront_origin_protocol_policy' do\r\n  title '8.5 - AWS CloudFront origin protocol policy does not enforce HTTPS-only'\r\n  impact 0.5\r\n  desc 'Enforce HTTPS-only traffic between a CloudFront distribution and the origin.\r\n  This policy checks for any distributions which does not enforce HTTPS-only.'\r\n  tag sgs_wiki_url: 'https://wiki.wdf.sap.corp/wiki/x/-0JAc'\r\n  tag terraform_remediation: <<-EOF\r\n  resource \"aws_cloudfront_distribution\" \"example_distribution\" {\r\n    origin {\r\n      ...\r\n      custom_origin_config {\r\n        ...\r\n        origin_protocol_policy = \"https-only\"\r\n      }\r\n    }\r\n  }\r\n  EOF\r\n  tag tested_tf_version: '1.0.11'\r\n\r\n  tag remediation_steps: <<-EOF\r\n  1.  Go to the AWS console.\r\n  2.  Go to CloudFront dashboard (or search for CloudFront in the search bar).\r\n  3.  Click your distribution ID.\r\n  4.  Select the Origins tab.\r\n  5.  Click the origin you want to modify > Click Edit > Change the Origin Protocol Policy to https-only.\r\n  6.  Click Yes > Edit.\r\n  EOF\r\n\r\n  aws_cloudfront_distributions.where(enabled: true).distribution_ids.each do |distribution_id|\r\n    describe aws_cloudfront_distribution(distribution_id) do\r\n      %w(http-only match-viewer).each do |protocol|\r\n        its('custom_origin_protocol_policies') { should_not include protocol }\r\n      end\r\n    end\r\n  end\r\nend\r\n","source_location":{"ref":"./controls/networks/8_05_networks.rb","line":39},"id":"8_05_cloudfront_origin_protocol_policy"},{"title":"8.5 - AWS CloudFront viewer protocol policy is not configured with HTTPS","desc":"Configuring viewer protocol policy to use only HTTPS enables connections to be encrypted when CloudFront communicates with viewers.","descriptions":{"default":"Configuring viewer protocol policy to use only HTTPS enables connections to be encrypted when CloudFront communicates with viewers."},"impact":0.5,"refs":[],"tags":{"sgs_wiki_url":"https://wiki.wdf.sap.corp/wiki/x/-0JAc","terraform_remediation":"  resource \"aws_cloudfront_distribution\" \"example_distribution\" {\n    ...\n    default_cache_behavior {\n      ...\n      viewer_protocol_policy = \"https-only\"\n    }\n  }\n","tested_tf_version":"1.0.11","remediation_steps":"  1.  Go to the AWS console.\n  2.  Go to CloudFront dashboard (or search for CloudFront in the search bar).\n  3.  Click your distribution ID.\n  4.  Click on the Behaviors tab.\n  5.  Click on the behavior you want to modify > Click Edit.\n  6.  Under Viewer Protocol Policy, Choose HTTPS Only or Redirect HTTP to HTTPS.\n  7.  Select Yes > Edit.\n"},"code":"control '8_05_cloudfront_viewer_protocol_policy' do\r\n  title '8.5 - AWS CloudFront viewer protocol policy is not configured with HTTPS'\r\n  impact 0.5\r\n  desc 'Configuring viewer protocol policy to use only HTTPS enables connections to be encrypted when CloudFront communicates with viewers.'\r\n  tag sgs_wiki_url: 'https://wiki.wdf.sap.corp/wiki/x/-0JAc'\r\n  tag terraform_remediation: <<-EOF\r\n  resource \"aws_cloudfront_distribution\" \"example_distribution\" {\r\n    ...\r\n    default_cache_behavior {\r\n      ...\r\n      viewer_protocol_policy = \"https-only\"\r\n    }\r\n  }\r\n  EOF\r\n  tag tested_tf_version: '1.0.11'\r\n\r\n  tag remediation_steps: <<-EOF\r\n  1.  Go to the AWS console.\r\n  2.  Go to CloudFront dashboard (or search for CloudFront in the search bar).\r\n  3.  Click your distribution ID.\r\n  4.  Click on the Behaviors tab.\r\n  5.  Click on the behavior you want to modify > Click Edit.\r\n  6.  Under Viewer Protocol Policy, Choose HTTPS Only or Redirect HTTP to HTTPS.\r\n  7.  Select Yes > Edit.\r\n  EOF\r\n\r\n  aws_cloudfront_distributions.where(enabled: true).distribution_ids.each do |distribution_id|\r\n    describe aws_cloudfront_distribution(distribution_id) do\r\n      it { should_not have_viewer_protocol_policies_allowing_http }\r\n    end\r\n  end\r\nend\r\n","source_location":{"ref":"./controls/networks/8_05_networks.rb","line":76},"id":"8_05_cloudfront_viewer_protocol_policy"},{"title":"8.5 - AWS Cloudfront Distribution with S3 have Origin Access set to disabled","desc":"This control verifies that AWS CloudFront distributions which are utilizing S3 bucket and have Origin Access Enabled. Enabling the origin access identity restricts any direct access to your objects through Amazon S3 URLs.","descriptions":{"default":"This control verifies that AWS CloudFront distributions which are utilizing S3 bucket and have Origin Access Enabled. Enabling the origin access identity restricts any direct access to your objects through Amazon S3 URLs."},"impact":0.5,"refs":[],"tags":{"sgs_wiki_url":"https://wiki.wdf.sap.corp/wiki/x/-0JAc","terraform_remediation":"  resource \"aws_cloudfront_origin_access_identity\" \"example\" {}\n  resource \"aws_cloudfront_distribution\" \"example_distribution\" {\n    ...\n    origin {\n      ..\n      s3_origin_config {\n        origin_access_identity = aws_cloudfront_origin_access_identity.example.cloudfront_access_identity_path\n      }\n    }\n\n","tested_tf_version":"1.0.11","remediation_steps":"  1. Sign in to the AWS Management Console.\n  2. Go to CloudFront (or search for CloudFront in the search bar).\n  3. Click the reported Distribution.\n  4. Click on 'Origins' tab.\n  5. Select the S3 bucket and click on 'Edit'.\n  6. Under the 'S3 bucket access', select 'Yes use OAI (bucket can restrict access to only CloudFront)' > Choose the origin access identity > Select 'Yes, update the bucket policy'. \n  7. Click 'Save changes'.\n"},"code":"control '8_05_cloudfront_s3_origin_access' do\r\n  title '8.5 - AWS Cloudfront Distribution with S3 have Origin Access set to disabled'\r\n  impact 0.5\r\n  desc 'This control verifies that AWS CloudFront distributions which are utilizing S3 bucket and have Origin Access Enabled. Enabling the origin access identity restricts any direct access to your objects through Amazon S3 URLs.'\r\n  tag sgs_wiki_url: 'https://wiki.wdf.sap.corp/wiki/x/-0JAc'\r\n  tag terraform_remediation: <<-EOF\r\n  resource \"aws_cloudfront_origin_access_identity\" \"example\" {}\r\n  resource \"aws_cloudfront_distribution\" \"example_distribution\" {\r\n    ...\r\n    origin {\r\n      ..\r\n      s3_origin_config {\r\n        origin_access_identity = aws_cloudfront_origin_access_identity.example.cloudfront_access_identity_path\r\n      }\r\n    }\r\n\r\n  EOF\r\n  tag tested_tf_version: '1.0.11'\r\n\r\n  tag remediation_steps: <<-EOF\r\n  1. Sign in to the AWS Management Console.\r\n  2. Go to CloudFront (or search for CloudFront in the search bar).\r\n  3. Click the reported Distribution.\r\n  4. Click on 'Origins' tab.\r\n  5. Select the S3 bucket and click on 'Edit'.\r\n  6. Under the 'S3 bucket access', select 'Yes use OAI (bucket can restrict access to only CloudFront)' > Choose the origin access identity > Select 'Yes, update the bucket policy'.#{' '}\r\n  7. Click 'Save changes'.\r\n  EOF\r\n\r\n  aws_cloudfront_distributions.where(enabled: true).distribution_ids.each do |distribution_id|\r\n    next unless aws_cloudfront_distribution(distribution_id).has_s3_origin_configs?\r\n    describe aws_cloudfront_distribution(distribution_id) do\r\n      its('s3_origin_access') { should_not eq [''] }\r\n    end\r\n  end\r\nend\r\n","source_location":{"ref":"./controls/networks/8_05_networks.rb","line":109},"id":"8_05_cloudfront_s3_origin_access"},{"title":"8.5 - AWS CloudFront distribution with access logging not enabled","desc":"This control enforces CloudFront distributions to have access logging enabled. Enabling access logging creates log files with all the detailed\n  information about all the requests received by CloudFront. You can specify Amazon S3 bucket that you want CloudFront to save files in.","descriptions":{"default":"This control enforces CloudFront distributions to have access logging enabled. Enabling access logging creates log files with all the detailed\n  information about all the requests received by CloudFront. You can specify Amazon S3 bucket that you want CloudFront to save files in."},"impact":0.5,"refs":[],"tags":{"sgs_wiki_url":"https://wiki.wdf.sap.corp/wiki/x/-0JAc","terraform_remediation":"  resource \"aws_cloudfront_distribution\" \"example_cloudfront_distribution\" {\n    ...\n    logging_config {\n      bucket          = <logging bucket>\n    }\n  }\n","tested_tf_version":"1.0.11","remediation_steps":"  1.  Go to the AWS console.\n  2.  Go to the CloudFront dashboard (or search for CloudFront in the search bar).\n  3.  Click your distribution ID.\n  4.  On the General tab, click Edit.\n  5.  On 'Edit Distribution' page, change Logging to On > Select a Bucket for Logs and Log Prefix.\n  6.  Click Yes >  Edit.\n"},"code":"control '8_05_cloudfront_access_log_enabled' do\r\n  title '8.5 - AWS CloudFront distribution with access logging not enabled'\r\n  impact 0.5\r\n  desc 'This control enforces CloudFront distributions to have access logging enabled. Enabling access logging creates log files with all the detailed\r\n  information about all the requests received by CloudFront. You can specify Amazon S3 bucket that you want CloudFront to save files in.'\r\n  tag sgs_wiki_url: 'https://wiki.wdf.sap.corp/wiki/x/-0JAc'\r\n  tag terraform_remediation: <<-EOF\r\n  resource \"aws_cloudfront_distribution\" \"example_cloudfront_distribution\" {\r\n    ...\r\n    logging_config {\r\n      bucket          = <logging bucket>\r\n    }\r\n  }\r\n  EOF\r\n  tag tested_tf_version: '1.0.11'\r\n\r\n  tag remediation_steps: <<-EOF\r\n  1.  Go to the AWS console.\r\n  2.  Go to the CloudFront dashboard (or search for CloudFront in the search bar).\r\n  3.  Click your distribution ID.\r\n  4.  On the General tab, click Edit.\r\n  5.  On 'Edit Distribution' page, change Logging to On > Select a Bucket for Logs and Log Prefix.\r\n  6.  Click Yes >  Edit.\r\n  EOF\r\n\r\n  aws_cloudfront_distributions.where(enabled: true).distribution_ids.each do |distribution_id|\r\n    describe aws_cloudfront_distribution(distribution_id) do\r\n      it { should have_access_logging_enabled }\r\n    end\r\n  end\r\nend\r\n","source_location":{"ref":"./controls/networks/8_05_networks.rb","line":146},"id":"8_05_cloudfront_access_log_enabled"},{"title":"5.1 - AWS S3 Bucket Global GET Permissions must be disabled via bucket policy","desc":"This policy identifies the S3 Bucket(s) which will allow any unauthenticated user to GET objects from a bucket.\n  These permissions permit anyone, malicious or not, to GET objects from your S3 bucket if they can guess the namespace.\n  Since the S3 service does not protect the namespace other than with ACLs and Bucket Policy, you risk loss or compromise of critical data by leaving this open.","descriptions":{"default":"This policy identifies the S3 Bucket(s) which will allow any unauthenticated user to GET objects from a bucket.\n  These permissions permit anyone, malicious or not, to GET objects from your S3 bucket if they can guess the namespace.\n  Since the S3 service does not protect the namespace other than with ACLs and Bucket Policy, you risk loss or compromise of critical data by leaving this open."},"impact":0.8,"refs":[],"tags":{"sgs_wiki_url":"https://wiki.wdf.sap.corp/wiki/x/-0JAc","terraform_remediation":"  resource \"aws_s3_bucket_policy\" \"example_policy\" {\n    bucket = <your bucket>\n\n    policy = <<POLICY\n  {\n    \"Version\": \"2012-10-17\",\n    \"Statement\": [\n      {\n          \"Effect\": \"Allow\",\n          \"Principal\": <limited list of users>,\n          \"Action\": [\"s3:*\", \"s3:GetObject\"],\n          \"Resource\": \"<your bucket arn>/*\",\n          \"Condition\": {\n              \"IpAddress\": {\n                  \"aws:SourceIp\" : <limited IP source list>\n              }\n          }\n      }\n    ]\n  }\n  POLICY\n  }\n","tested_tf_version":"1.0.11","remediation_steps":"  1.  Log into to the AWS Management Console > Search for S3 in the search bar.\n  2.  Navigate to the bucket mentioned in the alert.\n  3.  Navigate to the permissions > Check bucket policy i.e. You can't have effect set to Allow with Principal set to * or 'AWS' => '*' and action set to s3:Get or s3:* or * > reference [5.1 Ensure storage services are not publicly accessible] SGS hardening guidelines for more information.\n\n      *Please note: To prevent public access on AWS S3, the bucket setting “Block all public access” SHOULD be enabled. If this is not feasible because of a special use case, accessibility can be configured on a bucket level. Object level policies MUST NOT be used. When using bucket level policies, an asterisk (\"*\") MUST not be used in the principal field of any policy that grants permissions. All GET permissions MUST NOT be allowed to all users on the public internet.*\n  4.  Click on Edit Bucket policy to make necessary changes.\n  5.  Save changes.\n"},"code":"control '5_01_get' do\r\n  title '5.1 - AWS S3 Bucket Global GET Permissions must be disabled via bucket policy'\r\n  impact 0.8\r\n  desc 'This policy identifies the S3 Bucket(s) which will allow any unauthenticated user to GET objects from a bucket.\r\n  These permissions permit anyone, malicious or not, to GET objects from your S3 bucket if they can guess the namespace.\r\n  Since the S3 service does not protect the namespace other than with ACLs and Bucket Policy, you risk loss or compromise of critical data by leaving this open.'\r\n  tag sgs_wiki_url: 'https://wiki.wdf.sap.corp/wiki/x/-0JAc'\r\n  tag terraform_remediation: <<-EOF\r\n  resource \"aws_s3_bucket_policy\" \"example_policy\" {\r\n    bucket = <your bucket>\r\n\r\n    policy = <<POLICY\r\n  {\r\n    \"Version\": \"2012-10-17\",\r\n    \"Statement\": [\r\n      {\r\n          \"Effect\": \"Allow\",\r\n          \"Principal\": <limited list of users>,\r\n          \"Action\": [\"s3:*\", \"s3:GetObject\"],\r\n          \"Resource\": \"<your bucket arn>/*\",\r\n          \"Condition\": {\r\n              \"IpAddress\": {\r\n                  \"aws:SourceIp\" : <limited IP source list>\r\n              }\r\n          }\r\n      }\r\n    ]\r\n  }\r\n  POLICY\r\n  }\r\n  EOF\r\n  tag tested_tf_version: '1.0.11'\r\n\r\n  tag remediation_steps: <<-EOF\r\n  1.  Log into to the AWS Management Console > Search for S3 in the search bar.\r\n  2.  Navigate to the bucket mentioned in the alert.\r\n  3.  Navigate to the permissions > Check bucket policy i.e. You can't have effect set to Allow with Principal set to * or 'AWS' => '*' and action set to s3:Get or s3:* or * > reference [5.1 Ensure storage services are not publicly accessible] SGS hardening guidelines for more information.\r\n\r\n      *Please note: To prevent public access on AWS S3, the bucket setting “Block all public access” SHOULD be enabled. If this is not feasible because of a special use case, accessibility can be configured on a bucket level. Object level policies MUST NOT be used. When using bucket level policies, an asterisk (\"*\") MUST not be used in the principal field of any policy that grants permissions. All GET permissions MUST NOT be allowed to all users on the public internet.*\r\n  4.  Click on Edit Bucket policy to make necessary changes.\r\n  5.  Save changes.\r\n  EOF\r\n\r\n  aws_s3_buckets.bucket_names.each do |bucket_name|\r\n    s3_bucket = aws_s3_bucket(bucket_name: bucket_name)\r\n    next if s3_bucket.prevent_public_access? || s3_bucket.tags['sec-by-def-public-storage-exception'] == 'enabled'\r\n\r\n    describe \"Bucket Policy: GetObject for #{bucket_name}\" do\r\n      subject do\r\n        bucket_policy = s3_bucket.bucket_policy\r\n        allow_all = bucket_policy.select do |s|\r\n          (s.effect == 'Allow' && s.principal == '*' && s.action.to_s.match(/s3:\\*/)) ||\r\n            (s.effect == 'Allow' && s.principal == '*' && s.action.to_s.match(/s3:Get/)) ||\r\n            (s.effect == 'Allow' && s.principal == '*' && s.action == '*') ||\r\n            (s.effect == 'Allow' && s.principal == { 'AWS' => '*' } && s.action.to_s.match(/s3:\\*/)) ||\r\n            (s.effect == 'Allow' && s.principal == { 'AWS' => '*' } && s.action.to_s.match(/s3:Get/)) ||\r\n            (s.effect == 'Allow' && s.principal == { 'AWS' => '*' } && s.action == '*')\r\n        end\r\n        allow_all.count\r\n      end\r\n      it { should be_zero }\r\n    end\r\n  end\r\nend\r\n","source_location":{"ref":"./controls/storage/5_01_storage.rb","line":1},"id":"5_01_get"},{"title":"5.1 - AWS S3 Bucket Global LIST Permissions should be disabled via bucket policy","desc":"This policy identifies the S3 Bucket(s) which will allow any unauthenticated user to LIST objects from a bucket.\n  These permissions permit anyone, malicious or not, to LIST objects from your S3 bucket if they can guess the namespace.\n  Since the S3 service does not protect the namespace other than with ACLs and Bucket Policy, you risk loss or compromise of critical data by leaving this open.","descriptions":{"default":"This policy identifies the S3 Bucket(s) which will allow any unauthenticated user to LIST objects from a bucket.\n  These permissions permit anyone, malicious or not, to LIST objects from your S3 bucket if they can guess the namespace.\n  Since the S3 service does not protect the namespace other than with ACLs and Bucket Policy, you risk loss or compromise of critical data by leaving this open."},"impact":0.5,"refs":[],"tags":{"sgs_wiki_url":"https://wiki.wdf.sap.corp/wiki/x/-0JAc","terraform_remediation":"  resource \"aws_s3_bucket_policy\" \"example_policy\" {\n    bucket = <your bucket>\n\n    policy = <<POLICY\n  {\n    \"Version\": \"2012-10-17\",\n    \"Statement\": [\n      {\n          \"Effect\": \"Allow\",\n          \"Principal\": <limited list of users>,\n          \"Action\": [<list of s3List actions>],\n          \"Resource\": \"<your bucket arn>/*\",\n          \"Condition\": {\n              \"IpAddress\": {\n                  \"aws:SourceIp\" : <limited IP source list>\n              }\n          }\n      }\n    ]\n  }\n  POLICY\n  }\n","tested_tf_version":"1.0.11","remediation_steps":"  1.  Log into to the AWS Management Console > Search for S3 in the search bar.\n  2.  Navigate to the bucket mentioned in the alert.\n  3.  Navigate to the permissions > Check bucket policy i.e. You can't have effect set to Allow with Principal set to * or 'AWS' => '*' and action set to s3:List or s3:* or * -> reference [5.1 Ensure storage services are not publicly accessible] SGS hardening guidelines for more information.\n      *Please note: To prevent public access on AWS S3, the bucket setting “Block all public access” SHOULD be enabled. If this is not feasible because of a special use case, accessibility can be configured on a bucket level. Object level policies MUST NOT be used. When using bucket level policies, an asterisk (\"*\") MUST not be used in the principal field of any policy that grants permissions. All GET permissions MUST NOT be allowed to all users on the public internet. All LIST permissions SHOULD NOT be allowed to all users on the public internet.*\n  4.  Click on Edit Bucket policy to make necessary changes.\n  5. Save changes.\n"},"code":"control '5_01_list' do\r\n  title '5.1 - AWS S3 Bucket Global LIST Permissions should be disabled via bucket policy'\r\n  impact 0.5\r\n  desc 'This policy identifies the S3 Bucket(s) which will allow any unauthenticated user to LIST objects from a bucket.\r\n  These permissions permit anyone, malicious or not, to LIST objects from your S3 bucket if they can guess the namespace.\r\n  Since the S3 service does not protect the namespace other than with ACLs and Bucket Policy, you risk loss or compromise of critical data by leaving this open.'\r\n  tag sgs_wiki_url: 'https://wiki.wdf.sap.corp/wiki/x/-0JAc'\r\n  tag terraform_remediation: <<-EOF\r\n  resource \"aws_s3_bucket_policy\" \"example_policy\" {\r\n    bucket = <your bucket>\r\n\r\n    policy = <<POLICY\r\n  {\r\n    \"Version\": \"2012-10-17\",\r\n    \"Statement\": [\r\n      {\r\n          \"Effect\": \"Allow\",\r\n          \"Principal\": <limited list of users>,\r\n          \"Action\": [<list of s3List actions>],\r\n          \"Resource\": \"<your bucket arn>/*\",\r\n          \"Condition\": {\r\n              \"IpAddress\": {\r\n                  \"aws:SourceIp\" : <limited IP source list>\r\n              }\r\n          }\r\n      }\r\n    ]\r\n  }\r\n  POLICY\r\n  }\r\n  EOF\r\n  tag tested_tf_version: '1.0.11'\r\n\r\n  tag remediation_steps: <<-EOF\r\n  1.  Log into to the AWS Management Console > Search for S3 in the search bar.\r\n  2.  Navigate to the bucket mentioned in the alert.\r\n  3.  Navigate to the permissions > Check bucket policy i.e. You can't have effect set to Allow with Principal set to * or 'AWS' => '*' and action set to s3:List or s3:* or * -> reference [5.1 Ensure storage services are not publicly accessible] SGS hardening guidelines for more information.\r\n      *Please note: To prevent public access on AWS S3, the bucket setting “Block all public access” SHOULD be enabled. If this is not feasible because of a special use case, accessibility can be configured on a bucket level. Object level policies MUST NOT be used. When using bucket level policies, an asterisk (\"*\") MUST not be used in the principal field of any policy that grants permissions. All GET permissions MUST NOT be allowed to all users on the public internet. All LIST permissions SHOULD NOT be allowed to all users on the public internet.*\r\n  4.  Click on Edit Bucket policy to make necessary changes.\r\n  5. Save changes.\r\n  EOF\r\n\r\n  aws_s3_buckets.bucket_names.each do |bucket_name|\r\n    s3_bucket = aws_s3_bucket(bucket_name: bucket_name)\r\n    next if s3_bucket.prevent_public_access? || s3_bucket.tags['sec-by-def-public-storage-exception'] == 'enabled'\r\n\r\n    describe \"Bucket Policy: ListObject for #{bucket_name}\" do\r\n      subject do\r\n        bucket_policy = s3_bucket.bucket_policy\r\n        allow_all = bucket_policy.select do |s|\r\n          (s.effect == 'Allow' && s.principal == '*' && s.action.to_s.match(/s3:\\*/)) ||\r\n            (s.effect == 'Allow' && s.principal == '*' && s.action.to_s.match(/s3:List/)) ||\r\n            (s.effect == 'Allow' && s.principal == '*' && s.action == '*') ||\r\n            (s.effect == 'Allow' && s.principal == { 'AWS' => '*' } && s.action.to_s.match(/s3:\\*/)) ||\r\n            (s.effect == 'Allow' && s.principal == { 'AWS' => '*' } && s.action.to_s.match(/s3:List/)) ||\r\n            (s.effect == 'Allow' && s.principal == { 'AWS' => '*' } && s.action == '*')\r\n        end\r\n        allow_all.count\r\n      end\r\n      it { should be_zero }\r\n    end\r\n  end\r\nend\r\n","source_location":{"ref":"./controls/storage/5_01_storage.rb","line":66},"id":"5_01_list"},{"title":"5.1 - AWS S3 Bucket Global DELETE Permissions must be disabled via bucket policy","desc":"This policy identifies the S3 Bucket(s) which will allow any unauthenticated user to DELETE objects from a bucket.\n  These permissions permit anyone, malicious or not, to DELETE objects from your S3 bucket if they can guess the namespace.\n  Since the S3 service does not protect the namespace other than with ACLs and Bucket Policy, you risk loss or compromise of\n  critical data by leaving this open.","descriptions":{"default":"This policy identifies the S3 Bucket(s) which will allow any unauthenticated user to DELETE objects from a bucket.\n  These permissions permit anyone, malicious or not, to DELETE objects from your S3 bucket if they can guess the namespace.\n  Since the S3 service does not protect the namespace other than with ACLs and Bucket Policy, you risk loss or compromise of\n  critical data by leaving this open."},"impact":0.8,"refs":[],"tags":{"sgs_wiki_url":"https://wiki.wdf.sap.corp/wiki/x/-0JAc","terraform_remediation":"  resource \"aws_s3_bucket_policy\" \"example_policy\" {\n    bucket = <your bucket>\n\n    policy = <<POLICY\n  {\n    \"Version\": \"2012-10-17\",\n    \"Statement\": [\n      {\n          \"Effect\": \"Allow\",\n          \"Principal\": <limited list of users>,\n          \"Action\": [<list of s3Delete actions>],\n          \"Resource\": \"<your bucket arn>/*\",\n          \"Condition\": {\n              \"IpAddress\": {\n                  \"aws:SourceIp\" : <limited IP source list>\n              }\n          }\n      }\n    ]\n  }\n  POLICY\n  }\n","tested_tf_version":"1.0.11","remediation_steps":"  1.  Log into to the AWS Management Console > Search for S3 in the search bar.\n  2.  Navigate to the bucket mentioned in the alert.\n  3.  Navigate to the permissions > Check bucket policy i.e. You can't have effect set to Allow with Principal set to * or 'AWS' => '*' and action set to s3:Delete or s3:* or * -> reference [5.1 Ensure storage services are not publicly accessible] SGS hardening guidelines for more information\n\n      *Please note: To prevent public access on AWS S3, the bucket setting “Block all public access” SHOULD be enabled. If this is not feasible because of a special use case, accessibility can be configured on a bucket level. Object level policies MUST NOT be used. When using bucket level policies, an asterisk (\"*\") MUST not be used in the principal field of any policy that grants permissions. All DELETE permissions MUST NOT be allowed to all users on the public internet.*\n  4.  Click on Edit Bucket policy to make necessary changes.\n  5.  Save changes.\n"},"code":"control '5_01_s3_global_delete' do\r\n  title '5.1 - AWS S3 Bucket Global DELETE Permissions must be disabled via bucket policy'\r\n  impact 0.8\r\n  desc 'This policy identifies the S3 Bucket(s) which will allow any unauthenticated user to DELETE objects from a bucket.\r\n  These permissions permit anyone, malicious or not, to DELETE objects from your S3 bucket if they can guess the namespace.\r\n  Since the S3 service does not protect the namespace other than with ACLs and Bucket Policy, you risk loss or compromise of\r\n  critical data by leaving this open.'\r\n  tag sgs_wiki_url: 'https://wiki.wdf.sap.corp/wiki/x/-0JAc'\r\n  tag terraform_remediation: <<-EOF\r\n  resource \"aws_s3_bucket_policy\" \"example_policy\" {\r\n    bucket = <your bucket>\r\n\r\n    policy = <<POLICY\r\n  {\r\n    \"Version\": \"2012-10-17\",\r\n    \"Statement\": [\r\n      {\r\n          \"Effect\": \"Allow\",\r\n          \"Principal\": <limited list of users>,\r\n          \"Action\": [<list of s3Delete actions>],\r\n          \"Resource\": \"<your bucket arn>/*\",\r\n          \"Condition\": {\r\n              \"IpAddress\": {\r\n                  \"aws:SourceIp\" : <limited IP source list>\r\n              }\r\n          }\r\n      }\r\n    ]\r\n  }\r\n  POLICY\r\n  }\r\n  EOF\r\n  tag tested_tf_version: '1.0.11'\r\n\r\n  tag remediation_steps: <<-EOF\r\n  1.  Log into to the AWS Management Console > Search for S3 in the search bar.\r\n  2.  Navigate to the bucket mentioned in the alert.\r\n  3.  Navigate to the permissions > Check bucket policy i.e. You can't have effect set to Allow with Principal set to * or 'AWS' => '*' and action set to s3:Delete or s3:* or * -> reference [5.1 Ensure storage services are not publicly accessible] SGS hardening guidelines for more information\r\n\r\n      *Please note: To prevent public access on AWS S3, the bucket setting “Block all public access” SHOULD be enabled. If this is not feasible because of a special use case, accessibility can be configured on a bucket level. Object level policies MUST NOT be used. When using bucket level policies, an asterisk (\"*\") MUST not be used in the principal field of any policy that grants permissions. All DELETE permissions MUST NOT be allowed to all users on the public internet.*\r\n  4.  Click on Edit Bucket policy to make necessary changes.\r\n  5.  Save changes.\r\n  EOF\r\n\r\n  aws_s3_buckets.bucket_names.each do |bucket_name|\r\n    s3_bucket = aws_s3_bucket(bucket_name: bucket_name)\r\n    next if s3_bucket.prevent_public_access?\r\n\r\n    describe \"Bucket Policy: DeleteObject for #{bucket_name}\" do\r\n      subject do\r\n        bucket_policy = s3_bucket.bucket_policy\r\n        allow_all = bucket_policy.select do |s|\r\n          (s.effect == 'Allow' && s.principal == '*' && s.action.to_s.match(/s3:\\*/)) ||\r\n            (s.effect == 'Allow' && s.principal == '*' && s.action.to_s.match(/s3:Delete/)) ||\r\n            (s.effect == 'Allow' && s.principal == '*' && s.action == '*') ||\r\n            (s.effect == 'Allow' && s.principal == { 'AWS' => '*' } && s.action.to_s.match(/s3:\\*/)) ||\r\n            (s.effect == 'Allow' && s.principal == { 'AWS' => '*' } && s.action.to_s.match(/s3:Delete/)) ||\r\n            (s.effect == 'Allow' && s.principal == { 'AWS' => '*' } && s.action == '*')\r\n        end\r\n        allow_all.count\r\n      end\r\n      it { should be_zero }\r\n    end\r\n  end\r\nend\r\n","source_location":{"ref":"./controls/storage/5_01_storage.rb","line":130},"id":"5_01_s3_global_delete"},{"title":"5.1 - AWS S3 Bucket Global PUT Permissions should be disabled via bucket policy","desc":"This policy identifies the S3 Bucket(s) which will allow any unauthenticated user to PUT objects from a bucket.\n  These permissions permit anyone, malicious or not, to PUT objects from your S3 bucket if they can guess the namespace.\n  Since the S3 service does not protect the namespace other than with ACLs and Bucket Policy, you risk loss or compromise of critical data by leaving this open.","descriptions":{"default":"This policy identifies the S3 Bucket(s) which will allow any unauthenticated user to PUT objects from a bucket.\n  These permissions permit anyone, malicious or not, to PUT objects from your S3 bucket if they can guess the namespace.\n  Since the S3 service does not protect the namespace other than with ACLs and Bucket Policy, you risk loss or compromise of critical data by leaving this open."},"impact":0.5,"refs":[],"tags":{"sgs_wiki_url":"https://wiki.wdf.sap.corp/wiki/x/-0JAc","terraform_remediation":"  resource \"aws_s3_bucket_policy\" \"example_policy\" {\n    bucket = <your bucket>\n\n    policy = <<POLICY\n  {\n    \"Version\": \"2012-10-17\",\n    \"Statement\": [\n      {\n          \"Effect\": \"Allow\",\n          \"Principal\": <limited list of users>,\n          \"Action\": [<list of s3Put actions>],\n          \"Resource\": \"<your bucket arn>/*\",\n          \"Condition\": {\n              \"IpAddress\": {\n                  \"aws:SourceIp\" : <limited IP source list>\n              }\n          }\n      }\n    ]\n  }\n  POLICY\n  }\n","tested_tf_version":"1.0.11"},"code":"control '5_01_put' do\r\n  title '5.1 - AWS S3 Bucket Global PUT Permissions should be disabled via bucket policy'\r\n  impact 0.5\r\n  desc 'This policy identifies the S3 Bucket(s) which will allow any unauthenticated user to PUT objects from a bucket.\r\n  These permissions permit anyone, malicious or not, to PUT objects from your S3 bucket if they can guess the namespace.\r\n  Since the S3 service does not protect the namespace other than with ACLs and Bucket Policy, you risk loss or compromise of critical data by leaving this open.'\r\n  tag sgs_wiki_url: 'https://wiki.wdf.sap.corp/wiki/x/-0JAc'\r\n  tag terraform_remediation: <<-EOF\r\n  resource \"aws_s3_bucket_policy\" \"example_policy\" {\r\n    bucket = <your bucket>\r\n\r\n    policy = <<POLICY\r\n  {\r\n    \"Version\": \"2012-10-17\",\r\n    \"Statement\": [\r\n      {\r\n          \"Effect\": \"Allow\",\r\n          \"Principal\": <limited list of users>,\r\n          \"Action\": [<list of s3Put actions>],\r\n          \"Resource\": \"<your bucket arn>/*\",\r\n          \"Condition\": {\r\n              \"IpAddress\": {\r\n                  \"aws:SourceIp\" : <limited IP source list>\r\n              }\r\n          }\r\n      }\r\n    ]\r\n  }\r\n  POLICY\r\n  }\r\n  EOF\r\n  tag tested_tf_version: '1.0.11'\r\n\r\n  aws_s3_buckets.bucket_names.each do |bucket_name|\r\n    s3_bucket = aws_s3_bucket(bucket_name: bucket_name)\r\n    next if s3_bucket.prevent_public_access?\r\n\r\n    describe \"Bucket Policy: PutObject for #{bucket_name}\" do\r\n      subject do\r\n        bucket_policy = s3_bucket.bucket_policy\r\n        allow_all = bucket_policy.select do |s|\r\n          (s.effect == 'Allow' && s.principal == '*' && s.action.to_s.match(/s3:\\*/)) ||\r\n            (s.effect == 'Allow' && s.principal == '*' && s.action.to_s.match(/s3:Put/)) ||\r\n            (s.effect == 'Allow' && s.principal == '*' && s.action == '*') ||\r\n            (s.effect == 'Allow' && s.principal == { 'AWS' => '*' } && s.action.to_s.match(/s3:\\*/)) ||\r\n            (s.effect == 'Allow' && s.principal == { 'AWS' => '*' } && s.action.to_s.match(/s3:Put/)) ||\r\n            (s.effect == 'Allow' && s.principal == { 'AWS' => '*' } && s.action == '*')\r\n        end\r\n        allow_all.count\r\n      end\r\n      it { should be_zero }\r\n    end\r\n  end\r\nend\r\n","source_location":{"ref":"./controls/storage/5_01_storage.rb","line":196},"id":"5_01_put"},{"title":"5.1 - AWS RDS snapshots must not be publicly accessible","desc":"Amazon RDS is an AWS service that makes it easier to manage databases. This control identifies the RDS snapshots which are\n  accessible to public. If RDS snapshots are shared in public, any unauthorized user can gain access to snapshots and sensitive data.","descriptions":{"default":"Amazon RDS is an AWS service that makes it easier to manage databases. This control identifies the RDS snapshots which are\n  accessible to public. If RDS snapshots are shared in public, any unauthorized user can gain access to snapshots and sensitive data."},"impact":0.8,"refs":[],"tags":{"sgs_wiki_url":"https://wiki.wdf.sap.corp/wiki/x/-0JAc","terraform_remediation":"  resource \"aws_db_snapshot\" \"example_rds_snapshot\" {\n    ...\n    include_public = false\n  }\n","tested_tf_version":"1.0.11","remediation_steps":"  1.  Log into to the AWS Management Console\n  2.  Search for RDS in the search bar.\n  3.  Click on Databases > Click on the name of DB identifier mentioned in the alert.\n  4.  Under the Connectivity & security tab, check the value for Publicly accessible under Security section (i.e. Yes).\n  5.  Click Modify.\n  6.  Go to Connectivity section > Click Additional configuration.\n  7.  Select Not publicly accessible > Click continue.\n  8.  Click Modify DB instance.\n      *Note: During modification process the database can go from Available to Modifying state for a short period of time so make sure you do this operation carefully and plan for any outages by consulting the responsible teams.*\n"},"code":"control '5_01_rds_snapshot_private' do\r\n  title '5.1 - AWS RDS snapshots must not be publicly accessible'\r\n  impact 0.8\r\n  desc 'Amazon RDS is an AWS service that makes it easier to manage databases. This control identifies the RDS snapshots which are\r\n  accessible to public. If RDS snapshots are shared in public, any unauthorized user can gain access to snapshots and sensitive data.'\r\n  tag sgs_wiki_url: 'https://wiki.wdf.sap.corp/wiki/x/-0JAc'\r\n  tag terraform_remediation: <<-EOF\r\n  resource \"aws_db_snapshot\" \"example_rds_snapshot\" {\r\n    ...\r\n    include_public = false\r\n  }\r\n  EOF\r\n  tag tested_tf_version: '1.0.11'\r\n\r\n  tag remediation_steps: <<-EOF\r\n  1.  Log into to the AWS Management Console\r\n  2.  Search for RDS in the search bar.\r\n  3.  Click on Databases > Click on the name of DB identifier mentioned in the alert.\r\n  4.  Under the Connectivity & security tab, check the value for Publicly accessible under Security section (i.e. Yes).\r\n  5.  Click Modify.\r\n  6.  Go to Connectivity section > Click Additional configuration.\r\n  7.  Select Not publicly accessible > Click continue.\r\n  8.  Click Modify DB instance.\r\n      *Note: During modification process the database can go from Available to Modifying state for a short period of time so make sure you do this operation carefully and plan for any outages by consulting the responsible teams.*\r\n  EOF\r\n\r\n  aws_rds_snapshots.db_snapshot_identifiers.each do |db_snapshot_identifier|\r\n    rds_snapshot_attributes = aws_rds_snapshot_attributes(db_snapshot_identifier: db_snapshot_identifier).where(attribute_name: 'restore')\r\n    rds_snapshot_attributes.attribute_values.each do |attribute_value|\r\n      describe \"RDS snapshot attributes for #{db_snapshot_identifier}\" do\r\n        subject { attribute_value }\r\n        it { should_not include 'all' }\r\n      end\r\n    end\r\n  end\r\nend\r\n","source_location":{"ref":"./controls/storage/5_01_storage.rb","line":251},"id":"5_01_rds_snapshot_private"},{"title":"5.2 - AWS S3 buckets must have server side encryption enabled","desc":"Data in S3 buckets must be protected by using the AWS server-side encryption. If the server-side encryption is not turned on for S3 buckets with sensitive data, in the event of a data breach, malicious users can gain access to the data.","descriptions":{"default":"Data in S3 buckets must be protected by using the AWS server-side encryption. If the server-side encryption is not turned on for S3 buckets with sensitive data, in the event of a data breach, malicious users can gain access to the data."},"impact":0.8,"refs":[],"tags":{"sgs_control_hash":"8ae223887226fcbd01722703b9830032","sgs_wiki_url":"https://wiki.wdf.sap.corp/wiki/x/-0JAc","terraform_remediation":"  resource \"aws_s3_bucket\" \"example_bucket\" {\n    ...\n    server_side_encryption_configuration {\n      rule {\n        apply_server_side_encryption_by_default {\n          sse_algorithm = \"aws:kms\"\n        }\n      }\n    }\n  }\n","tested_tf_version":"1.0.11","remediation_steps":"  1.  Log into to the AWS Management Console.\n  2.  Search for S3 in the search bar.\n  3.  Select the S3 bucket in the alert.\n  4.  Click on the 'Properties' tab.\n  5.  Under the 'Default encryption' section, click 'Edit', under 'Server-side encryption', choose 'Enable', choose encryption option either 'Amazon S3-managed keys (SSE-S3)' or 'AWS Key Management Service key (SSE-KMS)' based on your requirement.\n"},"code":"control '5_02_s3_bucket_encryption_enabled' do\r\n  impact 0.8\r\n  title '5.2 - AWS S3 buckets must have server side encryption enabled'\r\n  desc 'Data in S3 buckets must be protected by using the AWS server-side encryption. If the server-side encryption is not turned on for S3 buckets with sensitive data, in the event of a data breach, malicious users can gain access to the data.'\r\n  tag sgs_control_hash: '8ae223887226fcbd01722703b9830032'\r\n  tag sgs_wiki_url: 'https://wiki.wdf.sap.corp/wiki/x/-0JAc'\r\n  tag terraform_remediation: <<-EOF\r\n  resource \"aws_s3_bucket\" \"example_bucket\" {\r\n    ...\r\n    server_side_encryption_configuration {\r\n      rule {\r\n        apply_server_side_encryption_by_default {\r\n          sse_algorithm = \"aws:kms\"\r\n        }\r\n      }\r\n    }\r\n  }\r\n  EOF\r\n  tag tested_tf_version: '1.0.11'\r\n\r\n  tag remediation_steps: <<-EOF\r\n  1.  Log into to the AWS Management Console.\r\n  2.  Search for S3 in the search bar.\r\n  3.  Select the S3 bucket in the alert.\r\n  4.  Click on the 'Properties' tab.\r\n  5.  Under the 'Default encryption' section, click 'Edit', under 'Server-side encryption', choose 'Enable', choose encryption option either 'Amazon S3-managed keys (SSE-S3)' or 'AWS Key Management Service key (SSE-KMS)' based on your requirement.\r\n  EOF\r\n\r\n  aws_s3_buckets.bucket_names.each do |bucket_name|\r\n    s3_bucket = aws_s3_bucket(bucket_name: bucket_name)\r\n    next if s3_bucket.tags['sec-by-def-encrypt-storage-exception'] == 'enabled'\r\n    describe s3_bucket do\r\n      it { should have_default_encryption_enabled }\r\n    end\r\n  end\r\nend\r\n","source_location":{"ref":"./controls/storage/5_02_storage.rb","line":1},"id":"5_02_s3_bucket_encryption_enabled"},{"title":"5.3 - AWS S3 buckets must always use encrypted communication (secure transfer is enabled) - Encrypt inbound and outbound S3 data traffic","desc":"Use S3 SSL endpoints to safely transfer data via HTTPS. All access to S3 storage buckets must be performed by using an encrypted connection TLS 1.2 or higher to ensure that the transferred data cannot be intercepted by unauthorized third parties.","descriptions":{"default":"Use S3 SSL endpoints to safely transfer data via HTTPS. All access to S3 storage buckets must be performed by using an encrypted connection TLS 1.2 or higher to ensure that the transferred data cannot be intercepted by unauthorized third parties."},"impact":0.8,"refs":[],"tags":{"sgs_control_hash":"8ae223887226fcbd01722703b9830038","sgs_wiki_url":"https://wiki.wdf.sap.corp/wiki/x/-0JAc","terraform_remediation":"  resource \"aws_s3_bucket_policy\" \"example_s3_bucket\" {\n    ...\n\n    policy = <<POLICY\n  {\n    \"Version\": \"2012-10-17\",\n    \"Statement\": [\n      {\n          \"Effect\": \"Deny\",\n          \"Principal\": \"*\",\n          \"Action\": \"s3:*\",\n          \"Resource\": \"<bucket arn>/*\",\n          \"Condition\": {\n              \"Bool\": {\n                  \"aws:SecureTransport\": \"false\"\n              }\n          }\n      }\n    ]\n  }\n  POLICY\n  }\n","tested_tf_version":"1.0.11","remediation_steps":"  1.  Log in to the AWS Management Console.\n  2.  Search for S3 in the search bar.\n  3.  Select the S3 bucket mentioned in the alert.\n  4.  Click on the 'Permissions' tab.\n  5.  Under 'Bucket Policy' click edit to deny all access from anybody to Amazon S3 objects within an Amazon S3 bucket if they are not accessed through HTTPS.\n      Below is the sample policy:\n\n      ```\n      {\n          \"Version\": \"2012-10-17\",\n          \"Statement\": [\n            {\n                \"Effect\": \"Deny\",\n                \"Principal\": \"*\",\n                \"Action\": \"s3:*\",\n                \"Resource\": \"<bucket arn>/*\",\n                \"Condition\": {\n                    \"Bool\": {\n                        \"aws:SecureTransport\": \"false\"\n                    }\n                }\n            }\n          ]\n        }\n      ```\n"},"code":"control '5_03_s3_secure_transport_enabled' do\r\n  impact 0.8\r\n  title '5.3 - AWS S3 buckets must always use encrypted communication (secure transfer is enabled) - Encrypt inbound and outbound S3 data traffic'\r\n  desc 'Use S3 SSL endpoints to safely transfer data via HTTPS. All access to S3 storage buckets must be performed by using an encrypted connection TLS 1.2 or higher to ensure that the transferred data cannot be intercepted by unauthorized third parties.'\r\n\r\n  tag sgs_control_hash: '8ae223887226fcbd01722703b9830038'\r\n  tag sgs_wiki_url: 'https://wiki.wdf.sap.corp/wiki/x/-0JAc'\r\n  tag terraform_remediation: <<-EOF\r\n  resource \"aws_s3_bucket_policy\" \"example_s3_bucket\" {\r\n    ...\r\n\r\n    policy = <<POLICY\r\n  {\r\n    \"Version\": \"2012-10-17\",\r\n    \"Statement\": [\r\n      {\r\n          \"Effect\": \"Deny\",\r\n          \"Principal\": \"*\",\r\n          \"Action\": \"s3:*\",\r\n          \"Resource\": \"<bucket arn>/*\",\r\n          \"Condition\": {\r\n              \"Bool\": {\r\n                  \"aws:SecureTransport\": \"false\"\r\n              }\r\n          }\r\n      }\r\n    ]\r\n  }\r\n  POLICY\r\n  }\r\n  EOF\r\n  tag tested_tf_version: '1.0.11'\r\n\r\n  tag remediation_steps: <<-EOF\r\n  1.  Log in to the AWS Management Console.\r\n  2.  Search for S3 in the search bar.\r\n  3.  Select the S3 bucket mentioned in the alert.\r\n  4.  Click on the 'Permissions' tab.\r\n  5.  Under 'Bucket Policy' click edit to deny all access from anybody to Amazon S3 objects within an Amazon S3 bucket if they are not accessed through HTTPS.\r\n      Below is the sample policy:\r\n\r\n      ```\r\n      {\r\n          \"Version\": \"2012-10-17\",\r\n          \"Statement\": [\r\n            {\r\n                \"Effect\": \"Deny\",\r\n                \"Principal\": \"*\",\r\n                \"Action\": \"s3:*\",\r\n                \"Resource\": \"<bucket arn>/*\",\r\n                \"Condition\": {\r\n                    \"Bool\": {\r\n                        \"aws:SecureTransport\": \"false\"\r\n                    }\r\n                }\r\n            }\r\n          ]\r\n        }\r\n      ```\r\n  EOF\r\n\r\n  aws_s3_buckets.bucket_names.each do |bucket_name|\r\n    describe aws_s3_bucket(bucket_name: bucket_name) do\r\n      it { should have_secure_transport_enabled }\r\n    end\r\n  end\r\nend\r\n","source_location":{"ref":"./controls/storage/5_03_storage.rb","line":1},"id":"5_03_s3_secure_transport_enabled"},{"title":"6.2 - AWS MQ should not be publicly accessible","desc":"This control enforces the AWS MQ brokers to not be publicly accessible. From a security perspective it is always\n  advisable to use MQ brokers privately only from within your AWS Virtual Private Cloud (VPC). This will avoid sensitive data\n  exposure and minimize security risks.","descriptions":{"default":"This control enforces the AWS MQ brokers to not be publicly accessible. From a security perspective it is always\n  advisable to use MQ brokers privately only from within your AWS Virtual Private Cloud (VPC). This will avoid sensitive data\n  exposure and minimize security risks."},"impact":0.5,"refs":[],"tags":{"sgs_wiki_url":"https://wiki.wdf.sap.corp/wiki/x/-0JAc","terraform_remediation":"  resource \"aws_mq_broker\" \"example_mq_broker\" {\n    publicly_accessible = false\n    ...\n  }\n","tested_tf_version":"1.0.11","remediation_steps":"  1.  Login to AWS Management console.\n  2.  Select Services > Application Integration > Amazon MQ OR Search for Amazon MQ in the search bar.\n  3.  Navigate to broker mentioned in the alert.\n  4.  In Detail section > Security and network > Check Public accessibility (i.e. Yes).\n      Note: Once the broker is created public accessibility config setting can't be modified hence you need to create new broker with Public accessibility set to No.\n  5.  Click Create brokers > Select broker engine (make sure you select the correct setting by checking existing broker engine type) > Click Next.\n  6.  Select Deployment mode and storage type (make sure to select the correct setting by checking existing broker config) > Click Next.\n  7.  Fill all the required fields in Configure settings screen > In Additional settings choose Private access > Click Next > Click Create broker.\n\n      Reference AWS Guide: <https://docs.aws.amazon.com/amazon-mq/latest/developer-guide/amazon-mq-creating-configuring-broker.html>\n\n      Note: Delete publicly accessible broker (ensure that team responsible for managing this broker is aware before carrying out the delete activity) only when the new broker is successfully created.\n"},"code":"control '6_02_mq_public' do\r\n  title '6.2 - AWS MQ should not be publicly accessible'\r\n  desc 'This control enforces the AWS MQ brokers to not be publicly accessible. From a security perspective it is always\r\n  advisable to use MQ brokers privately only from within your AWS Virtual Private Cloud (VPC). This will avoid sensitive data\r\n  exposure and minimize security risks.'\r\n  tag sgs_wiki_url: 'https://wiki.wdf.sap.corp/wiki/x/-0JAc'\r\n  tag terraform_remediation: <<-EOF\r\n  resource \"aws_mq_broker\" \"example_mq_broker\" {\r\n    publicly_accessible = false\r\n    ...\r\n  }\r\n  EOF\r\n  tag tested_tf_version: '1.0.11'\r\n\r\n  tag remediation_steps: <<-EOF\r\n  1.  Login to AWS Management console.\r\n  2.  Select Services > Application Integration > Amazon MQ OR Search for Amazon MQ in the search bar.\r\n  3.  Navigate to broker mentioned in the alert.\r\n  4.  In Detail section > Security and network > Check Public accessibility (i.e. Yes).\r\n      Note: Once the broker is created public accessibility config setting can't be modified hence you need to create new broker with Public accessibility set to No.\r\n  5.  Click Create brokers > Select broker engine (make sure you select the correct setting by checking existing broker engine type) > Click Next.\r\n  6.  Select Deployment mode and storage type (make sure to select the correct setting by checking existing broker config) > Click Next.\r\n  7.  Fill all the required fields in Configure settings screen > In Additional settings choose Private access > Click Next > Click Create broker.\r\n\r\n      Reference AWS Guide: <https://docs.aws.amazon.com/amazon-mq/latest/developer-guide/amazon-mq-creating-configuring-broker.html>\r\n\r\n      Note: Delete publicly accessible broker (ensure that team responsible for managing this broker is aware before carrying out the delete activity) only when the new broker is successfully created.\r\n  EOF\r\n\r\n  aws_regions.region_names.each do |region_name|\r\n    next if region_name == 'me-central-1'\r\n\r\n    aws_mq_brokers(aws_region: region_name).broker_ids.each do |mq_broker|\r\n      describe aws_mq_broker(aws_region: region_name, broker_id: mq_broker) do\r\n        its('publicly_accessible') { should eq false }\r\n      end\r\n    end\r\n  end\r\nend\r\n","source_location":{"ref":"./controls/storage/6_02_storage.rb","line":1},"id":"6_02_mq_public"},{"title":"6.3 - AWS RDS instance Automatic Backup should be enabled","desc":"When Automatic Backup is enabled, RDS creates a storage volume snapshot of your DB instance that backs up the entire DB instance\n  for point-in-time recovery. This automatic backup happens within a specific backup window time and keeps the backup for\n  limited period of time as defined in the retention period. It is recommended to set Automatic backups for your critical RDS servers for\n  data restoration process. This control identifies RDS instances which are not set with the Automatic Backup setting","descriptions":{"default":"When Automatic Backup is enabled, RDS creates a storage volume snapshot of your DB instance that backs up the entire DB instance\n  for point-in-time recovery. This automatic backup happens within a specific backup window time and keeps the backup for\n  limited period of time as defined in the retention period. It is recommended to set Automatic backups for your critical RDS servers for\n  data restoration process. This control identifies RDS instances which are not set with the Automatic Backup setting"},"impact":0.5,"refs":[],"tags":{"sgs_wiki_url":"https://wiki.wdf.sap.corp/wiki/x/-0JAc","terraform_remediation":"  resource \"aws_db_instance\" \"example_rds_instance\" {\n    ...\n    backup_retention_period = <number of days to backup>\n  }\n","tested_tf_version":"1.0.11","remediation_steps":"  1.  Log into to the AWS Management Console.\n  2.  Search for RDS in the search bar.\n  3.  Select DB Instances > Navigate to the DB identifier mentioned in the alert.\n  4.  Select Maintenance & backups tab.\n  5.  Go to Backup section.\n  6.  Check Automated backups setting to see if it is Disabled.\n      Note: Before applying the below step please ensure that the team responsible for the database in question is aware of this activity for any impact/outage.\n  7.  In order to enable automated backups setting please follow the step by step AWS RDS user guide: <https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_WorkingWithAutomatedBackups.html#USER_WorkingWithAutomatedBackups.Enabling>\n"},"code":"control '6_03_rds_instance_backup' do\r\n  title '6.3 - AWS RDS instance Automatic Backup should be enabled'\r\n  impact 0.5\r\n  desc 'When Automatic Backup is enabled, RDS creates a storage volume snapshot of your DB instance that backs up the entire DB instance\r\n  for point-in-time recovery. This automatic backup happens within a specific backup window time and keeps the backup for\r\n  limited period of time as defined in the retention period. It is recommended to set Automatic backups for your critical RDS servers for\r\n  data restoration process. This control identifies RDS instances which are not set with the Automatic Backup setting'\r\n  tag sgs_wiki_url: 'https://wiki.wdf.sap.corp/wiki/x/-0JAc'\r\n  tag terraform_remediation: <<-EOF\r\n  resource \"aws_db_instance\" \"example_rds_instance\" {\r\n    ...\r\n    backup_retention_period = <number of days to backup>\r\n  }\r\n  EOF\r\n  tag tested_tf_version: '1.0.11'\r\n\r\n  tag remediation_steps: <<-EOF\r\n  1.  Log into to the AWS Management Console.\r\n  2.  Search for RDS in the search bar.\r\n  3.  Select DB Instances > Navigate to the DB identifier mentioned in the alert.\r\n  4.  Select Maintenance & backups tab.\r\n  5.  Go to Backup section.\r\n  6.  Check Automated backups setting to see if it is Disabled.\r\n      Note: Before applying the below step please ensure that the team responsible for the database in question is aware of this activity for any impact/outage.\r\n  7.  In order to enable automated backups setting please follow the step by step AWS RDS user guide: <https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_WorkingWithAutomatedBackups.html#USER_WorkingWithAutomatedBackups.Enabling>\r\n  EOF\r\n\r\n  aws_regions.region_names.each do |region_name|\r\n    aws_rds_instances(aws_region: region_name).db_instance_identifiers.each do |db_instance_identifier|\r\n      describe aws_rds_instance(aws_region: region_name, db_instance_identifier: db_instance_identifier) do\r\n        its('backup_retention_period') { should be > 0 }\r\n      end\r\n    end\r\n  end\r\nend\r\n","source_location":{"ref":"./controls/storage/6_03_storage.rb","line":1},"id":"6_03_rds_instance_backup"},{"title":"8.3 - AWS RDS database instance must not be publicly accessible","desc":"This policy identifies RDS database instances which are publicly accessible. DB instances must not be publicly accessible to protect the integrity of data.\n  Public accessibility of DB instances can be modified by turning on or off the Public accessibility parameter.","descriptions":{"default":"This policy identifies RDS database instances which are publicly accessible. DB instances must not be publicly accessible to protect the integrity of data.\n  Public accessibility of DB instances can be modified by turning on or off the Public accessibility parameter."},"impact":0.8,"refs":[],"tags":{"sgs_wiki_url":"https://wiki.wdf.sap.corp/wiki/x/-0JAc","terraform_remediation":"  resource \"aws_db_instance\" \"example_rds_instance\" {\n    ...\n    publicly_accessible  = false\n  }\n\n","tested_tf_version":"1.0.11","remediation_steps":"  1.  Log into to the AWS Management Console.\n  2.  Search for RDS in the search bar.\n  3.  Click on Databases > Click on the DB identifier mentioned in the alert.\n  4.  Click Modify > Scroll down to Connectivity > Click on Additional configuration > Click Not publicly accessible.\n  5.  Click Continue > Click Modify DB Instance.\n  6.  Verify Changes and Save.\n"},"code":"control '8_03_rds_instance_publicly_accessible' do\r\n  title '8.3 - AWS RDS database instance must not be publicly accessible'\r\n  impact 0.8\r\n  desc 'This policy identifies RDS database instances which are publicly accessible. DB instances must not be publicly accessible to protect the integrity of data.\r\n  Public accessibility of DB instances can be modified by turning on or off the Public accessibility parameter.'\r\n  tag sgs_wiki_url: 'https://wiki.wdf.sap.corp/wiki/x/-0JAc'\r\n  tag terraform_remediation: <<-EOF\r\n  resource \"aws_db_instance\" \"example_rds_instance\" {\r\n    ...\r\n    publicly_accessible  = false\r\n  }\r\n\r\n  EOF\r\n  tag tested_tf_version: '1.0.11'\r\n\r\n  tag remediation_steps: <<-EOF\r\n  1.  Log into to the AWS Management Console.\r\n  2.  Search for RDS in the search bar.\r\n  3.  Click on Databases > Click on the DB identifier mentioned in the alert.\r\n  4.  Click Modify > Scroll down to Connectivity > Click on Additional configuration > Click Not publicly accessible.\r\n  5.  Click Continue > Click Modify DB Instance.\r\n  6.  Verify Changes and Save.\r\n  EOF\r\n\r\n  aws_regions.region_names.each do |region_name|\r\n    aws_rds_instances(aws_region: region_name).db_instance_identifiers.each do |db_instance_identifier|\r\n      describe aws_rds_instance(aws_region: region_name, db_instance_identifier: db_instance_identifier) do\r\n        its('publicly_accessible') { should eq false }\r\n      end\r\n    end\r\n  end\r\nend\r\n","source_location":{"ref":"./controls/storage/8_03_storage.rb","line":1},"id":"8_03_rds_instance_publicly_accessible"},{"title":"8.3 - AWS RDS database instance should not be in a public subnet","desc":"RDS should not be deployed in a public subnet. Production databases should be located behind a DMZ in a private subnet with limited access.","descriptions":{"default":"RDS should not be deployed in a public subnet. Production databases should be located behind a DMZ in a private subnet with limited access."},"impact":0.5,"refs":[],"tags":{"sgs_wiki_url":"https://wiki.wdf.sap.corp/wiki/x/-0JAc","terraform_remediation":"  resource \"aws_db_instance\" \"example_rds_instance\" {\n    ...\n    db_subnet_group_name = <name of subnet group>\n  }\n\n","tested_tf_version":"1.0.11","terraform_remediation_note":"The subnet should not be associated with an internet gateway that allows all IP destinations.","remediation_steps":"  In order to remediate this alert, you will need to redeploy RDS into a private RDS Subnet group.\n\n  Please note: You can't move an existing RDS instance from one subnet to another.\n\n  To create a RDS Subnet group, please do the following steps:\n\n  (A DB subnet group is a collection of subnets that you create for a VPC and then utilize for your DB instances.)\n\n  1.  Open the Amazon RDS console (or search for RDS in the search bar.\n  2.  In the navigation pane, choose Subnet groups.\n  3.  Click Create DB Subnet Group > Enter the Name of your DB subnet group.\n  4.  Enter a Description for your DB subnet group > Select your VPC > Select Availability Zones.\n  5.  In the Add subnets section, add your Private subnets related to the above VPC.\n  6.  Click Create.\n\n  When creating your RDS DB, under Configure advanced settings, choose the Subnet group created above.\n"},"code":"control '8_03_rds_instance_in_public_subnet' do\r\n  title '8.3 - AWS RDS database instance should not be in a public subnet'\r\n  impact 0.5\r\n  desc 'RDS should not be deployed in a public subnet. Production databases should be located behind a DMZ in a private subnet with limited access.'\r\n  tag sgs_wiki_url: 'https://wiki.wdf.sap.corp/wiki/x/-0JAc'\r\n  tag terraform_remediation: <<-EOF\r\n  resource \"aws_db_instance\" \"example_rds_instance\" {\r\n    ...\r\n    db_subnet_group_name = <name of subnet group>\r\n  }\r\n\r\n  EOF\r\n  tag tested_tf_version: '1.0.11'\r\n  tag terraform_remediation_note: 'The subnet should not be associated with an internet gateway that allows all IP destinations.'\r\n\r\n  tag remediation_steps: <<-EOF\r\n  In order to remediate this alert, you will need to redeploy RDS into a private RDS Subnet group.\r\n\r\n  Please note: You can't move an existing RDS instance from one subnet to another.\r\n\r\n  To create a RDS Subnet group, please do the following steps:\r\n\r\n  (A DB subnet group is a collection of subnets that you create for a VPC and then utilize for your DB instances.)\r\n\r\n  1.  Open the Amazon RDS console (or search for RDS in the search bar.\r\n  2.  In the navigation pane, choose Subnet groups.\r\n  3.  Click Create DB Subnet Group > Enter the Name of your DB subnet group.\r\n  4.  Enter a Description for your DB subnet group > Select your VPC > Select Availability Zones.\r\n  5.  In the Add subnets section, add your Private subnets related to the above VPC.\r\n  6.  Click Create.\r\n\r\n  When creating your RDS DB, under Configure advanced settings, choose the Subnet group created above.\r\n  EOF\r\n\r\n  aws_regions.region_names.each do |region_name|\r\n    aws_rds_instances(aws_region: region_name).db_instance_identifiers.each do |db_instance_identifier|\r\n      rds_instance = aws_rds_instance(aws_region: region_name, db_instance_identifier: db_instance_identifier)\r\n      subnets_db_subnet_group_members = rds_instance.db_subnet_group.subnets\r\n\r\n      subnets_db_subnet_group_members.each do |subnet|\r\n        associated_route_tables = aws_route_tables(aws_region: region_name).table.select { |n| n[:vpc_id] == rds_instance.db_subnet_group.vpc_id && n[:associated_subnet_ids].include?(subnet.subnet_identifier) }\r\n        # in this case, the subnet is implicitly associated with the main routing table, since it doesn't have an explicit association\r\n        if associated_route_tables.count == 0\r\n          main_table = aws_route_tables(aws_region: region_name).where(vpc_id: rds_instance.db_subnet_group.vpc_id, main: true)\r\n\r\n          # control fails only if route table has an internet gateway and destination CIDR block for the internet\r\n          describe.one do\r\n            describe \"Subnet #{subnet.subnet_identifier} for RDS instance #{db_instance_identifier} should not be implicitly associated to main routing table with 0.0.0.0/0 destination CIDR block\" do\r\n              subject { main_table.destination_cidr_blocks.compact }\r\n              it { should_not include '0.0.0.0/0' }\r\n            end\r\n            describe \"Subnet #{subnet.subnet_identifier} for RDS instance #{db_instance_identifier} should not be implicitly associated to main routing table with internet gateway\" do\r\n              internet_gateways = main_table.gateway_ids.select { |i| i[/igw/] }\r\n              subject { internet_gateways }\r\n              its('count') { should eq 0 }\r\n            end\r\n          end\r\n          describe.one do\r\n            describe \"Subnet #{subnet.subnet_identifier} for RDS instance #{db_instance_identifier} should not be implicitly associated to main routing table with ::/0 ipv6 destination CIDR block\" do\r\n              subject { main_table.destination_ipv_6_cidr_blocks.compact }\r\n              it { should_not include '::/0' }\r\n            end\r\n            describe \"Subnet #{subnet.subnet_identifier} for RDS instance #{db_instance_identifier} should not be implicitly associated to main routing table with internet gateway\" do\r\n              internet_gateways = main_table.gateway_ids.select { |i| i[/igw/] }\r\n              subject { internet_gateways }\r\n              its('count') { should eq 0 }\r\n            end\r\n          end\r\n\r\n        # in this case, the subnet is explicitly associated with a routing table\r\n        elsif associated_route_tables.count == 1\r\n          # control fails only if route table has an internet gateway and destination CIDR block for the internet\r\n          describe.one do\r\n            describe \"Subnet #{subnet.subnet_identifier} for RDS instance #{db_instance_identifier} should not be associated to routing table with 0.0.0.0/0 destination CIDR block\" do\r\n              subject { associated_route_tables[0][:destination_cidr_block].compact }\r\n              it { should_not include '0.0.0.0/0' }\r\n            end\r\n            describe \"Subnet #{subnet.subnet_identifier} for RDS instance #{db_instance_identifier} should not be associated to routing table with internet gateway\" do\r\n              gateway_ids = associated_route_tables[0][:gateway_id].compact\r\n              internet_gateways = gateway_ids.select { |i| i[/igw/] }\r\n              subject { internet_gateways }\r\n              its('count') { should eq 0 }\r\n            end\r\n          end\r\n          describe.one do\r\n            describe \"Subnet #{subnet.subnet_identifier} for RDS instance #{db_instance_identifier} should not be associated to routing table with ::/0 ipv6 destination CIDR block\" do\r\n              subject { associated_route_tables[0][:destination_ipv_6_cidr_block].compact }\r\n              it { should_not include '::/0' }\r\n            end\r\n            describe \"Subnet #{subnet.subnet_identifier} for RDS instance #{db_instance_identifier} should not be associated to routing table with internet gateway\" do\r\n              gateway_ids = associated_route_tables[0][:gateway_id].compact\r\n              internet_gateways = gateway_ids.select { |i| i[/igw/] }\r\n              subject { internet_gateways }\r\n              its('count') { should eq 0 }\r\n            end\r\n          end\r\n        end\r\n      end\r\n    end\r\n  end\r\nend\r\n","source_location":{"ref":"./controls/storage/8_03_storage.rb","line":34},"id":"8_03_rds_instance_in_public_subnet"},{"title":"8.3 - AWS RDS instance must be encrypted","desc":"This policy identifies AWS RDS instances which are not encrypted.\n  Amazon Relational Database Service (Amazon RDS) is a web service that makes it easier to set up and manage databases.\n  Amazon allows customers to turn on encryption for RDS which is recommended for compliance and security reasons.","descriptions":{"default":"This policy identifies AWS RDS instances which are not encrypted.\n  Amazon Relational Database Service (Amazon RDS) is a web service that makes it easier to set up and manage databases.\n  Amazon allows customers to turn on encryption for RDS which is recommended for compliance and security reasons."},"impact":0.8,"refs":[],"tags":{"sgs_wiki_url":"https://wiki.wdf.sap.corp/wiki/x/-0JAc","terraform_remediation":"  resource \"aws_db_instance\" \"example_rds_instance\" {\n    ...\n    storage_encrypted    = true\n  }\n","tested_tf_version":"1.0.11","remediation_steps":"  You can only enable encryption for an Amazon RDS DB instance when you create it, not after the DB instance is created.\n\n  1.  Log into to the AWS Management Console.\n  2.  Search for RDS in the search bar.\n  3.  Click on Databases > Click on the DB identifier mentioned in the alert > Click on the Configuration tab.\n  4.  Check the value for Encryption key under Storage section (i.e. Not enabled).\n  5.  Create a new DB instance with encryption enabled.\n  6.  Migrate all required data from existing non encrypted DB instance to new encrypted DB instance.\n\n  To create RDS DB instance with encryption follow the AWS guide below,\n  <https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/Overview.Encryption.html>\n"},"code":"control '8_03_rds' do\r\n  title '8.3 - AWS RDS instance must be encrypted'\r\n  impact 0.8\r\n  desc 'This policy identifies AWS RDS instances which are not encrypted.\r\n  Amazon Relational Database Service (Amazon RDS) is a web service that makes it easier to set up and manage databases.\r\n  Amazon allows customers to turn on encryption for RDS which is recommended for compliance and security reasons.'\r\n  tag sgs_wiki_url: 'https://wiki.wdf.sap.corp/wiki/x/-0JAc'\r\n  tag terraform_remediation: <<-EOF\r\n  resource \"aws_db_instance\" \"example_rds_instance\" {\r\n    ...\r\n    storage_encrypted    = true\r\n  }\r\n  EOF\r\n  tag tested_tf_version: '1.0.11'\r\n\r\n  tag remediation_steps: <<-EOF\r\n  You can only enable encryption for an Amazon RDS DB instance when you create it, not after the DB instance is created.\r\n\r\n  1.  Log into to the AWS Management Console.\r\n  2.  Search for RDS in the search bar.\r\n  3.  Click on Databases > Click on the DB identifier mentioned in the alert > Click on the Configuration tab.\r\n  4.  Check the value for Encryption key under Storage section (i.e. Not enabled).\r\n  5.  Create a new DB instance with encryption enabled.\r\n  6.  Migrate all required data from existing non encrypted DB instance to new encrypted DB instance.\r\n\r\n  To create RDS DB instance with encryption follow the AWS guide below,\r\n  <https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/Overview.Encryption.html>\r\n  EOF\r\n\r\n  aws_regions.region_names.each do |region_name|\r\n    aws_rds_instances(aws_region: region_name).entries.each do |rds_instance|\r\n      next if rds_instance.engine == 'sqlserver-ex' || !rds_instance.tag_list.select { |tag| tag[:key] == 'sec-by-def-rds-encryption-exception' && tag[:value] == 'enabled' }.empty?\r\n      describe \"RDS instance #{rds_instance.db_instance_identifier} in region #{region_name}\" do\r\n        subject { rds_instance }\r\n        its('storage_encrypted') { should eq true }\r\n      end\r\n    end\r\n  end\r\nend\r\n","source_location":{"ref":"./controls/storage/8_03_storage.rb","line":136},"id":"8_03_rds"},{"title":"8.3 - AWS RDS DB cluster encryption should be enabled","desc":"This policy identifies AWS RDS DB clusters which are not encrypted.\n\n  Amazon Relational Database Service (Amazon RDS) is a web service that makes\n  it easier to set up, operate, and scale a relational database in the AWS\n  Cloud. RDS database clusters should have encryption enabled, as per the\n  SGS Amazon Cloud wiki policy.","descriptions":{"default":"This policy identifies AWS RDS DB clusters which are not encrypted.\n\n  Amazon Relational Database Service (Amazon RDS) is a web service that makes\n  it easier to set up, operate, and scale a relational database in the AWS\n  Cloud. RDS database clusters should have encryption enabled, as per the\n  SGS Amazon Cloud wiki policy."},"impact":0.5,"refs":[],"tags":{"sgs_wiki_url":"https://wiki.wdf.sap.corp/wiki/x/-0JAc","terraform_remediation":"  resource \"aws_rds_cluster\" \"example_rds_cluster\" {\n    ...\n    storage_encrypted       = true\n  }\n","tested_tf_version":"1.0.11","remediation_steps":"  AWS DB clusters can only be encrypted when creating the database cluster. You can't convert an unencrypted DB cluster into an encrypted one. You can restore an unencrypted Aurora DB cluster snapshot to a new encrypted Aurora DB cluster. To do that, you'll need to specify a KMS encryption key when you restore from the unencrypted DB cluster snapshot.\n\n  For AWS RDS:\n  1.  To create a 'Snapshot' of the unencrypted DB cluster, please follow the instructions listed in this link: <https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/USER_CreateSnapshotCluster.html>\n\n      Please note that you can't restore from a DB cluster snapshot to an existing DB cluster; instead a new DB cluster is created when you restore. Once the Snapshot status is showing as Available, delete the unencrypted DB cluster before restoring from the DB cluster Snapshot by performing the following steps:\n\n        a.  Sign to the AWS Management Console > open the Amazon RDS console (or search for RDS in the search bar).\n\n        b.  In the left side navigation pane, click on Databases.\n\n        c.  In the list of DB instances, click on the bubble by the DB identifier you'd like to delete > Click Actions > Click Delete.\n  2.  To restoring the Cluster from a DB Cluster Snapshot, please follow the instructions listed in this link: <https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/USER_RestoreFromSnapshot.html>\n\n  For AWS Document DB:\n  1.  To create a 'Snapshot' of the unencrypted DB cluster, follow the instructions listed in this link: <https://docs.aws.amazon.com/documentdb/latest/developerguide/backup_restore-create_manual_cluster_snapshot.html>\n\n        Please note that you can't restore from a DB cluster snapshot to an existing DB cluster; instead a new DB cluster is created when you restore. Once the Snapshot status is showing as Available, delete the unencrypted DB cluster before restoring from the DB cluster Snapshot by following below steps for AWS Document DB,\n\n        a.  Sign to the AWS Management Console > open the Amazon DocumentDB console (or search for DocumentDB in the search bar).\n\n        b.  In the navigation pane, Click Clusters.\n\n        c.  Click the checkbox of the cluster identifier that you'd like to delete > Click Actions > Click Delete.\n\n  3.  To restore the Cluster from a DB Cluster Snapshot, follow the instructions listed in this link: <https://docs.aws.amazon.com/documentdb/latest/developerguide/backup_restore-restore_from_snapshot.html>\n"},"code":"control '8_03_enable_cluster_encryption' do\r\n  title '8.3 - AWS RDS DB cluster encryption should be enabled'\r\n  impact 0.5\r\n  desc 'This policy identifies AWS RDS DB clusters which are not encrypted.\r\n\r\n  Amazon Relational Database Service (Amazon RDS) is a web service that makes\r\n  it easier to set up, operate, and scale a relational database in the AWS\r\n  Cloud. RDS database clusters should have encryption enabled, as per the\r\n  SGS Amazon Cloud wiki policy.'\r\n  tag sgs_wiki_url: 'https://wiki.wdf.sap.corp/wiki/x/-0JAc'\r\n  tag terraform_remediation: <<-EOF\r\n  resource \"aws_rds_cluster\" \"example_rds_cluster\" {\r\n    ...\r\n    storage_encrypted       = true\r\n  }\r\n  EOF\r\n  tag tested_tf_version: '1.0.11'\r\n\r\n  tag remediation_steps: <<-EOF\r\n  AWS DB clusters can only be encrypted when creating the database cluster. You can't convert an unencrypted DB cluster into an encrypted one. You can restore an unencrypted Aurora DB cluster snapshot to a new encrypted Aurora DB cluster. To do that, you'll need to specify a KMS encryption key when you restore from the unencrypted DB cluster snapshot.\r\n\r\n  For AWS RDS:\r\n  1.  To create a 'Snapshot' of the unencrypted DB cluster, please follow the instructions listed in this link: <https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/USER_CreateSnapshotCluster.html>\r\n\r\n      Please note that you can't restore from a DB cluster snapshot to an existing DB cluster; instead a new DB cluster is created when you restore. Once the Snapshot status is showing as Available, delete the unencrypted DB cluster before restoring from the DB cluster Snapshot by performing the following steps:\r\n\r\n        a.  Sign to the AWS Management Console > open the Amazon RDS console (or search for RDS in the search bar).\r\n\r\n        b.  In the left side navigation pane, click on Databases.\r\n\r\n        c.  In the list of DB instances, click on the bubble by the DB identifier you'd like to delete > Click Actions > Click Delete.\r\n  2.  To restoring the Cluster from a DB Cluster Snapshot, please follow the instructions listed in this link: <https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/USER_RestoreFromSnapshot.html>\r\n\r\n  For AWS Document DB:\r\n  1.  To create a 'Snapshot' of the unencrypted DB cluster, follow the instructions listed in this link: <https://docs.aws.amazon.com/documentdb/latest/developerguide/backup_restore-create_manual_cluster_snapshot.html>\r\n\r\n        Please note that you can't restore from a DB cluster snapshot to an existing DB cluster; instead a new DB cluster is created when you restore. Once the Snapshot status is showing as Available, delete the unencrypted DB cluster before restoring from the DB cluster Snapshot by following below steps for AWS Document DB,\r\n\r\n        a.  Sign to the AWS Management Console > open the Amazon DocumentDB console (or search for DocumentDB in the search bar).\r\n\r\n        b.  In the navigation pane, Click Clusters.\r\n\r\n        c.  Click the checkbox of the cluster identifier that you'd like to delete > Click Actions > Click Delete.\r\n\r\n  3.  To restore the Cluster from a DB Cluster Snapshot, follow the instructions listed in this link: <https://docs.aws.amazon.com/documentdb/latest/developerguide/backup_restore-restore_from_snapshot.html>\r\n  EOF\r\n\r\n  aws_regions.region_names.each do |region_name|\r\n    aws_rds_clusters(aws_region: region_name).cluster_identifier.each do |db_cluster_identifier|\r\n      describe aws_rds_cluster(aws_region: region_name, db_cluster_identifier: db_cluster_identifier) do\r\n        its('storage_encrypted') { should eq true }\r\n        its('db_cluster_resource_id') { should_not be_nil }\r\n      end\r\n    end\r\n  end\r\nend\r\n","source_location":{"ref":"./controls/storage/8_03_storage.rb","line":176},"id":"8_03_enable_cluster_encryption"},{"title":"8.3 - AWS RDS DB snapshot must be encrypted","desc":"This control identifies AWS RDS DB (Relational Database Service Database) cluster snapshots which are not encrypted. Encryption at rest must be enforced when you are working with production data that have sensitive information, to protect from unauthorized access.","descriptions":{"default":"This control identifies AWS RDS DB (Relational Database Service Database) cluster snapshots which are not encrypted. Encryption at rest must be enforced when you are working with production data that have sensitive information, to protect from unauthorized access."},"impact":0.8,"refs":[],"tags":{"sgs_wiki_url":"https://wiki.wdf.sap.corp/wiki/x/-0JAc","terraform_remediation":"  resource \"aws_db_instance\" \"example_rds_instance\" {\n    ...\n    storage_encrypted       = true\n  }\n","tested_tf_version":"1.0.11","remediation_steps":"  You can encrypt a copy of an unencrypted snapshot. By doing so, you can quickly add encryption to a previously unencrypted DB instance.\n\n  In order to remediate this alert, follow the below steps to encrypt a copy of an unencrypted snapshot:\n  1.  Log into to the AWS Management Console.\n  2.  Search for RDS in the search bar.\n  3.  Go to Snapshots > Navigate to the DB snapshot mentioned in the alert listed under the Manual tab or the System tab.\n  4.  Click on the checkbox by the snapshot that caused the alert > Click Actions > Select copy snapshot > Fill the required fields.\n  5.  Ensure Encryption Enabled checkbox is ticked > Copy snapshot.\n  6.  The new (copied) snapshot is available under the Manual tab.\n\n      Note: For system generated snapshots enable encryption at database, please refer to the following link: <https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/Overview.Encryption.html>\n  7.  Delete the non-compliant snapshots once the new encrypted snapshots are created and verified.\n"},"code":"control '8_03_rds_db_snapshot_encryption' do\r\n  title '8.3 - AWS RDS DB snapshot must be encrypted'\r\n  impact 0.8\r\n  desc 'This control identifies AWS RDS DB (Relational Database Service Database) cluster snapshots which are not encrypted. Encryption at rest must be enforced when you are working with production data that have sensitive information, to protect from unauthorized access.'\r\n  tag sgs_wiki_url: 'https://wiki.wdf.sap.corp/wiki/x/-0JAc'\r\n  tag terraform_remediation: <<-EOF\r\n  resource \"aws_db_instance\" \"example_rds_instance\" {\r\n    ...\r\n    storage_encrypted       = true\r\n  }\r\n  EOF\r\n  tag tested_tf_version: '1.0.11'\r\n\r\n  tag remediation_steps: <<-EOF\r\n  You can encrypt a copy of an unencrypted snapshot. By doing so, you can quickly add encryption to a previously unencrypted DB instance.\r\n\r\n  In order to remediate this alert, follow the below steps to encrypt a copy of an unencrypted snapshot:\r\n  1.  Log into to the AWS Management Console.\r\n  2.  Search for RDS in the search bar.\r\n  3.  Go to Snapshots > Navigate to the DB snapshot mentioned in the alert listed under the Manual tab or the System tab.\r\n  4.  Click on the checkbox by the snapshot that caused the alert > Click Actions > Select copy snapshot > Fill the required fields.\r\n  5.  Ensure Encryption Enabled checkbox is ticked > Copy snapshot.\r\n  6.  The new (copied) snapshot is available under the Manual tab.\r\n\r\n      Note: For system generated snapshots enable encryption at database, please refer to the following link: <https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/Overview.Encryption.html>\r\n  7.  Delete the non-compliant snapshots once the new encrypted snapshots are created and verified.\r\n  EOF\r\n\r\n  aws_regions.region_names.each do |region_name|\r\n    aws_rds_snapshots(aws_region: region_name).db_snapshot_identifiers.each do |db_snapshot_identifier|\r\n      rds_snapshot = aws_rds_snapshot(aws_region: region_name, db_snapshot_identifier: db_snapshot_identifier)\r\n      next if rds_snapshot.status != 'available'\r\n      next if rds_snapshot.engine == 'sqlserver-ex'\r\n\r\n      describe rds_snapshot do\r\n        it { should be_encrypted }\r\n      end\r\n    end\r\n  end\r\nend\r\n","source_location":{"ref":"./controls/storage/8_03_storage.rb","line":233},"id":"8_03_rds_db_snapshot_encryption"},{"title":"5.2 - AWS EBS volumes and EFS must be encrypted","desc":"Data, snapshots, and disk I/O must be encrypted using the customary AES-256 algorithm.\n  Amazon EBS and EFS encryption offers a simple encryption solution without the need to build,\n  maintain, and secure own key management infrastructure.","descriptions":{"default":"Data, snapshots, and disk I/O must be encrypted using the customary AES-256 algorithm.\n  Amazon EBS and EFS encryption offers a simple encryption solution without the need to build,\n  maintain, and secure own key management infrastructure."},"impact":0.8,"refs":[],"tags":{"sgs_control_hash":"8ae223887226fcbd01722703b9830029","sgs_wiki_url":"https://wiki.wdf.sap.corp/wiki/x/-0JAc","terraform_remediation":"  resource \"aws_ebs_volume\" \"example_ebs_volume\" {\n    ...\n    encrypted         = true\n  }\n  resource \"aws_efs_file_system\" \"example_efs\" {\n    encrypted = true\n  }\n","tested_tf_version":"1.0.11","remediation_steps":"\n  EBS encryption steps:\n  1.  Sign in to the AWS Management Console.\n  2.  Navigate to EC2 dashboard (or search for EC2 in the search bar).\n  3.  Under Elastic Block Store, click Volumes.\n  4.  Click on the checkbox of the Volume ID that you'd like to change > Click the Actions dropdown button > Click Create Snapshot.\n  5.  In the Create Snapshot dialog box, enter a name and a description for the snapshot (optional) > Click Create.\n  6.  Under Elastic Block Store, click Snapshots > Click on the checkbox of the Volume ID of your new created EBS snapshot.\n  7.  Click the Actions dropdown button > Click Copy.\n  8.  In the Copy Snapshot dialog box, click Encrypt this snapshot checkbox > Click Copy.\n  9.  Click on the checkbox of the Volume ID of your new (copied) created EBS snapshot > Click the Actions dropdown button > Click Create Volume.\n  10. In the Create Volume dialog box, make sure the volume Encryption status set as Encrypted > Click Create.\n  11. Click Volumes (on the left hand side) > Click on the checkbox of the Volume that isn't encrypted > Click the Actions dropdown button > Click Detach Volume.\n  12. In the Detach Volume dialog box, click Yes, Detach.\n  13. In the Attach Volume dialog box, enter your EC2 instance ID and the device name for attachment > Click Attach.\n  EFS encryption steps:\n  1.  Login to the AWS Management Console.\n  2.  Navigate to Elastic File System (EFS) dashboard (or search for EFS in the search bar).\n  3.  In the left  navigation panel, Click File Systems > Click Create File System button.\n  4.  On the Configure file system access configuration page, please do the following steps:\n  * \t\tChoose the correct VPC from the VPC dropdown list. Please note that only the EC2 instances equipped within the selected VPC can access the new file system.\n  * \t\tUnder the Create mount targets section, Click the checkboxes for all of the Availability Zones within the selected VPC.\n  * \t\tClick Next step.\n    On the Configure optional settings page, please do the following steps:\n  * \t\tUnder the Add tags section, create tags for description purposes for your new file system.\n  * \t\tClick General Purpose (default) or Max I/O from Choose performance mode section.\n  * \t\tCheck Enable encryption checkbox and choose aws/elasticfilesystem from Select KMS master key dropdown list.\n  *     Click Next Step.\n  5.  On the Review and create age, be sure to look over and confirm that  the file system configuration details are correct > Click Create File System.\n  6.  Copy the data from the original EFS file system onto the new one.\n  7.  Once the data migration process is done and you've confirmed that all the data is loaded into your new encrypted file system, you can now delete the original unencrypted file system by performing the following steps:\n  * \t\tConnect to your AWS EC2 instance > unmount the original unencrypted EFS file system.\n  * \t\tClick on checkbox of the EFS file system that you want to delete.\n  * \t\tClick the Action dropdown button > Click on Delete file system.\n  * \t\tInside the Permanently delete file system dialog box, enter the file system ID for the EFS file system that you want to delete > Click on Delete File System.\n"},"code":"control '5_02_ebs_and_efs_encryption_enabled' do\r\n  impact 0.8\r\n  title '5.2 - AWS EBS volumes and EFS must be encrypted'\r\n  desc 'Data, snapshots, and disk I/O must be encrypted using the customary AES-256 algorithm.\r\n  Amazon EBS and EFS encryption offers a simple encryption solution without the need to build,\r\n  maintain, and secure own key management infrastructure.'\r\n\r\n  tag sgs_control_hash: '8ae223887226fcbd01722703b9830029'\r\n  tag sgs_wiki_url: 'https://wiki.wdf.sap.corp/wiki/x/-0JAc'\r\n  tag terraform_remediation: <<-EOF\r\n  resource \"aws_ebs_volume\" \"example_ebs_volume\" {\r\n    ...\r\n    encrypted         = true\r\n  }\r\n  resource \"aws_efs_file_system\" \"example_efs\" {\r\n    encrypted = true\r\n  }\r\n  EOF\r\n  tag tested_tf_version: '1.0.11'\r\n\r\n  tag remediation_steps: <<-EOF\r\n\r\n  EBS encryption steps:\r\n  1.  Sign in to the AWS Management Console.\r\n  2.  Navigate to EC2 dashboard (or search for EC2 in the search bar).\r\n  3.  Under Elastic Block Store, click Volumes.\r\n  4.  Click on the checkbox of the Volume ID that you'd like to change > Click the Actions dropdown button > Click Create Snapshot.\r\n  5.  In the Create Snapshot dialog box, enter a name and a description for the snapshot (optional) > Click Create.\r\n  6.  Under Elastic Block Store, click Snapshots > Click on the checkbox of the Volume ID of your new created EBS snapshot.\r\n  7.  Click the Actions dropdown button > Click Copy.\r\n  8.  In the Copy Snapshot dialog box, click Encrypt this snapshot checkbox > Click Copy.\r\n  9.  Click on the checkbox of the Volume ID of your new (copied) created EBS snapshot > Click the Actions dropdown button > Click Create Volume.\r\n  10. In the Create Volume dialog box, make sure the volume Encryption status set as Encrypted > Click Create.\r\n  11. Click Volumes (on the left hand side) > Click on the checkbox of the Volume that isn't encrypted > Click the Actions dropdown button > Click Detach Volume.\r\n  12. In the Detach Volume dialog box, click Yes, Detach.\r\n  13. In the Attach Volume dialog box, enter your EC2 instance ID and the device name for attachment > Click Attach.\r\n  EFS encryption steps:\r\n  1.  Login to the AWS Management Console.\r\n  2.  Navigate to Elastic File System (EFS) dashboard (or search for EFS in the search bar).\r\n  3.  In the left  navigation panel, Click File Systems > Click Create File System button.\r\n  4.  On the Configure file system access configuration page, please do the following steps:\r\n  * \t\tChoose the correct VPC from the VPC dropdown list. Please note that only the EC2 instances equipped within the selected VPC can access the new file system.\r\n  * \t\tUnder the Create mount targets section, Click the checkboxes for all of the Availability Zones within the selected VPC.\r\n  * \t\tClick Next step.\r\n    On the Configure optional settings page, please do the following steps:\r\n  * \t\tUnder the Add tags section, create tags for description purposes for your new file system.\r\n  * \t\tClick General Purpose (default) or Max I/O from Choose performance mode section.\r\n  * \t\tCheck Enable encryption checkbox and choose aws/elasticfilesystem from Select KMS master key dropdown list.\r\n  *     Click Next Step.\r\n  5.  On the Review and create age, be sure to look over and confirm that  the file system configuration details are correct > Click Create File System.\r\n  6.  Copy the data from the original EFS file system onto the new one.\r\n  7.  Once the data migration process is done and you've confirmed that all the data is loaded into your new encrypted file system, you can now delete the original unencrypted file system by performing the following steps:\r\n  * \t\tConnect to your AWS EC2 instance > unmount the original unencrypted EFS file system.\r\n  * \t\tClick on checkbox of the EFS file system that you want to delete.\r\n  * \t\tClick the Action dropdown button > Click on Delete file system.\r\n  * \t\tInside the Permanently delete file system dialog box, enter the file system ID for the EFS file system that you want to delete > Click on Delete File System.\r\n  EOF\r\n\r\n  aws_regions.region_names.each do |region_name|\r\n    aws_ebs_volumes(aws_region: region_name).entries.each do |volume|\r\n      next unless volume.tags.select { |t| t.key == 'sec-by-def-ebs-encryption-exception' && t.value == 'enabled' }.empty?\r\n      describe \"Elastic Block Storage (EBS) Volume #{volume.volume_id} in region #{region_name}\" do\r\n        subject { volume }\r\n        its('encrypted') { should eq true }\r\n      end\r\n    end\r\n    aws_efs_file_systems(aws_region: region_name).entries.each do |file_system|\r\n      next unless file_system.tags.select { |t| t.key == 'sec-by-def-ebs-encryption-exception' && t.value == 'enabled' }.empty?\r\n      describe \"Elastic File System (EFS) #{file_system.file_system_id} in region #{region_name}\" do\r\n        subject { file_system }\r\n        its('encrypted') { should eq true }\r\n      end\r\n    end\r\n  end\r\nend\r\n","source_location":{"ref":"./controls/vm_encryption/5_02_vms.rb","line":1},"id":"5_02_ebs_and_efs_encryption_enabled"},{"title":"5.1 - AWS EBS snapshots must not be publicly accessible","desc":"This policy finds EBS snapshots that are accessible to public.\n  if EBS snapshots are public, any unauthorized user can gain access to sensitive data","descriptions":{"default":"This policy finds EBS snapshots that are accessible to public.\n  if EBS snapshots are public, any unauthorized user can gain access to sensitive data"},"impact":0.8,"refs":[],"tags":{"sgs_wiki_url":"https://wiki.wdf.sap.corp/wiki/x/-0JAc","remediation_steps":"\t1.  Sign in to the AWS Management Console.\n  2.  Navigate to EC2 dashboard (or search for EC2 in the search bar).\n  3.  Under Elastic Block Store, click Snapshots.\n  4.  Click on the EBS snapshot ID that you'd like to change.\n  5.  Click on Modify Permissions tab > Click the Edit button.\n  6.  Inside Modify Permissions dialog box, click Private > Click Save.\n"},"code":"control '5_01_ebs_snapshots' do\r\n  title '5.1 - AWS EBS snapshots must not be publicly accessible'\r\n  impact 0.8\r\n  desc 'This policy finds EBS snapshots that are accessible to public.\r\n  if EBS snapshots are public, any unauthorized user can gain access to sensitive data'\r\n  tag sgs_wiki_url: 'https://wiki.wdf.sap.corp/wiki/x/-0JAc'\r\n\r\n  tag remediation_steps: <<-EOF\r\n\t1.  Sign in to the AWS Management Console.\r\n  2.  Navigate to EC2 dashboard (or search for EC2 in the search bar).\r\n  3.  Under Elastic Block Store, click Snapshots.\r\n  4.  Click on the EBS snapshot ID that you'd like to change.\r\n  5.  Click on Modify Permissions tab > Click the Edit button.\r\n  6.  Inside Modify Permissions dialog box, click Private > Click Save.\r\n  EOF\r\n\r\n  account_id = ENV['AWS_ACCOUNT_ID'] || aws_sts_caller_identity.account\r\n  aws_ebs_snapshots.where(owner_id: account_id).snapshot_ids.each do |snapshot_id|\r\n    describe aws_ebs_snapshot(snapshot_id: snapshot_id) do\r\n      it { should_not be_public }\r\n    end\r\n  end\r\nend\r\n","source_location":{"ref":"./controls/vm_public_access/5_01_vms.rb","line":1},"id":"5_01_ebs_snapshots"},{"title":"5.1 - AWS Amazon Machine Image (AMI) must not be publicly accessible","desc":"SAP must use its own VM images and creates its own repository of AMIs that should be used to run SAP cloud system in AWS accounts. These SAP VM images (AMIs) must comply with the SAP OS security procedure and fulfil all legal requirements (e.g. regarding licensing, use of third party software components). Because such images contain SAP proprietary configurations and e.g. license keys, it must not be made public to the whole internet community.","descriptions":{"default":"SAP must use its own VM images and creates its own repository of AMIs that should be used to run SAP cloud system in AWS accounts. These SAP VM images (AMIs) must comply with the SAP OS security procedure and fulfil all legal requirements (e.g. regarding licensing, use of third party software components). Because such images contain SAP proprietary configurations and e.g. license keys, it must not be made public to the whole internet community."},"impact":0.8,"refs":[],"tags":{"sgs_control_hash":"8ae223887226fcbd01722703b9830044","sgs_wiki_url":"https://wiki.wdf.sap.corp/wiki/x/-0JAc","remediation_steps":"\t1.  Sign in to the AWS Management Console.\n  2.  Navigate to EC2 dashboard (or search for EC2 in the search bar).\n  3.  Under IMAGES section, click AMIs.\n  4.  Click on the AMI ID that you want to change.\n  5.  Click on the Permissions tab > Click the Edit AMI permissions button.\n  6.  In the Modify Image Permissions dialog box, click Private > Click Save.\n"},"code":"control '5_01_ami_images_not_publicly_accessible' do\r\n  impact 0.8\r\n  title '5.1 - AWS Amazon Machine Image (AMI) must not be publicly accessible'\r\n  desc 'SAP must use its own VM images and creates its own repository of AMIs that should be used to run SAP cloud system in AWS accounts. These SAP VM images (AMIs) must comply with the SAP OS security procedure and fulfil all legal requirements (e.g. regarding licensing, use of third party software components). Because such images contain SAP proprietary configurations and e.g. license keys, it must not be made public to the whole internet community.'\r\n\r\n  tag sgs_control_hash: '8ae223887226fcbd01722703b9830044'\r\n  tag sgs_wiki_url: 'https://wiki.wdf.sap.corp/wiki/x/-0JAc'\r\n\r\n  tag remediation_steps: <<-EOF\r\n\t1.  Sign in to the AWS Management Console.\r\n  2.  Navigate to EC2 dashboard (or search for EC2 in the search bar).\r\n  3.  Under IMAGES section, click AMIs.\r\n  4.  Click on the AMI ID that you want to change.\r\n  5.  Click on the Permissions tab > Click the Edit AMI permissions button.\r\n  6.  In the Modify Image Permissions dialog box, click Private > Click Save.\r\n  EOF\r\n\r\n  # This would be great, but self isn't supported via filters:\r\n  # aws_amis(owner_alias: 'self').image_ids.each do |ami_id|\r\n\r\n  # This is fast and works by filtering using the account id for ownership, rather than the self alias\r\n  aws_amis(owners: 'self').image_ids.each do |ami_id|\r\n    ami = aws_ami(ami_id)\r\n    next if ami.tags['sec-by-def-public-image-exception'] == 'public'\r\n    describe ami do\r\n      it { should_not be_public }\r\n    end\r\n  end\r\nend\r\n","source_location":{"ref":"./controls/vm_public_access/5_01_vms.rb","line":25},"id":"5_01_ami_images_not_publicly_accessible"}],"groups":[{"title":null,"controls":["5_02_emr_cluster_local_disk_encryption","5_02_emr_cluster_encryption_at_rest","5_02_emr_cluster_encryption_in_transit"],"id":"controls/aws_elastic/5_02_aws_elastic.rb"},{"title":null,"controls":["8_01_elasticache_cluster_at_rest_encryption","8_01_elasticache_cluster_in_transit_encryption"],"id":"controls/aws_elastic/8_01_aws_elastic.rb"},{"title":null,"controls":["8_02_domain_publicly_available","8_02_domain_encrypted_at_rest","8_02_domain_in_vpc_or_access_based_on_ip_allow_list","8_02_domain_in_vpc"],"id":"controls/aws_elastic/8_02_aws_elastic.rb"},{"title":null,"controls":["7_04_eks_cluster_security_group_traffic_permissions","7_04_eks_cluster_using_default_vpc"],"id":"controls/containers_and_kubernetes/7_04_k8s.rb"},{"title":null,"controls":["7_12_eks_cluster_api_publicly_accessible"],"id":"controls/containers_and_kubernetes/7_12_k8s.rb"},{"title":null,"controls":["2_01_key_last_use","2_01_key_rotation","2_01_iam_ssh_key_age_rotation","2_01_iam_server_cert_expired"],"id":"controls/iam_and_keys/2_01_iam_and_keys.rb"},{"title":null,"controls":["2_02_iam_group_admin_access","2_02_iam_role_admin_access","2_02_iam_user_admin_access"],"id":"controls/iam_and_keys/2_02_iam_and_keys.rb"},{"title":"Enforce MFA for all accounts","controls":["2_03_mfa_enabled"],"id":"controls/iam_and_keys/2_03_iam_and_keys.rb"},{"title":null,"controls":["3_06_kms_key_rotation"],"id":"controls/iam_and_keys/3_06_iam_and_keys.rb"},{"title":null,"controls":["ra_2_password_policy"],"id":"controls/iam_and_keys/ra_2_iam_and_keys.rb"},{"title":null,"controls":["5_03_sns_subscription_using_secure_protocol"],"id":"controls/networks/5_03_networks.rb"},{"title":null,"controls":["6_01_01_db_ports"],"id":"controls/networks/6_01_01_networks.rb"},{"title":null,"controls":["6_01_02_admin_ports"],"id":"controls/networks/6_01_02_networks.rb"},{"title":null,"controls":["6_01_03_infra_ports"],"id":"controls/networks/6_01_03_networks.rb"},{"title":null,"controls":["6_01_04_fileshare_ports"],"id":"controls/networks/6_01_04_networks.rb"},{"title":null,"controls":["6_01_05_telnet_ports"],"id":"controls/networks/6_01_05_networks.rb"},{"title":null,"controls":["6_03_elb_access_logging","6_03_alb_access_logging","6_03_elb_security_policies"],"id":"controls/networks/6_03_networks.rb"},{"title":null,"controls":["6_04_aws_secure_vpn_setup"],"id":"controls/networks/6_04_networks.rb"},{"title":null,"controls":["8_04_public_zone_private_records"],"id":"controls/networks/8_04_networks.rb"},{"title":null,"controls":["8_05_cloudfront_ssl_protocol","8_05_cloudfront_origin_protocol_policy","8_05_cloudfront_viewer_protocol_policy","8_05_cloudfront_s3_origin_access","8_05_cloudfront_access_log_enabled"],"id":"controls/networks/8_05_networks.rb"},{"title":null,"controls":["5_01_get","5_01_list","5_01_s3_global_delete","5_01_put","5_01_rds_snapshot_private"],"id":"controls/storage/5_01_storage.rb"},{"title":null,"controls":["5_02_s3_bucket_encryption_enabled"],"id":"controls/storage/5_02_storage.rb"},{"title":null,"controls":["5_03_s3_secure_transport_enabled"],"id":"controls/storage/5_03_storage.rb"},{"title":null,"controls":["6_02_mq_public"],"id":"controls/storage/6_02_storage.rb"},{"title":null,"controls":["6_03_rds_instance_backup"],"id":"controls/storage/6_03_storage.rb"},{"title":null,"controls":["8_03_rds_instance_publicly_accessible","8_03_rds_instance_in_public_subnet","8_03_rds","8_03_enable_cluster_encryption","8_03_rds_db_snapshot_encryption"],"id":"controls/storage/8_03_storage.rb"},{"title":null,"controls":["5_02_ebs_and_efs_encryption_enabled"],"id":"controls/vm_encryption/5_02_vms.rb"},{"title":null,"controls":["5_01_ebs_snapshots","5_01_ami_images_not_publicly_accessible"],"id":"controls/vm_public_access/5_01_vms.rb"}],"sha256":"90da325fe41bff4e292f03bfe0e8dd177424133a043e61a4dc93fb0926ddd8ac","status_message":"","status":"loaded","generator":{"name":"inspec","version":"4.56.17"}}
