---
controls:
  # Chapter 2
  - name: 2_01_gcp_overly_permissive_service_account_privileges
    description: 2.1 - GCP IAM Users should not have overly permissive service account privileges
    sgs_wiki_link: https://wiki.wdf.sap.corp/wiki/x/9Ik-cg
    query: GcpUser with PolicyBindings with Role.Name in ['roles/iam.serviceAccountActor' , 'roles/iam.serviceAccountAdmin']
    score: 5.0
    allow_orca_score_adjustment: false
    enabled: true
    category: Best practices
    minerva_control_id: 2_01_overly_permissive_service_account_privileges
    remediation_steps: |
      1. Go to the GCP console and navigate to the 'IAM & Admin' page.
      2. Identify the user with overly permissive service account privileges based on the Asset ID provided in the alert details.
      3. Click on the user's name to view their details.
      4. Scroll down to the "Service Accounts" section and review the permissions granted to each service account.
      5. Remove the following roles from the user account: 'roles/iam.serviceAccountActor' and 'roles/iam.serviceAccountAdmin'.
      6. Consider creating a new service account with only the necessary permissions and assign it to the user.
      7. Monitor the user's activity and service account usage to ensure compliance with security policies.
    terraform_remediation: |
      1. Use the following Terraform code to remove the following roles from the user account: 'roles/iam.serviceAccountActor' and 'roles/iam.serviceAccountAdmin':
      resource "google_project_iam_member" "example_google_project_iam_member" {
        role    = "roles/iam.serviceAccountActor"
        member  = [
          <Should not be structured like user:member@sap.com>
        ]
      }

      resource "google_project_iam_member" "example_google_project_iam_member" {
        role    = "roles/iam.serviceAccountAdmin"
        member  = [
          <Should not be structured like user:member@sap.com>
        ]
      }
  - name: 2_01_gcp_iam_user_with_service_account_privileges
    description: 2.1 - GCP IAM Users should not be permitted to use service account privileges
    sgs_wiki_link: https://wiki.wdf.sap.corp/wiki/x/9Ik-cg
    query: GcpUser with PolicyBindings with Policy.Scope = 'Project' and Role.Name in ['roles/iam.serviceAccountUser', 'roles/iam.serviceAccountTokenCreator']
    score: 5.0
    allow_orca_score_adjustment: false
    enabled: true
    category: Best practices
    minerva_control_id: 2_01_iam_user_with_service_account_privileges
    remediation_steps: |
      1. Access the 'IAM & Admin' page in the GCP Console.
      2. Select the IAM user with service account privileges.
      3. Edit their settings to remove service account privileges.
      4. Save the changes.
      5. Continuously monitor the IAM user's activity to ensure compliance.
    terraform_remediation: |
      1. Use the following Terraform code to remove the following roles from the user account: 'roles/iam.serviceAccountUser' and 'roles/iam.serviceAccountTokenCreator':
      resource "google_project_iam_member" "example_google_project_iam_member" {
        role    = "roles/iam.serviceAccountUser"
        member  = [
          <Should start with "serviceAccount:">
        ]
      }

      resource "google_project_iam_member" "example_google_project_iam_member" {
        role    = "roles/iam.serviceAccountTokenCreator"
        member  = [
          <Should start with "serviceAccount:">
        ]
      }
  - name: 2_01_gcp_user_managed_service_account_key_rotation
    description: 2.1 - GCP User managed service account keys must be rotated within 90 days
    sgs_wiki_link: https://wiki.wdf.sap.corp/wiki/x/9Ik-cg
    query: GcpIamServiceAccountKey with CreationTime < 90 days ago and KeyType != "SYSTEM_MANAGED"
    score: 8.0
    allow_orca_score_adjustment: false
    enabled: true
    category: Best practices
    minerva_control_id: 2_01_key_rotation
    remediation_steps: |
      To address this alert, rotate expired service account keys as follows:
        1. Access the GCP Console and navigate to 'IAM & Admin.'
        2. Locate the user-managed service account mentioned in the alert under "Service accounts."
        3. In the "Keys" tab, find the key older than 90 days and delete it.
        4. Confirm key deletion.
        5. Create a new key (JSON or P12) for the service account and save it securely.
        6. Update any applications or services using the old key with the new one.
        7. Repeat for other user-managed service accounts with keys older than 90 days.
    terraform_remediation:  |
      1. Use the following Terraform code to for Usage, creating and regularly rotating a key:
      resource "time_rotating" "example_time_rotating" {
        rotation_days = <Value less than 90>
      }

      resource "google_service_account_key" "example_google_service_account_key" {
        keepers = {
          rotation_time = time_rotating.example_time_rotating.rotation_rfc3339
        }
      }
  - name: 2_02_gcp_non_corporate_user_admin_access
    description: 2.2 - GCP Non-corporate Users must not have administrator access permissions
    sgs_wiki_link: https://wiki.wdf.sap.corp/wiki/x/9Ik-cg
    query: GcpUser with ( PolicyBindings with Policy and Role.Name in [ 'roles/editor' , 'roles/owner' , 'roles/resourcemanager.organizationAdmin' , 'roles/resourcemanager.projectDeleter' , 'roles/resourcemanager.projectIamAdmin' , 'roles/iam.roleAdmin' , 'roles/compute.admin' , 'roles/compute.networkAdmin' , 'roles/storage.admin' , 'roles/storage.objectAdmin' , 'roles/accesscontextmanager.policyAdmin' , 'roles/cloudfunctions.admin' , 'roles/managedidentities.admin' , 'roles/secretmanager.admin' ] ) and not ( Name like ( '@sap.com' or '@global.corp.sap' or '@gserviceaccount.com' or '@emarsys.com' or '@ondemand.com' or '@qualtrics.com' or '@loyalsys.io' or '@tipico.com' or '@mobileprogramming.com' or '@saponepat.onmicrosoft.com' or '@sapzeropat.onmicrosoft.com' or 'sap.com@gtempaccount.com' or 'emarsys.com@gtempaccount.com' or '@multicloud.int.sap') )
    score: 8.0
    allow_orca_score_adjustment: false
    enabled: true
    category: Best practices
    minerva_control_id: 2_02_non_corporate_accounts
    remediation_steps: |
      1. Log in to the GCP console with the appropriate credentials.
      2. Navigate to the IAM & Admin page.
      3. Click on the Non-corporate Users tab.
      4. Identify and remove administrator access permissions from the user.
      5. Verify the user no longer has administrator access.
      Utilize our managed corporate Google accounts for enhanced visibility, auditing, and control over GCP resources. Avoid accessing GCP resources through personal or non-approved accounts.
    terraform_remediation:  |
      1. Use the following Terraform code to update the IAM policy to grant a role to a list of members. Other roles within the IAM policy for the project are preserved.
      resource "google_project_iam_binding" "example_google_project_iam_binding" {
        role   =  "roles/editor"
        members = [
          <must only be GCP corporate accounts>
        ]
      }

      resource "google_project_iam_binding" "example_google_project_iam_binding" {
        role   =  "roles/owner"
        members = [
          <must only be GCP corporate accounts>
        ]
      }
  # Chapter 3
  - name: 3_06_gcp_kms_secure_usage
    description: 3.6 - GCP Key Management System (KMS) must be configured securely
    sgs_wiki_link: https://wiki.wdf.sap.corp/wiki/x/9Ik-cg
    query: GcpKmsKey with Purpose = "ENCRYPT_DECRYPT" and not RotationPeriod and PrimaryKeyState and not PrimaryKeyState = ("DESTROYED" or "DESTROY_SCHEDULED" or "DISABLED")
    score: 8.0
    allow_orca_score_adjustment: false
    enabled: true
    category: Best practices
    minerva_control_id: 3_06_secure_kms_usage
    remediation_steps: |
      1. Access the GCP console and navigate to the Key Management System (KMS) section.
      2. Select the name of the GCP KMS key ring that requires changes.
      3. Click on the three-dot submenu icon next to the key name, choose "Edit rotation period," and review/adjust key permissions as needed.
      4. In the "Edit rotation period" configuration box:
          - Select an optimal rotation period (less than 90 days) for the key.
          - Use the Starting on date picker (DTP) to set the rotation period's start date as soon as possible.
          - Click "Save" to apply the changes.
      5. Enable audit logging for the key to monitor usage and detect suspicious activity.
      6. Regularly review the key's usage logs to identify potential security issues.
    terraform_remediation:  |
      1. Use the following Terraform code to add a resource block for the GCP KMS key with the required properties:
      resource "google_kms_crypto_key" "example_google_kms_key" {
        rotation_period = <Valid rotation period>
      }
  - name: 3_06_gcp_overly_permissive_kms_role
    description: 3.6 - GCP IAM users or service accounts should not have overly permissive Cloud KMS roles
    sgs_wiki_link: https://wiki.wdf.sap.corp/wiki/x/9Ik-cg
    query: >
      [GcpUser or GcpIamServiceAccount ] with PolicyBindings with Policy.Scope = 'Project' and Role.Name in ['roles/cloudkms.admin', 'roles/cloudkms.cryptoKeyEncrypterDecrypter']
    score: 5.0
    allow_orca_score_adjustment: false
    enabled: true
    category: Best practices
    minerva_control_id: 3_06_iam_user_with_overly_permissive_kms_roles
    remediation_steps: |
      1. Sign in to the GCP Console and go to 'IAM & Admin' page.
      2. On the left Navigation pane, click IAM.
      3. Select a project, folder, or organization.
      4. Under PERMISSIONS tab, View By: PRINCIPALS, find the row containing the principal's name and click Edit principal in that row.
      5. Remove 'roles/cloudkms.admin' and 'roles/cloudkms.cryptoKeyEncrypterDecrypter' roles for this account.
      6. Click Save.
    terraform_remediation:  |
      1. Use the following Terraform code to create a new Cloud KMS role with the appropriate permissions:
      resource "google_project_iam_binding" "example_google_project_iam_binding" {
        role    = 'roles/cloudkms.admin'
        members = []
      }

       resource "google_project_iam_binding" "example_google_project_iam_binding" {
        role    = 'roles/cloudkms.cryptoKeyEncrypterDecrypter'
        members = []
      }
  # Chapter 4
  - name: 4_02_gcp_ip_forwarding
    description: 4.2 - GCP IP Forwarding should not be enabled
    sgs_wiki_link: https://wiki.wdf.sap.corp/wiki/x/9Ik-cg
    query: GcpVmInstance with CanIpForward and State != "stopped"
    score: 1.0
    allow_orca_score_adjustment: false
    enabled: true
    category: Best practices
    minerva_control_id: null
    remediation_steps: |
      1. Go to the GCP console and navigate to the 'VM instances' page.
      2. Locate the 'VM instance' with the IP forwarding enabled alert and note down its name.
      3. Stop the 'VM instance' by clicking on the stop button.
      4. Once the 'VM instance' is stopped, click on the delete button to delete the instance.
      5. Create a new 'VM instance' with the same configuration as the deleted instance, but ensure that IP forwarding is disabled during creation.
      6. Verify that the new 'VM instance' is running and functioning properly.
      7. Monitor the instance for any further alerts or issues related to IP forwarding.
    terraform_remediation:  |
      1. Use the following Terraform code to disable IP forwarding for the instance:
      resource "google_compute_instance" "vm_instance" {
        metadata = {
          enable-ip-forwarding = "false"
        }
      }
  - name: 4_05_gcp_compute_instance_block_ssh_key
    description:  4.5 - GCP VM instances must have Block project-wide SSH keys activated
    sgs_wiki_link: https://wiki.wdf.sap.corp/wiki/x/9Ik-cg
    query: GcpVmInstance with not Tags [ "block-project-ssh-keys" ] = "true" and not Metadata.BlockProjectSshKeys in [ 'true' , '1' , 'TRUE' ]
    score: 8.0
    allow_orca_score_adjustment: false
    enabled: true
    category: Best practices
    minerva_control_id: 4_05_compute_instance_block_ssh_keys
    remediation_steps: |
      1. Go to the GCP console and select the project with the Cloud Provider ID
      2. Navigate to the 'Compute Engine' section and select the VM instance with the Asset ID
      3. Click on the Edit button at the top of the page.
      4. Scroll down to the SSH Keys section and select the option "Block project-wide SSH keys".
      5. Click on the Save button to apply the changes.
      6. Verify that the alert has been resolved by checking the alert status in the Security Command Center.
    terraform_remediation:  |
      1. 1. Use the following Terraform code to add the metadata block to the google_compute_instance resource to enable block project-wide SSH keys:
      resource "google_compute_instance" "example_compute_instance" {
        metadata = {
        block-project-ssh-keys = true
        }
      }

      If a node pool is configured for GKE cluster, this needs to be enabled for those compute instances as well:
        resource "google_container_node_pool" "example_node_pool" {
          node_config {
            metadata = {
              block-project-ssh-keys = true
            }
          }
        }
  # Chapter 5
  - name: 5_01_gcp_storage_bucket_public_accessibility
    description: 5.1 - GCP Storage buckets must not be publicly accessible to all users
    sgs_wiki_link: https://wiki.wdf.sap.corp/wiki/x/9Ik-cg
    query: GcpStorageBucket with Policy.PolicyBindings with Members containing 'allUsers' and not Tags ["sec-by-def-public-storage-exception"] = "enabled"
    score: 8.0
    allow_orca_score_adjustment: false
    enabled: true
    category: Best practices
    minerva_control_id: 5_01_public_buckets_all_users_restricted
    remediation_steps: |
      1. Go to the GCP console and navigate to the 'Cloud Storage' section.
      2. Select the bucket identified in the alert details
      3. Click on the "Edit bucket permissions" button.
      4. Under the "Public access prevention" section, select the option "Prevent public access to all buckets and objects".
      5. Click on the "Save" button to apply the changes.
      6. Verify that the bucket is no longer publicly accessible by attempting to access it from a different account or network.
    terraform_remediation:  |
      1. Use the following Terraform code to update the bucket's access control list ACL and deny access to allUsers:
      resource "google_storage_bucket_access_control" "example_google_storage_bucket_access_control" {
        role   =  <Some bucket role>
        entity =  <Should not be equal to "allUsers">
      }
  - name: 5_01_gcp_storage_bucket_uniform_access_control
    description: 5.1 - GCP Storage buckets must have Uniform access control enabled
    sgs_wiki_link: https://wiki.wdf.sap.corp/wiki/x/9Ik-cg
    query: GcpStorageBucket without (IamUniformBucketLevelAccess or Name like ".appspot.com")
    score: 8.0
    allow_orca_score_adjustment: false
    enabled: true
    category: Best practices
    minerva_control_id: 5_01_buckets_uniform_access_enforced
    remediation_steps: |
      1. Go to the GCP console and navigate to the 'Cloud Storage' section.
      2. Select the bucket with the Asset ID mentioned in the alert details.
      3. Click on the "Edit bucket permissions" button.
      4. Under the "Uniform" tab, select "Uniform" as the access control model.
      5. Click on the "Save" button to apply the changes.
      6. Verify that the alert has been resolved in the Security Command Center.
    terraform_remediation:  |
      1. Use the following Terraform code to enable Uniform access control for the GCP Storage bucket:
      resource "google_storage_bucket" "test-bucket" {
        uniform_bucket_level_access = true
      }
  - name: 5_01_gcp_public_bucket_all_authenticated_users_restricted
    description:  5.1 - GCP Storage buckets must not be publicly accessible to all authenticated users
    sgs_wiki_link: https://wiki.wdf.sap.corp/wiki/x/9Ik-cg
    query: GcpStorageBucket with Policy.PolicyBindings with Members containing 'allAuthenticatedUsers'
    score: 8.0
    allow_orca_score_adjustment: false
    enabled: true
    category: Best practices
    minerva_control_id: 5_01_public_buckets_all_authenticated_users_restricted
    remediation_steps: |
      1. Go to the GCP console and navigate to the 'Cloud Storage' section.
      2. Find the bucket with the Asset ID mentioned in the alert details.
      3. Click on the bucket to open its details page.
      4. Under the "Permissions" tab, remove the "allAuthenticatedUsers" entry.
      5. Click "Save" to apply the changes.
      6. Verify that the bucket is no longer publicly accessible to all authenticated users by running the following command: gsutil iam get gs://BUCKET_NAME
      7. If the output confirms the removal of the "allAuthenticatedUsers" entry, the remediation is complete.
    terraform_remediation:  |
      1. Use the following Terraform code to create a new role on the affected bucket, which denies access to all authenticated users:
      resource "google_storage_bucket_access_control" "example_google_storage_bucket_access_control" {
        role   =  <Some bucket role>
        entity =  <must not be equal to "allAuthenticatedUsers">
      }
  - name: 5_01_gcp_machine_images_public_exposure
    description: GCP Machine Images MUST NOT be made publicly available
    sgs_wiki_link: https://wiki.wdf.sap.corp/wiki/x/9Ik-cg
    query: GcpVMImage with Cloudaccount.GcpIamPolicyBinding with Members containing ("allAuthenticatedUsers" or "allUsers") and Role.Name = "roles/compute.imageUser"
    score: 1.0
    allow_orca_score_adjustment: false
    enabled: true
    category: Best practices
    minerva_control_id: null
    remediation_steps: |
      1. Login to GCP console and type 'Compute Engine' in the search bar.
      2. Select on the instance for which the alert is raised.
      3. Click Delete.
      4. To Ensure machine images is not publicly accessible, only grant the appropriate IAM roles to control access to the images.
      5. In the Google Cloud console, go to the IAM page of the project whose service account you want to grant access to.
      6. If prompted, select your project from the list.
      7. Look for the the Google APIs Service Agent, which has the email address in the following format:PROJECT_NUMBER@cloudservices.gserviceaccount.com.
      8. To add a new member, click person_add Grant access.
      9. In the New principals field, add the service account email address.
      10. In the Role list, hold the pointer over Compute and select Compute Image User.
      11. Click Save.
    terraform_remediation:  |
      1. Use the following Terraform code to Update the IAM policy to grant the appropriate IAM roles to control access to the images which denies access to "allAuthenticatedUsers" or "allUsers" :
      resource "google_compute_machine_image_iam_binding" "binding" {
        provider = google-beta
        project = google_compute_machine_image.image.project
        machine_image = google_compute_machine_image.image.name
        role = "roles/compute.imageUser"
        entity =  <Should not be equal to "allAuthenticatedUsers" or "allUsers">
      }
  - name: 5_04_gcp_storage_log_bucket_object_versioning
    description:  5.4 - GCP Storage log buckets should have object versioning enabled
    sgs_wiki_link: https://wiki.wdf.sap.corp/wiki/x/9Ik-cg
    query: GcpStorageBucket with not ( RetentionPolicyEnabled or VersioningEnabled )
    score: 5.0
    allow_orca_score_adjustment: false
    enabled: true
    category: Best practices
    minerva_control_id: 5_04_enable_storage_log_bucket_object_versioning
    remediation_steps: |
      1. Log in to the GCP console using the Cloud Provider ID
      2. Navigate to the Cloud Storage section of the console.
      3. Locate the sbd-exception-handling-testing bucket.
      4. Click on the bucket to open its details page.
      5. Click on the "Edit bucket" button.
      6. Scroll down to the "Object Versioning" section or "Retention Policy" section.
      7. Click on the "Enable object versioning" or "Enable Retention Policy" checkbox.
      8. Click on the "Save" button to save the changes.
      9. Verify that the Object Versioning or Retention Policy feature is now enabled
      10. Close the console.
    terraform_remediation:  |
      1. Use the following Terraform code to enable object versioning for the GCP Cloud Storage bucket:
      resource "google_logging_project_sink" "example_google_logging_project_sink" {
        destination = "google_storage_bucket.example_google_storage_bucket"
      }

      resource "google_storage_bucket" "example_google_storage_bucket" {
        versioning {
          enabled = true
        }
      }
  # Chapter 6
  - name: 6_01_01_gcp_db_ports
    description:  6.1.1 - GCP Firewall rules must not allow inbound traffic from the Internet to blocklisted Database (DB) ports
    sgs_wiki_link: https://wiki.wdf.sap.corp/wiki/x/9Ik-cg
    query: GcpVpcFirewallRule with TargetTags not containing "sec-by-def-database-port-exception" and IpPermissions with SourceRanges containing ( "::/0" or "0.0.0.0/0" ) and PortRange containing ([5432, 3306, 4333, 1521, 27017, 1433, 1434][*]) and IpProtocol in ['tcp','udp','all'] and RuleType = 'INGRESS' and Action = 'allow' and not Disabled
    score: 8.0
    allow_orca_score_adjustment: false
    enabled: true
    category: Best practices
    minerva_control_id: 6_01_01_db_ports
    remediation_steps: |
      1. Go to the GCP console and navigate to the 'VPC firewall rules' page.
      2. Identify the firewall rule that is allowing inbound traffic from the internet to blocklisted database ports.
      3. Edit the firewall rule to remove the blocklisted database ports from the allowed inbound traffic.
      4. Make sure the following rule does not exists: 'Direction' as 'Ingress', 'Action' as 'Allow' and 'Enabled','Source IPv4 ranges' is 0.0.0.0/0 or 'Source IPv6 ranges' is ::/0; Under 'Protocols and ports': no DB ports are included in 'tcp' or 'udp' or 'all'.
      5. Navigate to the inbound rules > Click on Edit Inbound rules > Ensure CIDR block 0.0.0.0/0 or ::/0 is not bound to any of the following ports: PostgreSQL (5432), MySQL (3306), MSSQL (4333, 1433, 1434), OracleSQL (1521) , MongoDB (27017) OR any ports mentioned in [6.1.1 Firewall Rules for DB ports] SGS hardening guidelines.
      6. Save the changes to the firewall rule.
      7. Verify that the firewall rule no longer allows inbound traffic from the internet to blocklisted database ports.
    terraform_remediation:  |
      1. Use the following Terraform code to create a new GCP VPC firewall rule that denies inbound traffic from the Internet to the identified blocklisted DB port:
      resource "google_compute_firewall" "example_google_compute_firewall" {
        source_ranges = <Specific IP CIDR range != 0.0.0.0/0 or ::/0>
        target_tags   = ["sec-by-def-database-port-exception"]

        allow {
          protocol = "tcp"
          ports    = [... 5432 3306 4333 1521 27017 1433 1434 ...]
        }

        allow {
          protocol = "udp"
          ports    = [... 5432 3306 4333 1521 27017 1433 1434 ...]
        }
      }
  - name: 6_01_02_gcp_admin_ports
    description:  6.1.2 - GCP Firewall rules must not allow inbound traffic from the Internet to blocklisted Administrative ports
    sgs_wiki_link: https://wiki.wdf.sap.corp/wiki/x/9Ik-cg
    query: GcpVpcFirewallRule with TargetTags not containing "sec-by-def-admin-port-exception" and IpPermissions with SourceRanges containing ( "::/0" or "0.0.0.0/0" ) and PortRange containing ([22, 3389, 135, 111, 5500, 5900][*]) and IpProtocol in ['tcp','udp','all'] and RuleType = 'INGRESS' and Action = 'allow' and not Disabled
    score: 8.0
    allow_orca_score_adjustment: false
    enabled: true
    category: Best practices
    minerva_control_id: 6_01_02_admin_ports
    remediation steps: |
      1. Go to the GCP console and navigate to the 'VPC firewall rules' page.
      2. Identify the firewall rule that is allowing inbound traffic from the internet to blocklisted Administrative ports.
      3. Edit the firewall rule to remove the blocklisted Administrative ports from the allowed inbound traffic.
      4. Make sure the following rule does not exists: 'Direction' as 'Ingress', 'Action' as 'Allow' and 'Enabled','Source IPv4 ranges' is 0.0.0.0/0 or 'Source IPv6 ranges' is ::/0; Under 'Protocols and ports': no Administrative ports are included in 'tcp' or 'udp' or 'all'.
      5. Navigate to the inbound rules > Click on Edit Inbound rules > Ensure CIDR block 0.0.0.0/0 or ::/0 is not bound to any of the following ports: RDP (3389), SSH (22), VNC (Listener: 5500, Server: 5900), RPC (135, 111) OR any ports mentioned in [6.1.2 Firewall Rules for ADMIN ports] SGS hardening guidelines.
      6. Save the changes to the firewall rule.
      7. Verify that the firewall rule no longer allows inbound traffic from the internet to blocklisted Administrative ports.
    terraform_remediation: |
      1. Use the following Terraform code to create a new GCP VPC firewall rule that denies inbound traffic from the Internet to the identified blocklisted Administrative port:
      resource "google_compute_firewall" "example_google_compute_firewall" {
        source_ranges = <Specific IP CIDR range != 0.0.0.0/0 or ::/0>
        target_tags   = ["sec-by-def-admin-port-exception"]

        allow {
          protocol = "tcp"
          ports    = [... 22 3389 135 111 5500 5900 ...]
        }

        allow {
          protocol = "udp"
          ports    = [... 22 3389 135 111 5500 5900 ...]
        }
      }
  - name: 6_01_03_gcp_infra_ports
    description:  6.1.3 - GCP Firewall rules should not allow inbound traffic from the Internet to blocklisted Infrastructure ports
    sgs_wiki_link: https://wiki.wdf.sap.corp/wiki/x/9Ik-cg
    query: GcpVpcFirewallRule with TargetTags not containing "sec-by-def-infrastructure-port-exception" and IpPermissions with SourceRanges containing ( "::/0" or "0.0.0.0/0" ) and PortRange containing ([53, 110, 25, 67, 68, 161, 162][*]) and IpProtocol in ['tcp','udp','all'] and RuleType = 'INGRESS' and Action = 'allow' and not Disabled
    score: 5.0
    allow_orca_score_adjustment: false
    enabled: true
    category: Best practices
    minerva_control_id: 6_01_03_infra_ports
    remediation_steps:  |
      1. Go to the GCP console and navigate to the 'VPC firewall rules' page.
      2. Identify the firewall rule that is allowing inbound traffic from the internet to blocklisted Infrastructure ports.
      3. Edit the firewall rule to remove the blocklisted Infrastructure ports from the allowed inbound traffic.
      4. Make sure the following rule does not exists: 'Direction' as 'Ingress', 'Action' as 'Allow' and 'Enabled','Source IPv4 ranges' is 0.0.0.0/0 or 'Source IPv6 ranges' is ::/0; Under 'Protocols and ports': no Infrastructure ports are included in 'tcp' or 'udp' or 'all'.
      5. Navigate to the inbound rules > Click on Edit Inbound rules > Ensure CIDR block 0.0.0.0/0 or ::/0 is not bound to any of the following ports: DNS (53), POP3 (110), SMTP (25), DHCP (67 & 68), SNMP (161 & 162) OR any ports mentioned in [6.1.3 Firewall Rules for Infrastructure ports] SGS hardening guidelines.
      6. Save the changes to the firewall rule.
      7. Verify that the firewall rule no longer allows inbound traffic from the internet to blocklisted Infrastructure ports.
    terraform_remediation:  |
      1. Use the following Terraform code to create a new GCP VPC firewall rule that denies inbound traffic from the Internet to the identified blocklisted Infrastructure port:
      resource "google_compute_firewall" "example_google_compute_firewall" {
        source_ranges = <Specific IP CIDR range != 0.0.0.0/0 or ::/0>
        target_tags   = ["sec-by-def-infrastructure-port-exception"]

        allow {
          protocol = "tcp"
          ports    = [... 53 110 25 67 68 161 162 ...]
        }

        allow {
          protocol = "udp"
          ports    = [... 53 110 25 67 68 161 162 ...]
        }
      }
  - name: 6_01_04_gcp_fileshare_ports
    description:  6.1.4 - GCP Firewall rules should not allow inbound traffic from the Internet to blocklisted File Share ports
    sgs_wiki_link: https://wiki.wdf.sap.corp/wiki/x/9Ik-cg
    query: GcpVpcFirewallRule with TargetTags not containing "sec-by-def-fileshare-port-exception" and IpPermissions with SourceRanges containing ( "::/0" or "0.0.0.0/0" ) and PortRange containing ([139, 445, 21, 69][*]) and IpProtocol in ['tcp','udp','all'] and RuleType = 'INGRESS' and Action = 'allow' and not Disabled
    score: 5.0
    allow_orca_score_adjustment: false
    enabled: true
    category: Best practices
    minerva_control_id: 6_01_04_fileshare_ports
    remediation_steps:  |
      1. Go to the GCP console and navigate to the 'VPC firewall rules' page.
      2. Identify the firewall rule that is allowing inbound traffic from the internet to blocklisted File Share ports.
      3. Edit the firewall rule to remove the blocklisted File Share ports from the allowed inbound traffic.
      4. Make sure the following rule does not exists: 'Direction' as 'Ingress', 'Action' as 'Allow' and 'Enabled','Source IPv4 ranges' is 0.0.0.0/0 or 'Source IPv6 ranges' is ::/0; Under 'Protocols and ports': no File Share ports are included in 'tcp' or 'udp' or 'all'.
      5. Navigate to the inbound rules > Click on Edit Inbound rules > Ensure CIDR block 0.0.0.0/0 or ::/0 is not bound to any of the following ports: NetBIOS (139), SMB (445), FTP (21), TFTP (69) OR any ports mentioned in [6.1.4 Firewall Rules for File Share ports] SGS hardening guidelines
      6. Save the changes to the firewall rule.
      7. Verify that the firewall rule no longer allows inbound traffic from the internet to blocklisted File Share ports.
    terraform_remediation:  |
      1. Use the following Terraform code to create a new GCP VPC firewall rule that denies inbound traffic from the Internet to the identified blocklisted File Share port:
      resource "google_compute_firewall" "example_google_compute_firewall" {
        source_ranges = <Specific IP CIDR range != 0.0.0.0/0 or ::/0>
        target_tags   = ["sec-by-def-fileshare-port-exception"]

        allow {
          protocol = "tcp"
          ports    = [... 139 445 21 69 ...]
        }

        allow {
          protocol = "udp"
          ports    = [... 139 445 21 69 ...]
        }
      }
  - name: 6_01_05_gcp_telnet_rsh_ports_ingress
    description:  6.1.5 - GCP Firewall rules must not allow inbound traffic from the Internet on Telnet or RSH ports
    sgs_wiki_link: https://wiki.wdf.sap.corp/wiki/x/9Ik-cg
    query: GcpVpcFirewallRule with IpPermissions with SourceRanges containing ( "::/0" or "0.0.0.0/0" ) and PortRange containing [23 , 514 ][*] and RuleType ilike 'INGRESS' and Action ilike 'allow' and not Disabled
    score: 8.0
    allow_orca_score_adjustment: false
    enabled: true
    category: Best practices
    minerva_control_id: 6_01_05_telnet_ports
    remediation_steps:  |
      1. Go to the GCP console and navigate to the 'VPC firewall rules' page.
      2. Edit the firewall rule to remove Telnet port (23) and RSH port (514) from the allowed ports.
      3. Make sure the following rule does not exist: 'Action' as 'Allow' and 'Enabled'
      4. Save the changes to the firewall rule.
      5. Verify that the firewall rule no longer allows traffic on Telnet port (23) or RSH port (514).
      6. Close the alert in the GCP console.
    terraform_remediation:  |
      1. Use the following Terraform code to create a new GCP VPC firewall rule that denies inbound traffic to Telnet and RSH ports:
      resource "google_compute_firewall" "example_google_compute_firewall" {
        source_ranges = <Specific IP CIDR range != 0.0.0.0/0 or ::/0>

        deny {
          protocols = ["all"]
          ports     = ["23", "514"]
        }
      }
  - name: 6_01_05_gcp_telnet_rsh_ports_egress
    description:  6.1.5 - GCP Firewall rules should not allow outbound traffic towards the Internet on Telnet or RSH ports
    sgs_wiki_link: https://wiki.wdf.sap.corp/wiki/x/9Ik-cg
    query: GcpVpcFirewallRule with IpPermissions with DestinationRanges containing ( "::/0" or "0.0.0.0/0" ) and PortRange containing [23 , 514 ][*] and RuleType ilike 'EGRESS' and Action ilike 'allow' and not Disabled
    score: 1.0
    allow_orca_score_adjustment: false
    enabled: true
    category: Best practices
    minerva_control_id: 6_01_05_telnet_ports
    remediation_steps:  |
      1. Go to the GCP console and navigate to the 'VPC firewall rules' page.
      2. Edit the firewall rule to remove Telnet port (23) and RSH port (514) from the allowed ports.
      3. Make sure the following rule does not exist: 'Action' as 'Allow' and 'Enabled'
      4. Save the changes to the firewall rule.
      5. Verify that the firewall rule no longer allows traffic on Telnet port (23) or RSH port (514).
      6. Close the alert in the GCP console.
    terraform_remediation:  |
      1. Use the following Terraform code to create a new GCP VPC firewall rule that denies outbound traffic to Telnet and RSH ports:
      resource "google_compute_firewall" "example_google_compute_firewall" {
        source_ranges = <Specific IP CIDR range != 0.0.0.0/0 or ::/0>

        deny {
          protocols = ["all"]
          ports     = ["23", "514"]
        }
      }
  - name: 6_03_gcp_load_balancer_tls_version
    description: 6.3 - GCP load balancers must be configured with SSL policy having TLS version 1.2 or higher
    sgs_wiki_link: https://wiki.wdf.sap.corp/wiki/x/9Ik-cg
    query: GcpLoadBalancer with SslPolicy and (SslPolicy.MinTlsVersion = ("TLS_1_0" or "TLS_1_1"))
    score: 8.0
    allow_orca_score_adjustment: false
    enabled: true
    category: Best practices
    minerva_control_id: 6_03_secure_load_balancer_configuration
    remediation_steps:  |
      1. Sign in to GCP Portal and navigate to 'Load Balancing' in the dashboard or use the search bar.
      2. Select the HTTPS/SSL Proxy load balancer mentioned in the alert.
      3. Click the 3-dot button and choose "Edit."
      4. In the 'Edit HTTP(S) load balancer' page, go to the 'Frontend configuration' tab.
      5. Click the downward arrow to access frontend configuration.
      6. Select the appropriate SSL policy that includes at least TLS 1.2, or create a new SSL policy if none exists.
      7. Click "Update" on the 'Edit HTTP(S) load balancer' page.
      8. Verify the correct SSL policy configuration by checking the Alert Details in the Security Command Center.
    terraform_remediation:  |
      1. Use the following Terraform code to update the appropriate SSL policy that includes at least TLS 1.2:
      resource "google_compute_target_https_proxy" "example_https_proxy" {
        ssl_policy       = <configured google compute ssl policy>
      }

       resource "google_compute_ssl_policy" "example_ssl_policy" {
        min_tls_version = "TLS_1_2"
      }
  - name: 6_04_gcp_vpn_secure_configuration
    description: 6.4 GCP VPN connections must use IKEv2
    sgs_wiki_link: https://wiki.wdf.sap.corp/wiki/x/9Ik-cg
    query: GcpVpnTunnel without IkeVersion = 2
    score: 8.0
    allow_orca_score_adjustment: false
    enabled: true
    category: Best practices
    minerva_control_id: 6_04_gcp_vpn_secure_configuration
    remediation_steps: |
      1. Sign in to GCP Portal.
      2. Navigate to VPN dashboard (or search for vpn in the search bar).
      3. select vpn tunnel for which alerts is raised.
      4. Under Details -> Routing and security section, IKE version must be IKEv2
    terraform_remediation:  |
      1. Use the following Terraform code to update the vpn tunnel to use IKE version 2
      resource "google_compute_vpn_tunnel" "example_vpn_tunnel" {
        ike_version = 2
      }
  # Chapter 7
  - name: 7_04_gcp_gke_unsupported_master_node_version
    description: 7.4 - GCP GKE must have supported Master node version
    sgs_wiki_link: https://wiki.wdf.sap.corp/wiki/x/9Ik-cg
    query: GcpGkeCluster without IsMasterVersionValid
    score: 8.0
    allow_orca_score_adjustment: false
    enabled: true
    category: Best practices
    minerva_control_id: 7_04_gke_unsupported_master_version
    remediation_steps:  |
      1. Log in to the GCP console using the appropriate credentials.
      2. Navigate to the GKE cluster identified in the alert details
      3. Check the version of the master node by running the following command:gcloud container clusters describe rme-production --zone=ASSET_AVAILABILITY_ZONE --format="value(currentMasterVersion)"
      4. Replace ASSET_AVAILABILITY_ZONE with the appropriate zone for the cluster.
      5. Compare the version obtained in step 3 with the list of supported versions provided by GCP here: <https://cloud.google.com/kubernetes-engine/docs/release-notes>
      6. Replace SUPPORTED_VERSION with a version from the list of supported versions provided by GCP.
      7. Verify that the master node has been upgraded by running the command in step 3 again.
    terraform_remediation:  |
      1. Use the following Terraform code to update GKE cluster master node with the latest list supported versions provided by GCP:
      resource "google_container_cluster" "example_google_container_cluster" {
        min_master_version = data.google_container_engine_versions.example_container_engine_version.latest_node_version
      }

      data "google_container_engine_versions" "example_container_engine_version" {
        version_prefix = "latest"
      }
  - name: 7_04_gcp_gke_master_authorized_network
    description: 7.4 - GCP Kubernetes Engine Clusters should have Master authorized networks enabled
    sgs_wiki_link: https://wiki.wdf.sap.corp/wiki/x/9Ik-cg
    query: GcpGkeCluster without MasterAuthorizedNetworksConfig['enabled'] = true
    score: 5.0
    allow_orca_score_adjustment: false
    enabled: true
    category: Best practices
    minerva_control_id: 7_04_gke_master_authorized_networks
    remediation_steps:  |
      1. Go to the GCP console and navigate to the Kubernetes Engine Clusters page.
      2. Select the GKE cluster with the Asset Name
      3. Click on the "Edit" button at the top of the page.
      4. Scroll down to the "Security" section and click on "Master authorized networks".
      5. Select "Enable master authorized networks".
      6. Add the appropriate network CIDR range(s) to the "Authorized networks" field.
      7. Click "Save" to apply the changes.
      8. Verify that the alert has been resolved in the Security Command Center.
    terraform_remediation:  |
      1. Use the following Terraform code to enable Master authorized networks for the GCP Kubernetes Engine Cluster:
      resource "google_container_cluster" "example_google_container_cluster" {
        master_authorized_networks_config {
        }
      }
  - name: 7_06_gcp_gke_stackdriver_monitoring
    description: 7.6 - GCP Kubernetes Engine Clusters should have Stackdriver Monitoring enabled
    sgs_wiki_link: https://wiki.wdf.sap.corp/wiki/x/9Ik-cg
    query: GcpGkeCluster without monitoringService like 'monitoring.googleapis.com'
    score: 5.0
    allow_orca_score_adjustment: false
    enabled: true
    category: Best practices
    minerva_control_id: 7_06_gke_stackdriver_monitoring_enabled
    remediation_steps:  |
      1. Go to the GCP console and navigate to the 'Kubernetes Engine Clusters' page.
      2. Select the cluster with the Asset Name - prod.
      3. Click on the "Edit" button at the top of the page.
      4. Scroll down to the "Stackdriver" section and enable "Stackdriver Monitoring".
      5. Click on the "Save" button to save the changes.
      6. Verify that Stackdriver Monitoring is enabled for the cluster by checking the "Monitoring" tab in the cluster details page.
    terraform_remediation:  |
      1. Use the following Terraform code to create a google_container_cluster resource with the valid monitoring_service:
      resource "google_container_cluster" "example_google_container_cluster" {
        monitoring_service = <Valid monitoring service>

      2. Use the following Terraform code to create a google_container_cluster resource with the monitoring_config block enabled:
      } Create a google_container_cluster resource with the monitoring_config block enabled:
      resource "google_container_cluster" "example_google_container_cluster" {
        monitoring_config {
        enabled = true}
  - name: 7_06_gcp_gke_legacy_authorization
    description: 7.6 - GCP Kubernetes Engine Clusters should have Legacy Authorization disabled
    sgs_wiki_link: https://wiki.wdf.sap.corp/wiki/x/9Ik-cg
    query: GcpGkeCluster with LegacyAbac
    score: 5.0
    allow_orca_score_adjustment: false
    enabled: true
    category: Best practices
    minerva_control_id: 7_06_gke_legacy_authorization_enabled
    remediation_steps:  |
      1. Open the GCP console and navigate to the 'GKE cluster'
      2. Click on the "Edit" button.
      3. Scroll down to the "Legacy Authorization" section.
      4. Disable the "Enable legacy authorization (ABAC)" option.
      5. Click on the "Save" button to apply the changes.
      6. Verify that the cluster is now using RBAC by checking the "Authorization" section.
    terraform_remediation:  |
      1. Use the following Terraform code to disable the legacy authorization ABAC:
      resource "google_container_cluster" "example_google_container_cluster" {
        enable_legacy_abac = false
      }
  - name: 7_09_gcp_gke_network_policy
    description: 7.9 - GCP Kubernetes Engine Clusters should have Network Policy enabled
    sgs_wiki_link: https://wiki.wdf.sap.corp/wiki/x/9Ik-cg
    query: GcpGkeCluster without IsNetworkPolicyEnabled
    score: 5.0
    allow_orca_score_adjustment: false
    enabled: true
    category: Best practices
    minerva_control_id: null
    remediation_steps:  |
      1. Go to 'Kubernetes Engine' page in GCP console.
      2. In the search bar > Click on the cluster for which the alert is raised.
      3. Under Networking, in the Network policy field, click "Edit Network Policy"
      4. Select the "Enable network policy for master" checkbox and click "Save Changes"
      5. Wait for the changes to aply, and then click "Edit network policy" again.
      6. Select the "Enable network Policy for nodes" checkbox
    terraform_remediation:  |
      1. Use the following Terraform code to enable network policy for master and nodes:
      resource "google_container_cluster" "example_cluster" {
        name               = "example-cluster"
        location           = "us-central1"
        initial_node_count = 1
        network_policy {
          enabled = true
        }
      }
  - name: 7_11_gcp_gke_basic_authentication
    description: 7.11 - GCP Kubernetes Engine Clusters Basic Authentication should be disabled
    sgs_wiki_link: https://wiki.wdf.sap.corp/wiki/x/9Ik-cg
    query: GcpGkeCluster with IsBasicAuthEnabled
    score: 5.0
    allow_orca_score_adjustment: false
    enabled: true
    category: Best practices
    minerva_control_id: 7_11_disable_gke_basic_authentication
    remediation_steps:  |
      1. Login to GCP console and type 'Kubernetes Clusters'
      2. In the search bar > Click on the cluster for which the alert is raised.
      3. In the Details tab, under Security > 'Basic authentication' attribute should be 'Disabled'.
    terraform_remediation:  |
      1. Use the following Terraform code to disable GKE Basic authentication:
      resource "google_container_cluster" "example_google_container_cluster" {
        master_auth {
          client_certificate_config {
          }
        }
      }
  - name: 7_12_gcp_gke_cluster_private_node
    description: 7.12 - GCP Kubernetes Engine Clusters should be configured with private nodes feature
    sgs_wiki_link: https://wiki.wdf.sap.corp/wiki/x/9Ik-cg
    query: GcpGkeCluster without PrivateClusterConfig['enablePrivateNodes'] = true
    score: 5.0
    allow_orca_score_adjustment: false
    enabled: true
    category: Best practices
    minerva_control_id: 7_12_enable_gke_cluster_private_nodes
    remediation_steps:  |
      1. Go to the GCP console and navigate to the 'Kubernetes Engine Clusters' page.
      2. In the search bar > Click on the cluster for which the alert is raised.
      3. Click on the Edit button.
      4. Scroll down to the Node Pools section and click on the node pool that needs to be configured with private nodes.
      5. In the Node pool details page, scroll down to the Networking section.
      6. Under Networking, select the Private cluster checkbox.
      7. Click Save to apply the changes.
      8. Verify that the node pool is now configured with private nodes by checking the Networking section again.
      9. Once all node pools are configured with private nodes, the alert should be resolved.
    terraform_remediation:  |
      1. Use the following Terraform code to enable GKE private nodes:
      resource "google_container_cluster" "example_google_container_cluster" {
        private_cluster_config {
        enable_private_nodes    = true
        enable_private_endpoint = true
        }
      }
  - name: 7_13_gcp_gke_cluster_shielded_gke_node
    description: 7.13 - GCP “Shielded GKE” nodes should be enabled
    sgs_wiki_link: https://wiki.wdf.sap.corp/wiki/x/9Ik-cg
    query: GcpGkeCluster without ShieldedNodes['enabled'] = true
    score: 5.0
    allow_orca_score_adjustment: false
    enabled: true
    category: Best practices
    minerva_control_id: null
    remediation_steps:  |
      1. Go to the GCP console and navigate to the 'Kubernetes Engine Clusters' page
      2. In the search bar > Click on the cluster for which the alert is raised.
      3. From the list of clusters, click on the cluster requiring the update and click ADD NODE POOL
      4. Ensure that the 'Integrity monitoring' checkbox is checked under the 'Shielded options' Heading.
      5. Click SAVE.
    terraform_remediation:  |
      1. Use the following Terraform code to enable GCP “Shielded GKE” nodes:
      resource "google_container_cluster" "gke_cluster" {
        name               = "my-gke-cluster"
        location           = "us-central1"
        initial_node_count = 1
        shielded_instance_config {
          enable_secure_boot = true
          }
      }
  - name: 7_15_gcp_gke_container_optimized_node_image
    description: 7.15 - GCP Kubernetes Engine Clusters should use Container-Optimized OS for Node image
    sgs_wiki_link: https://wiki.wdf.sap.corp/wiki/x/9Ik-cg
    query: GcpGkeCluster with NodePools with ImageType != 'COS' and ImageType != 'COS_CONTAINERD'
    score: 5.0
    allow_orca_score_adjustment: false
    enabled: true
    category: Best practices
    minerva_control_id: 7_15_gke_container_optimized_node_image
    remediation_steps:  |
      1. Navigate to 'Kubernetes Engine Clusters' in the GCP console.
      2. Click on the cluster associated with the alert, then click "Edit."
      3. In the Node Pools section, click "Edit" for the relevant node pool.
      4. Choose "Container-Optimized OS" from the Node Image Type dropdown.
      5. Click "Save" to apply the changes.
      6. Verify the node pool is using the Container-Optimized OS image by checking the Node Image Type column in the Node Pools section.
      7. After updating all node pools, click "Save" at the bottom of the page to save changes to the GcpGkeCluster asset.
    terraform_remediation:  |
      1. Use the following Terraform code to use the GKE node pool that is using the "Container-Optimized OS" from the Node Image Type:
      resource "google_container_cluster" "example_google_container_cluster" {
        node_config {
        image_type = <Valid image type>
        }
      }
  # Chapter 8
  - name: 8_01_gcp_cache_redis_encryption_support_patches
    description: 8.1 - GCP Caching Software (Redis) must use transit encryption and be still supported with security patches (no active use of End of Life versions)
    sgs_wiki_link: https://wiki.wdf.sap.corp/wiki/x/9Ik-cg
    query: GcpRedisInstance with RedisVersion != 'REDIS_6_X' or TransitEncryptionMode != 'SERVER_AUTHENTICATION'
    score: 8.0
    allow_orca_score_adjustment: false
    enabled: true
    category: Best practices
    minerva_control_id: 8_01_caching_encryption_and_versioning
    remediation_steps:  |
      1. Log in to the GCP console and Navigate to the Redis instance
      2. Click on the Redis instance name to open its details page.
      3. Click on the "Edit" button at the top of the page.
      4. Scroll down to the "Encryption" section and select "Transit encryption."
      5. Scroll further down to the "Version" section and select a supported version if the Redis instance is running an End of Life version.
      6. Click on the "Save" button to apply the changes.
      7. Verify that the Redis instance is now using transit encryption and is running on a supported version.
    terraform_remediation:  |
      1. Use the following Terraform code to use the supported Redis version if the Redis instance is running an End of Life version:
      resource "google_redis_instance" "example_redis_instance" {
        transit_encryption_mode = 'SERVER_AUTHENTICATION'
        redis_version           = 'REDIS_6_X'
      }
  - name: 8_01_gcp_cache_memcached_support_patches
    description: 8.1 - GCP Caching Software (Memcached) must be still supported with security patches (no active use of End of Life versions)
    sgs_wiki_link: https://wiki.wdf.sap.corp/wiki/x/9Ik-cg
    query: GcpMemcacheCluster with not MemcacheFullVersion ilike "1.6."
    score: 8.0
    allow_orca_score_adjustment: false
    enabled: true
    category: Best practices
    minerva_control_id: null
    remediation_steps:  |
      1. Log in to the GCP console and Navigate to the 'GcpMemcacheCluster'
      2. Check the version of Memcached currently running on the cluster.
      3. If the version is End of Life, upgrade to the latest version that is still supported with security patches.
      4. Verify that the upgraded version is running on the cluster.
      5. Monitor the cluster for any security vulnerabilities and apply patches as necessary.
      6. Document the remediation steps taken for future reference.
    terraform_remediation:  |
      1. Use the following Terraform code to upgrade Memcached to the latest version that is still supported with security patches, if the version is End of Life:
      resource "google_memcache_instance" "example" {
        name               = "projects/ems-mobile-engage/locations/europe-west3/instances/client-state"
        tier               = "STANDARD"
        memory_size_gb     = 1
        region             = "us-central1"
        memcache_version   = "memcache-1.5.16"
        reserved_ip_range  = "10.0.0.0/29"
        instance_count     = 1
        display_name       = "example-memcache"
        authorized_network = "default"
      }
  - name: 8_03_gcp_sql_instance_internet_exposure
    description: 8.3 - GCP SQL instances must not be exposed to the Internet
    sgs_wiki_link: https://wiki.wdf.sap.corp/wiki/x/9Ik-cg
    query: GcpSQLInstance with AuthorizedNetworksConfiguration like '0.0.0.0/0'
    score: 8.0
    allow_orca_score_adjustment: false
    enabled: true
    category: Best practices
    minerva_control_id: 8_03_sql_instance_network_authorization
    remediation_steps:  |
      1. Log in to the GCP console and Navigate to the GCP SQL instance
      2. Click on the "Edit" button for the instance which the alert is raised
      3. Under the "Connections" section, select "Private IP" for the "Public IP" option.
      4. Click on the "Save" button to apply the changes.
      5. Verify that the instance is no longer exposed to the internet by checking the "Public IP" field in the instance details. It should be blank.
    terraform_remediation:  |
      1. Use the following Terraform code to allow only authorized networks on GCP SQL instance:
      resource "google_sql_database_instance" "example_sql_db_instance" {
        settings {
         ip_configuration {
            authorized_networks {
              value = <list of allowed IP CIDRs>
            }
          }
        }
      }
  - name: 8_03_gcp_sql_instance_ssl_configuration
    description: 8.3 - GCP SQL instances must have SSL configured
    sgs_wiki_link: https://wiki.wdf.sap.corp/wiki/x/9Ik-cg
    query: GcpSQLInstance without RequireSsl
    score: 8.0
    allow_orca_score_adjustment: false
    enabled: true
    category: Best practices
    minerva_control_id: 8_03_sql_instance_configure_ssl
    remediation_steps:  |
      1. Log in to the GCP console and Navigate to the 'Cloud SQL instances' page.
      2. Click on the "Edit" button for the instance which the alert is raised
      3. Under the "Connections" section, select "Require SSL".
      4. Click on the "Save" button to apply the changes.
      5. Verify that SSL is now configured for the SQL instance by checking the "SSL" column on the Cloud SQL instances page. It should show "Enabled".
    terraform_remediation:  |
      1. Use the following Terraform code to enable require SSL on Cloud SQL instances:
      resource "google_sql_database_instance" "example_sql_db_instance" {
        settings {
          ip_configuration {
            require_ssl = true
          }
        }
      }
  - name: 8_04_gcp_dnssec
    description: 8.4 - GCP Cloud DNS zones should have DNSSEC enabled
    sgs_wiki_link: https://wiki.wdf.sap.corp/wiki/x/9Ik-cg
    query: GcpDnsManagedZone with Visibility = 'public' and not DnssecState = 'on'
    score: 5.0
    allow_orca_score_adjustment: false
    enabled: true
    category: Best practices
    minerva_control_id: 8_04_dnssec_enabled
    remediation_steps:  |
      At the moment, DNSSEC zone-signing can only be changed using command line interface/terminal.
      1. If you need to updated the settings for a managed zone where it's been enabled, you have to turn DNSSEC off and then re-enable it with altered settings.
      To turn off DNSSEC, run following command: gcloud dns managed-zones update <ZONE_NAME> --dnssec-state off
    terraform_remediation:  |
      1. Use the following Terraform code to enable the DNSSEC state:
      resource "google_dns_managed_zone" "example_dns_managed_zone" {
        dnssec_config {
          state = "on"
        }
      }
  - name: 8_03_gcp_dms_conn_profile_tls_ssl
    description: 8.3 - GCP Database Migration Service connection profile must use TLS/SSL encryption
    sgs_wiki_link: https://wiki.wdf.sap.corp/wiki/x/9Ik-cg
    query: GcpDmsSourceConnectionProfile without SslType
    score: 1.0
    allow_orca_score_adjustment: false
    enabled: true
    category: Best practices
    minerva_control_id: null
    remediation_steps:  |
      1. Log in to the GCP console and Navigate to the "Database Migration" page.
      2. Left side click on "Connection profiles"
      3. Click on the "Edit" button for the connection profile which the alert is raised.
      4. Under the "Secure your connection" section, click "Update" and change Encryption type.
      5. Click on the "Save" button to apply the changes.
      6. Verify that TLS/SSL is now configured for the connection profile by checking the "Encryption type (SSL/TLS)". It should not show "None".
    terraform_remediation:  |
      1. Use the following Terraform code to create SSL cert for Database Migration service:
      resource "google_sql_ssl_cert" "sql_client_cert" {
        common_name = "my-cert"
        instance    = google_sql_database_instance.postgresqldb.name
        depends_on = [google_sql_database_instance.postgresqldb]
      }
      2. Use the SSL cert in DMS connection profile like below.
      resource "google_database_migration_service_connection_profile" "cloudsqlprofile" {
        location              = "us-central1"
        connection_profile_id = "my-fromprofileid"
        display_name          = "my-fromprofileid_display"
        mysql {
            // add database information for my-database
          ssl {
            client_key         = google_sql_ssl_cert.sql_client_cert.private_key
            client_certificate = google_sql_ssl_cert.sql_client_cert.cert
            ca_certificate     = google_sql_ssl_cert.sql_client_cert.server_ca_cert
          }
          cloud_sql_id = "my-database"
        }
      }
  - name: 8_04_gcp_dnssec_ksk_and_zsk
    description: 8.4 - GCP Cloud DNS zones with DNSSEC enabled must not use DNSSEC key-signing and zone-signing keys with deprecated SHA1 algorithm (such as RSASHA1)
    sgs_wiki_link: https://wiki.wdf.sap.corp/wiki/x/9Ik-cg
    query: GcpDnsManagedZone with Visibility = 'public' and DnssecState = 'on' and ( DnssecKeySigningKey.algorithm = 'rsasha1' or DnssecZoneSigningKey.algorithm ='rsasha1' or DnssecKeySigningKey.key_length < 2048 or DnssecZoneSigningKey.key_length < 2048 )
    score: 8.0
    allow_orca_score_adjustment: false
    enabled: true
    category: Best practices
    minerva_control_id: 8_04_dnssec_enabled
    remediation_steps:  |
      1. Log in to the GCP console and Navigate to the 'Cloud DNS' page.
      2. Select the DNS zone with DNSSEC enabled that needs to be remediated.
      3. Click on the "DNSSEC" tab.
      4. Check if the DNSSEC key-signing and zone-signing keys are using the deprecated SHA1 algorithm (such as RSASHA1).
      5. If the keys are using the deprecated algorithm, generate new keys using a stronger algorithm such as RSASHA256 or ECDSAP256SHA256.
      6. Update the DNS zone with the new keys.
      7. Verify that the DNS zone is now using the updated keys.
      8. Alternatively,run following command: gcloud dns managed-zones update <ZONE_NAME> --dnssec-state on --ksk-algorithm <KSK_ALGORITHM> --ksk-key-length <KSK_KEY_LENGTH> --zsk-algorithm
    terraform_remediation:  |
      1. Use the following Terraform code to update the new keys using a stronger algorithm such as RSASHA256 or ECDSAP256SHA256 for DNS zone:
      resource "google_dns_managed_zone" "example_dns_managed_zone" {
        dnssec_config {
        state = "on"
          default_key_specs {
            algorithm = <encryption algorithm that isn't rsasha1 (ex rsasha256)>
            key_length = <value greater than or equal to 2048>
          }
        }
      }
  - name: 8_05_gcp_cdn_https_only
    description: 8.5 - GCP CDN service should use HTTPS-only communication
    sgs_wiki_link: https://wiki.wdf.sap.corp/wiki/x/9Ik-cg
    query: >
      ( GcpLoadBalancerBackendBucket or GcpLoadBalancerBackendService ) with EnableCDN and not ( LoadBalancers with LoadBalancerKind like "HttpsProxy" )
    score: 1.0
    allow_orca_score_adjustment: false
    enabled: true
    category: Best practices
    minerva_control_id: null
  # Informational
  - name: gcp_user_policybinding
    description: (INFORMATIONAL - NO ACTION REQUIRED) GCP Users with their roles (policy bindings)
    sgs_wiki_link: null
    query: GcpUser with PolicyBindings
    score: 1.0
    allow_orca_score_adjustment: false
    enabled: true
    category: Best practices
    minerva_control_id: null
    remediation_steps:  |
      As the alert is informational and no action is required, there is no need for remediation steps. However, it is recommended to review the GCP users and their roles (policy bindings) to ensure that they have the appropriate level of access and permissions. This can be done by following these steps:
      1. Log in to the GCP console and Navigate to the 'IAM & Admin' page.
      2. Click on the Users tab.
      3. Review the list of users and their associated roles (policy bindings).
      4. Make any necessary changes to the roles and permissions to ensure that they are appropriate for each user's job responsibilities.
      5. Regularly review and update the roles and permissions as needed to maintain the security of the GCP environment.
    terraform_remediation:  |
      1. Use the following Terraform code to update users and their associated roles (policy bindings) to maintain the security of the GCP environment:
      module "gcp_user_policy_binding" {
      source  = "terraform-google-modules/iam/google//modules/user_policy_binding"
      version = "~> 4.0"
      project_id = <>
      user       = <>
        roles = [
          "roles/viewer",
          "roles/storage.objectViewer"
        ]
      }
global_labels:
  - sap_gcp
  - sap