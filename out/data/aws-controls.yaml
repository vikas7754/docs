---
controls:
  # Chapter 2
  - name: 2_01_aws_iam_server_cert_expired
    description: 2.1 - AWS IAM SSL/TLS certificates should not be expired
    sgs_wiki_link: https://wiki.wdf.sap.corp/wiki/x/-0JAc
    query: AwsCertificate with Status = 'expired' and Source = 'iam_certificate'
    score: 5.0
    allow_orca_score_adjustment: false
    enabled: true
    category: Best practices
    minerva_control_id: 2_01_iam_server_cert_expired
    remediation_steps:  |
      1. Log in to the AWS console.
      2. Navigate to the IAM service.
      3. Click on the "Server Certificates" tab.
      4. Locate the expired certificate.
      5. Click on the certificate and select "Delete".
      6. Follow the prompts to confirm the deletion.
      7. Generate a new SSL/TLS certificate for the affected asset.
      8. Update the asset with the new certificate information.
    terraform_remediation:  |
      1.  To generate a new SSL/TLS certificate, use the following Terraform module:
            resource "aws_acm_certificate" "example" {
              domain_name       = "example.com"  # Replace with your domain name
              subject_alternative_names = ["www.example.com"]  # Optional
              validation_method = "DNS"
            }
      2. After requesting the certificate, you'll need to wait for it to be issued and validated.
  - name: 2_01_aws_key_last_use
    description: 2.1 - AWS access keys must be used in the last 90 days
    sgs_wiki_link: https://wiki.wdf.sap.corp/wiki/x/-0JAc
    query: AwsAccessKey with CloudAccount.AwsUser with Name != 'azure-sync-user' and ( ( AccessKey1Active and AccessKey1LastUsedDate > 90 days ago ) or ( AccessKey2Active and AccessKey2LastUsedDate > 90 days ago ) )
    score: 8.0
    allow_orca_score_adjustment: false
    enabled: true
    category: Best practices
    minerva_control_id: 2_01_key_last_use
  - name: 2_01_aws_iam_access_key_rotation
    description: 2.1 - AWS IAM Access keys must be rotated within 90 days
    sgs_wiki_link: https://wiki.wdf.sap.corp/wiki/x/-0JAc
    query: AwsUser with ( (AccessKey1Active and AccessKey1LastRotated not in last 90 days) or (AccessKey2Active and AccessKey2LastRotated not in last 90 days) ) and Name != "azure-sync-user"
    score: 8.0
    allow_orca_score_adjustment: false
    enabled: true
    category: Best practices
    minerva_control_id: 2_01_key_rotation
    remediation_steps:  |
      1. Navigate to the IAM service (or search for IAM in the search bar).
      2. Click on the user that was reported in the alert.
      3. Click on Security Credentials and for each Access Key, follow the instructions below to rotate the Access Keys that are older than 90 days: https://docs.aws.amazon.com/IAM/latest/UserGuide/id_credentials_access-keys.html#rotating_access_keys_console
    terraform_remediation:  |
      1. To create the new access key, use the following Terraform module:
            resource "aws_iam_access_key" "new_access_key" {
              user = aws_iam_user.user1.name
            }
      2. Please delete the old access key once the new access key has been tested and confirmed to be functioning correctly.
  - name: 2_01_aws_iam_ssh_key_rotation
    description: 2.1 - AWS IAM SSH keys must be rotated within 730 days
    sgs_wiki_link: https://wiki.wdf.sap.corp/wiki/x/-0JAc
    query: AwsUser with SshPublicKeys with UploadDate <= 730 days ago
    score: 8.0
    allow_orca_score_adjustment: false
    enabled: true
    category: Best practices
    minerva_control_id: 2_01_iam_ssh_key_age_rotation
    remediation_steps:  |
      1. Login to AWS Console.
      2. Go to IAM (or search for IAM in the search bar) > Select Users.
      3. Click on the user mentioned in the alert.
      4. Click on the Security Credentials tab.
      5. Delete the SSH Key ID > Upload a new SSH Key. Please see the following link for details on key creation steps: https://docs.aws.amazon.com/codecommit/latest/userguide/setting-up-ssh-unixes.html
    terraform_remediation:  |
      1. To remove the SSH Key ID, please use the following Terraform Code:
            resource "aws_iam_user_ssh_key" "old_key_pair" {
              username = aws_iam_user.user.name
              encoding = "SSH"
              public_key = "ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQDQ..."
              revoke = true
            }
      2. To create new SSH Key ID, please use the folowing Terraform Code:
            resource "aws_key_pair" "new_key_pair" {
              key_name   = "new_key_pair"
              public_key = "ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQDQ..."
            }      
      3. To update new SSH Key ID , please use the following Terraform Code:
            resource "aws_iam_user_ssh_key" "new_key_pair" {
              username = aws_iam_user.user.name
              encoding = "SSH"
              public_key = aws_key_pair.new_key_pair.public_key
            }
  - name: 2_01_aws_iam_password_policy
    description: 2.1 - AWS Password Policy must be compliant with SAP Accounts & Password Standard
    sgs_wiki_link: https://wiki.wdf.sap.corp/wiki/x/-0JAc
    query: CloudAccount with CloudProvider = "aws" and not AwsIamPasswordPolicy or AwsIamPasswordPolicy with MinimumPasswordLength < 15 or not MinimumPasswordLength or MaxPasswordAge > 90 or not MaxPasswordAge or PasswordReusePrevention < 15 or not PasswordReusePrevention or not ((RequireLowercaseCharacters or RequireNumbers or RequireSymbols) or (RequireLowercaseCharacters or RequireNumbers or RequireUppercaseCharacters) or (RequireLowercaseCharacters or RequireSymbols or RequireUppercaseCharacters) or (RequireNumbers or RequireSymbols or RequireUppercaseCharacters))
    score: 8.0
    allow_orca_score_adjustment: false
    enabled: true
    category: Best practices
    minerva_control_id: ra_2_password_policy
    remediation_steps:  |
      1. All Hyperscaler Account's password policies are managed by Multicloud Hyperscaler Team.
      2. Therefore any remediation action required for this policy should be contacted to Multicloud Hyperscaler Team via ServiceNow Ticket
  - name: 2_02_aws_iam_group_admin_access
    description: 2.2 - AWS Accounts must not have more than 1 AWS IAM group with admin privileges
    sgs_wiki_link: https://wiki.wdf.sap.corp/wiki/x/-0JAc
    query: AwsIamGroup with Name != "AdminsGroup" and Policies with PolicyStatements with Resource containing "*" and Action containing "*" and Effect = "Allow"
    score: 8.0
    allow_orca_score_adjustment: false
    enabled: true
    category: Best practices
    minerva_control_id: 2_02_iam_group_admin_access
    remediation_steps:  |
      1. Log in to AWS console.
      2. Navigate to IAM service.
      3. Click on User Groups > AdminsGroup > Click on the Permissions tab > Click on AdministratorAccess > Click on the PolicyUsage Tab > Check the box in front of the AdminsGroup > Click on Detach OR Under ‘Inline Policies’ click on ‘Edit Policy’ or ‘Remove Policy’ and assign a limited permission. 
    terraform_remediation:  |
      resource "aws_iam_group_policy_attachment" "example_group_policy_attachment" {
        group      = "your-group-name"  # Replace with your group name
        policy_arn = "arn:aws:iam::your-account-id:policy/your-policy-name"  # Replace with your policy ARN with limited set of actions
      }
  - name: 2_02_aws_iam_user_admin_access
    description: 2.2 - AWS IAM Users should not have administrator access permissions
    sgs_wiki_link: https://wiki.wdf.sap.corp/wiki/x/-0JAc
    query: AwsUser with Policies with ResourceType != 'managed_policy' and PolicyStatements with (Effect = 'Allow' and Action containing ('*') and Resource containing '*' ) and not Name like ( "awsrechnung" or "svc-mc-billing-cbr-masterbilling" or "svc-mc-billing-ro-user" or "svc-mc-billing-service-account" or "svc-mc-billing-ri-purchase" or "svc-mc-cfte-ch-sync" or "svc-mc-cfte-supportd" or "svc-mc-cfte-creator" or "svc-mc-cost-explorer" or "svc-mc-costexplorer-nuno" or "svc-mc-hypersense-health-access" or "svc-mc-netops-netbrain" or "svc-mc-devopsaws-terraform" or "svc-mc-devsecops-chef-dev" or "svc-mc-devsecops-chef-prod" or "sap-devsecops-prisma-onboarder" or "svc-gcs-inventory-scanner" or "svc-gcs-platform-analytics" or "svc-itam-service-account" or "azure-sync-user" )
    score: 5.0
    allow_orca_score_adjustment: false
    enabled: true
    category: Best practices
    minerva_control_id: 2_02_iam_user_admin_access
    remediation_steps:  |
      1. Sign in to the AWS Management Console.
      2. Navigate to IAM dashboard (or search for IAM in the search bar).
      3. In the left navigation panel, select Users > Click on the privileged AWS IAM user that you want to reconfigure.
      4. On the IAM user Summary page, click on the Permissions tab.
      5. Find the AWS AdministratorAccess managed policy > Detach it from the selected IAM user by clicking the x icon next to the policy entry.
      6. Within the Detach policy dialog box, click Detach.
    terraform_remediation:  |
      resource "aws_iam_user_policy_attachment" "example_iam_user_policy_attachment" {
        user      = "your-iam-user-name"  # Replace with your IAM user name
        policy_arn = "arn:aws:iam::your-account-id:policy/your-policy-name"  # Replace with your policy ARN with limited set of actions
      }
  - name: 2_02_aws_iam_role_admin_access
    description: 2.2 - AWS IAM Roles should not have administrator access permissions
    sgs_wiki_link: https://wiki.wdf.sap.corp/wiki/x/-0JAc
    query: AwsIamRole with ( Policies with PolicyStatements with Resource containing "*" and Action containing "*" and Effect = "Allow" ) and not Tags [ "BTP_IAM_Role" ] = "ADMIN" and not Name like ( "stacksets-exec" or "MsCrossAccountAccessRole" or "OrganizationAccountAccessRole" or "aws-sso-admin-role" )
    score: 5.0
    allow_orca_score_adjustment: false
    enabled: true
    category: Best practices
    minerva_control_id: 2_02_iam_role_admin_access
    remediation_steps:  |
      1. Log in to AWS console.
      2. Navigate to IAM service (or search for IAM in the search bar).
      3. Click on Roles > Click on reported IAM role that caused the alert.
      4. Under Permissions policies, click on checkbox next to the permissions that has caused the alert > Click Remove.
    terraform_remediation:  |
      resource "aws_iam_policy" "example_role_policy" {
        name = <your role name>

        policy = jsonencode({
          Version = "2012-10-17"
          Statement = [
          {
            Action   = [<limited list of actions>]
            Effect   = "Allow"
            Resource = [<limited list of resources>]
          },
        ]
        })
      }
  - name: 2_03_aws_iam_user_mfa
    description: 2.3 - AWS Multi-Factor Authentication (MFA) must be enabled for all IAM user accounts
    sgs_wiki_link: https://wiki.wdf.sap.corp/wiki/x/-0JAc
    query: AwsUser with not Name = 'azure-sync-user' and PasswordEnabled and not MfaActive
    score: 8.0
    allow_orca_score_adjustment: false
    enabled: true
    category: Best practices
    minerva_control_id: 2_03_mfa_enabled
    remediation_steps:  |
      1. Sign in to AWS > Navigate to the IAM service (or search for IAM in the search bar).
      2. Under Access management > Click Users > Navigate to the user that was reported in the alert > Click on the user’s name.
      3. Click on the Security Credentials tab > Under Security Credentials, check Assigned MFA Device (or click Manage) > Follow the instructions to enable MFA for the user. 
    terraform_remediation:  |
      There is currently no Terraform remediation defined, please reach out to us on slack if you believe Terraform could be used for remediation in this instance.
  # Chapter 3
  - name: 3_06_aws_kms_key_rotation
    description: 3.6 - AWS Key Management Service (KMS) key rotation must be enabled
    sgs_wiki_link: https://wiki.wdf.sap.corp/wiki/x/-0JAc
    query: >
      [AwsKmsKey with KeyEnabled = true and KeyManager != "AWS" and not Tags [ 'policies.default.Id' ] = 'DataCustodian'] with (((Origin = "EXTERNAL" or KeySpec != "SYMMETRIC_DEFAULT" or Origin = "AWS_CLOUDHSM") and CreationTime not in last 365 days) or (Origin != "EXTERNAL" and KeySpec = "SYMMETRIC_DEFAULT" and Origin != "AWS_CLOUDHSM" and RotationEnabled=false))
    score: 8.0
    allow_orca_score_adjustment: false
    enabled: true
    category: Best practices
    minerva_control_id: 3_06_kms_key_rotation
    remediation_steps:  |
      1. Login to AWS Console.
      2. Go to Key Management Services (or search for KMS in the search bar).
      3. In the left navigation pane, click Customer managed keys.
      4. Click on the key ID mentioned in the alert.
      5. Click on the Key Rotation tab.
      6. Select Rotate this key every year checkbox.
      7. Click Save.
    terraform_remediation:  |
      resource "aws_kms_key" "example_key_rotation_enabled" {
        ...
        enable_key_rotation     = true
      }
  - name: 3_06_aws_unused_secrets
    description: 3.6 - AWS secrets that have not been accessed for 90 days must be removed from secret manager
    sgs_wiki_link: https://wiki.wdf.sap.corp/wiki/x/-0JAc
    query: AwsSecretsManagerSecret with LastAccessedDate < 90 days ago
    score: 8.0
    allow_orca_score_adjustment: false
    enabled: true
    category: Best practices
    minerva_control_id: null
  - name: 3_06_aws_iam_full_kms_permissions
    description: 3.6 - It must be ensured that in AWS only dedicated users/groups/roles have full kms:* permissions
    sgs_wiki_link: https://wiki.wdf.sap.corp/wiki/x/-0JAc
    query: AwsIamManagedPolicy with not PolicyArn like ['arn:aws:iam::aws:','arn:aws-us-gov:iam::aws:','arn:aws-cn:iam::aws:'][*] and DefaultPolicy.PolicyStatements with (Effect = 'Allow' and Action containing ('kms:*' or 'Kms:Encrypt' or 'kms:Decrypt' or 'kms:ReEncrypt*' or 'Kms:GenerateDataKey' or 'Kms:DescribeKey' ) and Resource containing '*' and not Condition)
    score: 8.0
    allow_orca_score_adjustment: false
    enabled: true
    category: Best practices
    minerva_control_id: null
  # Chapter 4
  - name: 4_05_aws_ec2_autoscaling_group_public_ips
    description: 4.5 - AWS EC2 instances launched using auto scaling group launch configurations must not have public IP addresses assigned by default
    sgs_wiki_link: https://wiki.wdf.sap.corp/wiki/x/-0JAc
    query: AwsAsg with LaunchConfigurationName and Ec2Instances with PublicIps
    score: 8.0
    allow_orca_score_adjustment: false
    enabled: true
    category: Best practices
    minerva_control_id: null
  - name: 4_07_aws_ec2_imdsv2
    description: 4.7 - AWS EC2 instances must have IMDSv2 enabled
    sgs_wiki_link: https://wiki.wdf.sap.corp/wiki/x/-0JAc
    query: AwsEc2Instance with MetadataOptions.HttpTokens='optional'
    score: 1.0
    allow_orca_score_adjustment: false
    enabled: true
    category: Best practices
    minerva_control_id: null
  # Chapter 5
  - name: 5_01_aws_rds_snapshot_public_accessibility
    description: 5.1 - AWS RDS snapshots must not be publicly accessible
    sgs_wiki_link: https://wiki.wdf.sap.corp/wiki/x/-0JAc
    query: AwsRdsDbInstanceSnapshot with IsPublic = true
    score: 8.0
    allow_orca_score_adjustment: false
    enabled: true
    category: Best practices
    minerva_control_id: 5_01_rds_snapshot_private
    remediation_steps:  |
      1. Log into to the AWS Management Console
      2. Search for RDS in the search bar.
      3. Click on Databases > Click on the name of DB identifier mentioned in the alert.
      4. Under the Connectivity & security tab, check the value for Publicly accessible under Security section (i.e. Yes).
      5. Click Modify.
      6. Go to Connectivity section > Click Additional configuration.
      7. Select Not publicly accessible > Click continue.
      8. Click Modify DB instance. Note: During modification process the database can go from Available to Modifying state for a short period of time so make sure you do this operation carefully and plan for any outages by consulting the responsible teams.
    terraform_remediation:  |
      resource "aws_db_snapshot" "example_rds_snapshot" {
        remove => snapshot_type = public
        or
        change => snapshot_type = shared with account_ids
      }
  - name: 5_01_aws_ebs_snapshot_public_accessibility
    description: 5.1 - AWS EBS snapshots must not be publicly accessible
    sgs_wiki_link: https://wiki.wdf.sap.corp/wiki/x/-0JAc
    query: AwsEc2EbsSnapshot with IsPublic
    score: 8.0
    allow_orca_score_adjustment: false
    enabled: true
    category: Best practices
    minerva_control_id: 5_01_ebs_snapshots
    remediation_steps:  |
      1. Sign in to the AWS Management Console.
      2. Navigate to EC2 dashboard (or search for EC2 in the search bar).
      3. Under Elastic Block Store, click Snapshots.   
      4. Click on the EBS snapshot ID that you'd like to change.   
      5. Click on Modify Permissions tab > Click the Edit button.   
      6. Inside Modify Permissions dialog box, click Private > Click Save.
    terraform_remediation:  |
      There is currently no Terraform remediation defined, please reach out to us on slack if you believe Terraform could be used for remediation in this instance.
  - name: 5_01_aws_ami_image_public_accessibility
    description: 5.1 - AWS Amazon Machine Image (AMI) must not be publicly accessible
    sgs_wiki_link: https://wiki.wdf.sap.corp/wiki/x/-0JAc
    query: AwsEc2Image with Public and VmImage.ImageOwnerId = CloudAccount.VendorId and not tags [ 'sec-by-def-public-image-exception' ] = 'enabled'
    score: 8.0
    allow_orca_score_adjustment: false
    enabled: true
    category: Best practices
    minerva_control_id: 5_01_ami_images_not_publicly_accessible
    remediation_steps:  |
      1. Sign in to the AWS Management Console.
      2. Navigate to EC2 dashboard (or search for EC2 in the search bar).   
      3. Under IMAGES section, click AMIs.   
      4. Click on the AMI ID that you want to change.   
      5. Click on the Permissions tab > Click the Edit AMI permissions button.   
      6. In the Modify Image Permissions dialog box, click Private > Click Save.
    terraform_remediation:  |
      resource "aws_ami_launch_permission" "example_ami_launch" {
        image_id = "ami-12345678"
        # Replace "group" or "account" with specific AWS account IDs to limit access.
      }
  - name: 5_01_aws_mq_public_accessibility
    description: 5.1 - AWS MQ must not be publicly accessible
    sgs_wiki_link: https://wiki.wdf.sap.corp/wiki/x/-0JAc
    query: AwsMqBroker with PubliclyAccessible
    score: 8.0
    allow_orca_score_adjustment: false
    enabled: true
    category: Best practices
    minerva_control_id: 6_02_mq_public
    remediation_steps:  |
      1. Login to AWS Management console.
      2. Select Services > Application Integration > Amazon MQ OR Search for Amazon MQ in the search bar.
      3. Navigate to broker mentioned in the alert.
      4. In Detail section > Security and network > Check Public accessibility (i.e. Yes). Note: Once the broker is created public accessibility config setting can’t be modified hence you need to create new broker with Public accessibility set to No.
      5. Click Create brokers > Select broker engine (make sure you select the correct setting by checking existing broker engine type) > Click Next.
      6. Select Deployment mode and storage type (make sure to select the correct setting by checking existing broker config) > Click Next.
      7. Fill all the required fields in Configure settings screen > In Additional settings choose Private access > Click Next > Click Create broker.
          Reference AWS Guide: https://docs.aws.amazon.com/amazon-mq/latest/developer-guide/amazon-mq-creating-configuring-broker.html
          Note: Delete publicly accessible broker (ensure that team responsible for managing this broker is aware before carrying out the delete activity) only when the new broker is successfully created.
    terraform_remediation:  |
      resource "aws_mq_broker" "example_mq_broker" {
        publicly_accessible = false
        ...
      }
  - name: 5_01_aws_glacier_lock_policy_principal_permission_overly_permissive
    description: 5.1 - AWS Glacier lock policy principal permission must not be overly permissive
    sgs_wiki_link: https://wiki.wdf.sap.corp/wiki/x/-0JAc
    query: AwsS3GlacierVault with AccessPolicy.PolicyStatements with Principal . AWS containing '*' and Effect = 'Allow'
    score: 8.0
    allow_orca_score_adjustment: false
    enabled: true
    category: Best practices
    minerva_control_id: null
  - name: 5_01_aws_s3_bucket_get_permissions
    description: 5.1 - AWS S3 Bucket Global GET Permissions must be disabled via bucket policy
    sgs_wiki_link: https://wiki.wdf.sap.corp/wiki/x/-0JAc
    query: AwsS3Bucket with ( not PublicAccessBlock or PublicAccessBlock [ 'RestrictPublicBuckets' ] = 'false' ) and BucketPolicy.PolicyStatements with Effect = 'Allow' and Action containing ('s3:GetObject' or 's3:*') and Principal.AWS containing '*' or Principal containing '*' and not RestrictedAccessCondition and not tags [ 'sec-by-def-public-storage-exception' ] = 'enabled'
    score: 8.0
    allow_orca_score_adjustment: false
    enabled: true
    category: Best practices
    minerva_control_id: 5_01_get
    remediation_steps:  |
      1. Log into to the AWS Management Console > Search for S3 in the search bar.
      2. Navigate to the bucket mentioned in the alert.
      3. Navigate to the permissions > Check bucket policy i.e. You can’t have effect set to Allow with Principal set to * or ‘AWS’ => ‘’ and action set to s3:GetObject or s3: or * > reference [5.1 Ensure storage services are not publicly accessible] SGS hardening guidelines for more information.
          Please note: To prevent public access on AWS S3, the bucket setting “Block all public access” SHOULD be enabled. If this is not feasible because of a special use case, accessibility can be configured on a bucket level. Object level policies MUST NOT be used. When using bucket level policies, an asterisk (“”) MUST not be used in the principal field of any policy that grants permissions. All GET permissions MUST NOT be allowed to all users on the public internet.*
      4. Click on Edit Bucket policy to make necessary changes.
      5. Save changes.
    terraform_remediation:  |
      resource "aws_s3_bucket_policy" "example_policy" {
        bucket = <your bucket>

        policy = <<POLICY
        {
          "Version": "2012-10-17",
          "Statement": [
          {
          "Effect": "Allow",
          "Principal": <limited list of users>,
          "Action": ["s3:*", "s3:GetObject"],
          "Resource": "<your bucket arn>/*",
          "Condition": {
              "IpAddress": {
                  "aws:SourceIp" : <limited IP source list>
              }
          }
        }
          ]
        }
      POLICY
      }
  - name: 5_01_aws_s3_bucket_list_permissions
    description: 5.1 - AWS S3 Bucket Global LIST Permissions should be disabled via bucket policy
    sgs_wiki_link: https://wiki.wdf.sap.corp/wiki/x/-0JAc
    query: AwsS3Bucket with ( not PublicAccessBlock or PublicAccessBlock [ 'RestrictPublicBuckets' ] = 'false' ) and BucketPolicy.PolicyStatements with Effect = 'Allow' and Action containing ('s3:ListBucket' or 's3:*') and Principal.AWS containing '*' or Principal containing '*' and not RestrictedAccessCondition and not tags [ 'sec-by-def-public-storage-exception' ] = 'enabled'
    score: 5.0
    allow_orca_score_adjustment: false
    enabled: true
    category: Best practices
    minerva_control_id: 5_01_list
    remediation_steps:  |
      1. Log into to the AWS Management Console > Search for S3 in the search bar.
      2. Navigate to the bucket mentioned in the alert.
      3. Navigate to the permissions > Check bucket policy i.e. You can’t have effect set to Allow with Principal set to * or ‘AWS’ => ‘’ and action set to s3:ListBucket or s3: or * -> reference [5.1 Ensure storage services are not publicly accessible] SGS hardening guidelines for more information. Please note: To prevent public access on AWS S3, the bucket setting “Block all public access” SHOULD be enabled. If this is not feasible because of a special use case, accessibility can be configured on a bucket level. Object level policies MUST NOT be used. When using bucket level policies, an asterisk (“”) MUST not be used in the principal field of any policy that grants permissions. All GET permissions MUST NOT be allowed to all users on the public internet. All LIST permissions SHOULD NOT be allowed to all users on the public internet.*
      4. Click on Edit Bucket policy to make necessary changes.
      5. Save changes.
    terraform_remediation:  |
      resource "aws_s3_bucket_policy" "example_policy" {
          bucket = <your bucket>

          policy = <<POLICY
        {
          "Version": "2012-10-17",
          "Statement": [
        {
          "Effect": "Allow",
          "Principal": <limited list of users>,
          "Action": [<list of s3List actions>],
          "Resource": "<your bucket arn>/*",
          "Condition": {
              "IpAddress": {
                  "aws:SourceIp" : <limited IP source list>
              }
          }
        }
          ]
        }
      POLICY
      }
  - name: 5_01_aws_s3_bucket_delete_permissions
    description: 5.1 - AWS S3 Bucket Global DELETE Permissions must be disabled via bucket policy
    sgs_wiki_link: https://wiki.wdf.sap.corp/wiki/x/-0JAc
    query: AwsS3Bucket with ( not PublicAccessBlock or PublicAccessBlock [ 'RestrictPublicBuckets' ] = 'false' ) and BucketPolicy.PolicyStatements with Effect = 'Allow' and Action containing ('s3:DeleteObject' or 's3:DeleteObjectVersion' or 's3:*') and Principal.AWS containing '*' or Principal containing '*' and not RestrictedAccessCondition and not tags [ 'sec-by-def-public-storage-exception' ] = 'enabled'
    score: 8.0
    allow_orca_score_adjustment: false
    enabled: true
    category: Best practices
    minerva_control_id: 5_01_s3_global_delete
    remediation_steps:  |
      1. Log into to the AWS Management Console > Search for S3 in the search bar.
      2. Navigate to the bucket mentioned in the alert.
      3. Navigate to the permissions > Check bucket policy i.e. You can’t have effect set to Allow with Principal set to * or ‘AWS’ => ‘’ and action set to s3:DeleteObject or s3: or * -> reference [5.1 Ensure storage services are not publicly accessible] SGS hardening guidelines for more information
          Please note: To prevent public access on AWS S3, the bucket setting “Block all public access” SHOULD be enabled. If this is not feasible because of a special use case, accessibility can be configured on a bucket level. Object level policies MUST NOT be used. When using bucket level policies, an asterisk (“”) MUST not be used in the principal field of any policy that grants permissions. All DELETE permissions MUST NOT be allowed to all users on the public internet.*
      4. Click on Edit Bucket policy to make necessary changes.
      5. Save changes.
    terraform_remediation:  |
      resource "aws_s3_bucket_policy" "example_policy" {
          bucket = <your bucket>

          policy = <<POLICY
        {
            "Version": "2012-10-17",
            "Statement": [
              {
                "Effect": "Allow",
                "Principal": <limited list of users>,
                "Action": [<list of s3Delete actions>],
                "Resource": "<your bucket arn>/*",
                "Condition": {
                "IpAddress": {
                  "aws:SourceIp" : <limited IP source list>
                }   
              }
          }
        ]
        }
      POLICY
      }
  - name: 5_01_aws_s3_bucket_put_permissions
    description: 5.1 - AWS S3 Bucket Global PUT Permissions should be disabled via bucket policy
    sgs_wiki_link: https://wiki.wdf.sap.corp/wiki/x/-0JAc
    query: AwsS3Bucket with ( not PublicAccessBlock or PublicAccessBlock [ 'RestrictPublicBuckets' ] = 'false' ) and BucketPolicy.PolicyStatements with Effect = 'Allow' and Action containing ('s3:PutObject' or 's3:PutObjectAcl' or 's3:*') and Principal.AWS containing '*' or Principal containing '*' and not RestrictedAccessCondition and not tags [ 'sec-by-def-public-storage-exception' ] = 'enabled'
    score: 5.0
    allow_orca_score_adjustment: false
    enabled: true
    category: Best practices
    minerva_control_id: 5_01_put
    remediation_steps:  |
      1. Log in to the AWS console.
      2. Navigate to the S3 service.
      3. Select the S3 bucket.
      4. Click on the Permissions tab.
      5. Click on Bucket Policy.
      6. Remove any statements that allow global PUT permissions ('s3:PutObject' or 's3:PutObjectAcl' or 's3:*').
      7. Add a statement that denies global PUT permissions.
      8. Save the changes to the bucket policy.
    terraform_remediation:  |
      resource "aws_s3_bucket_policy" "example_policy" {
          bucket = <your bucket>

          policy = <<POLICY
        {
          "Version": "2012-10-17",
          "Statement": [
            {
              "Effect": "Allow",
              "Principal": <limited list of users>,
              "Action": [<list of s3Put actions>],
              "Resource": "<your bucket arn>/*",
              "Condition": {
              "IpAddress": {
                  "aws:SourceIp" : <limited IP source list>
              }
            }
          }
          ]
        }
      POLICY
      }
  - name: 5_01_aws_efs_public_access
    description: 5.1 - Public Access to AWS EFS must be blocked
    sgs_wiki_link: https://wiki.wdf.sap.corp/wiki/x/-0JAc
    query: AwsEfsFileSystem with AccessPolicy.PolicyStatements with Effect = 'Allow' and Principal.AWS containing '*' and not (RestrictedAccessCondition or Condition['Bool']['elasticfilesystem:AccessedViaMountTarget'] containing 'true')
    score: 1.0
    allow_orca_score_adjustment: false
    enabled: true
    category: Best practices
    minerva_control_id: null
  - name: 5_02_aws_s3_bucket_encryption
    description: 5.2 - AWS S3 Buckets must have server side encryption enabled
    sgs_wiki_link: https://wiki.wdf.sap.corp/wiki/x/-0JAc
    query: AwsS3bucket with Encryption [ 'encryption_missing' ] = true and not tags [ 'sec-by-def-encrypt-storage-exception' ] = 'enabled'
    score: 8.0
    allow_orca_score_adjustment: false
    enabled: true
    category: Best practices
    minerva_control_id: 5_02_s3_bucket_encryption_enabled
    remediation_steps:  |
      1. Log into to the AWS Management Console.
      2. Search for S3 in the search bar.
      3. Select the S3 bucket in the alert.
      4. Click on the ‘Properties’ tab.
      5. Under the ‘Default encryption’ section, click ‘Edit’, under ‘Server-side encryption’, choose ‘Enable’, choose encryption option either ‘Amazon S3-managed keys (SSE-S3)’ or ‘AWS Key Management Service key (SSE-KMS)’ based on your requirement.
    terraform_remediation:  |
      resource "aws_kms_key" "mykey" {
        description            = "This key is used to encrypt bucket objects"
        key_usage              =  ENCRYPT_DECRYPT
      }
      resource "aws_s3_bucket_server_side_encryption_configuration" "example" {
        bucket = aws_s3_bucket.mybucket.id
        rule {
          apply_server_side_encryption_by_default {
          kms_master_key_id = aws_kms_key.mykey.arn
          sse_algorithm     = "aws:kms"
          }
        }
      }
  - name: 5_02_aws_ebs_encryption
    description: 5.2 - AWS EBS volumes must be encrypted
    sgs_wiki_link: https://wiki.wdf.sap.corp/wiki/x/-0JAc
    query: AwsEc2EbsVolume with StorageEncrypted = false and not tags [ 'sec-by-def-ebs-encryption-exception' ] = 'enabled'
    score: 8.0
    allow_orca_score_adjustment: false
    enabled: true
    category: Best practices
    minerva_control_id: 5_02_ebs_and_efs_encryption_enabled
    remediation_steps:  |
        1. Sign in to the AWS Management Console.
        2. Navigate to EC2 dashboard (or search for EC2 in the search bar).
        3. Under Elastic Block Store, click Volumes.
        4. Click on the checkbox of the Volume ID that you’d like to change > Click the Actions dropdown button > Click Create Snapshot.
        5. In the Create Snapshot dialog box, enter a name and a description for the snapshot (optional) > Click Create.
        6. Under Elastic Block Store, click Snapshots > Click on the checkbox of the Volume ID of your new created EBS snapshot.
        7. Click the Actions dropdown button > Click Copy.
        8. In the Copy Snapshot dialog box, click Encrypt this snapshot checkbox > Click Copy.
        9. Click on the checkbox of the Volume ID of your new (copied) created EBS snapshot > Click the Actions dropdown button > Click Create Volume.
        10. In the Create Volume dialog box, make sure the volume Encryption status set as Encrypted > Click Create.
        11. Click Volumes (on the left hand side) > Click on the checkbox of the Volume that isn’t encrypted > Click the Actions dropdown button > Click Detach Volume.
        12. In the Detach Volume dialog box, click Yes, Detach.
        13. In the Attach Volume dialog box, enter your EC2 instance ID and the device name for attachment > Click Attach. 
    terraform_remediation:  |
      resource "aws_ebs_volume" "example_ebs_volume" {
        ...
        encrypted         = true
      }
      resource "aws_efs_file_system" "example_efs" {
        encrypted = true
      }
  - name: 5_02_aws_efs_encryption
    description: 5.2 - AWS EFS must be encrypted
    sgs_wiki_link: https://wiki.wdf.sap.corp/wiki/x/-0JAc
    query: AwsEfsFileSystem with StorageEncrypted = false and not tags [ 'sec-by-def-ebs-encryption-exception' ] = 'enabled'
    score: 8.0
    allow_orca_score_adjustment: false
    enabled: true
    category: Best practices
    minerva_control_id: 5_02_ebs_and_efs_encryption_enabled
    remediation_steps:  |
        1. Login to the AWS Management Console.
        2. Navigate to Elastic File System (EFS) dashboard (or search for EFS in the search bar).
        3. In the left navigation panel, Click File Systems > Click Create File System button.
        4. On the Configure file system access configuration page, please do the following steps:
        5. Choose the correct VPC from the VPC dropdown list. Please note that only the EC2 instances equipped within the selected VPC can access the new file system.
        6. Under the Create mount targets section, Click the checkboxes for all of the Availability Zones within the selected VPC.
        7. Click Next step. On the Configure optional settings page, please do the following steps:
          7.1 Under the Add tags section, create tags for description purposes for your new file system.
          7.2 Click General Purpose (default) or Max I/O from Choose performance mode section.
          7.3 Check Enable encryption checkbox and choose aws/elasticfilesystem from Select KMS master key dropdown list.
          7.4 Click Next Step.
        8. On the Review and create age, be sure to look over and confirm that the file system configuration details are correct > Click Create File System.
        9. Copy the data from the original EFS file system onto the new one.
        10. Once the data migration process is done and you’ve confirmed that all the data is loaded into your new encrypted file system, you can now delete the original unencrypted file system by performing the following steps:
          10.1 Connect to your AWS EC2 instance > unmount the original unencrypted EFS file system.
          10.2 Click on checkbox of the EFS file system that you want to delete.
          10.3 Click the Action dropdown button > Click on Delete file system.
          10.4 Inside the Permanently delete file system dialog box, enter the file system ID for the EFS file system that you want to delete > Click on Delete File System.
    terraform_remediation:  |
      resource "aws_ebs_volume" "example_ebs_volume" {
        ...
        encrypted         = true
      }
      resource "aws_efs_file_system" "example_efs" {
        encrypted = true
      }
  - name: 5_02_aws_emr_cluster_encryption_in_transit
    description: 5.2 - AWS EMR clusters should have encryption in-transit enabled
    sgs_wiki_link: https://wiki.wdf.sap.corp/wiki/x/-0JAc
    query: AwsEmrCluster without SecurityConfiguration.EnableInTransitEncryption
    score: 5.0
    allow_orca_score_adjustment: false
    enabled: true
    category: Best practices
    minerva_control_id: 5_02_emr_cluster_encryption_in_transit
    remediation_steps:  |
      1. Login to the AWS Management Console.
      2. Navigate to EMR dashboard (or search for EMR in the search bar).
      3. In the navigation panel, click Security configurations > Click Create.
      4. On the Create security configuration page, please do the following steps:
        4.1 In Name box, enter a unique name for the new EMR security configuration.
        4.2 Select In-transit encryption checkbox to enable the open-source TLS encryption features for EMR in-transit data. To configure in-transit encryption, perform the following:
        4.3 Under TLS certificate provider, in Certificate provider type dropdown list, choose PEM. Two items should be available in your zip file: a PrivateKey.pem file and a CertificateChain.pem file (refer to Providing Certificates for In-Transit Data Encryption with Amazon EMR Encryption page for more details). In the S3 object box, enter the location of the zip file that contains your certificate PEM files. If you choose Custom from the Certificate provider type dropdown list > specify a custom certificate provider and specify the AWS S3 location of the custom certificate-provider file. In Certificate provider class box > type the full name of a class declared in your EMR application that implements the TLSArtifactsProvider interface.
        4.5 Click Create.
      5. In the navigation panel, under Amazon EMR > Click Clusters to access your AWS EMR clusters.
      6. Select the EMR cluster that you want to reconfigure > click on the Clone button from the dashboard top menu.
      7. Inside the Cloning dialog box > Choose Yes to include the steps from the original cluster into the cloned (new) cluster > Click Clone.
      8. On the Create Cluster page, in the Security Options section > Click Authentication and encryption.
      9. Select the name of the security configuration created at step #4 from the Security configuration dropdown list > Click Create Cluster to provision your new Amazon EMR cluster.
      10. Once you have moved the existing data and verified that your new EMR cluster is working with the new security configuration > Terminate the original cluster to stop incurring charges for it. To terminate the unencrypted, original AWS EMR cluster, please do the following steps:
        10.1 Go back to the navigation panel and under Amazon EMR > Choose Cluster list.
        10.2 Select the AWS EMR cluster that you want to shut down > Click on the Terminate button from the dashboard top menu.
        10.3 In the Terminate clusters confirmation box, review the original cluster details > Click Terminate.
    terraform_remediation:  |
      resource "aws_emr_cluster" "example_cluster" {
        ...
        security_configuration = aws_emr_security_configuration.emr_security_configuration
        ...
      }
      resource "aws_kms_key" "emr_kms_key" {
        description             = <key description>
        deletion_window_in_days = <key deletion window>
      }
      resource "aws_emr_security_configuration" "emr_security_configuration" {
        ...
        configuration = <<CONFIG
        {
        "EncryptionConfiguration": {
        "EnableInTransitEncryption": false
        }
      }
      CONFIG
      }
  - name: 5_02_aws_emr_cluster_local_disk_encryption
    description: 5.2 - AWS EMR cluster should be enabled with local disk encryption
    sgs_wiki_link: https://wiki.wdf.sap.corp/wiki/x/-0JAc
    query: AwsEmrCluster without SecurityConfiguration.AtRestEncryptionConfiguration containing 'LocalDiskEncryptionConfiguration'
    score: 5.0
    allow_orca_score_adjustment: false
    enabled: true
    category: Best practices
    minerva_control_id: 5_02_emr_cluster_local_disk_encryption
    remediation_steps:  |
      1. Login to the AWS Console.
      2. Navigate to EMR dashboard (or search for EMR in the search bar).
      3. Click on Security configurations > Click Create.
      4. On the Create security configuration window, please do the following:
        4.1 In Name box, enter a name for the new EMR security configuration.
        4.2 Under Local disk encryption, check the box Enable at-rest encryption for local disks.
        4.3 Select the appropriate key provider type from the key provider type dropdown.
        4.4 Click Create.
      5. On the left menu of EMR dashboard, click Clusters.
      6. Click on the EMR cluster mentioned in the alert > Click on the Clone button.
      7. In the Cloning popup, choose Yes > Click Clone.
      8. On the Create Cluster page, under the Security Options section, click on security configuration.
      9. From the Security configuration drop down, select the name of the security configuration created at step #4 > Click Create Cluster.
      10. Once the new cluster is set up > Confirm that it is working > terminate the original cluster.
      11. On the left menu of EMR dashboard, click clusters > Select the source cluster which was mentioned in the alert.
      12. Click on the Terminate button from the top menu > On the Terminate clusters pop-up, click Terminate.
    terraform_remediation:  |
      resource "aws_emr_cluster" "example_cluster" {
        ...
        security_configuration = aws_emr_security_configuration.emr_security_configuration
        ...
      }
      resource "aws_kms_key" "emr_kms_key" {
        description             = <key description>
        deletion_window_in_days = <key deletion window>
      }
      resource "aws_emr_security_configuration" "emr_security_configuration" {
        ...
        configuration = <<CONFIG
        {
          "EncryptionConfiguration": {
          "LocalDiskEncryptionConfiguration": {
          "EncryptionKeyProviderType": "AwsKms",
          "AwsKmsKey": "${aws_kms_key.emr_kms_key.arn}",
          "EnableEbsEncryption": true
          }
        }
        }
      }
      CONFIG
      }
  - name: 5_02_aws_emr_cluster_encryption_at_rest
    description: 5.2 - AWS EMR cluster should be enabled with data encryption at rest
    sgs_wiki_link: https://wiki.wdf.sap.corp/wiki/x/-0JAc
    query: AwsEmrCluster without SecurityConfiguration.EnableAtRestEncryption
    score: 5.0
    allow_orca_score_adjustment: false
    enabled: true
    category: Best practices
    minerva_control_id: 5_02_emr_cluster_encryption_at_rest
    remediation_steps:  |
      1. Login to the AWS Management Console.
      2. Navigate to EMR dashboard (or search for EMR in the search bar).
      3. In the navigation panel, click Security configurations > Click Create.
      4. On the Create security configuration page, please do the following steps:
        4.1 In Name box, enter a unique name for the new EMR security configuration.
        4.2 Select At-rest encryption checkbox to enable at-rest encryption for data stored within the cluster file system. To configure data-at-rest encryption, perform the following: * Under S3 encryption, pick a value from Encryption mode dropdown list. To select the right encryption mode to encrypt your EMR data, refer to the official AWS documentation page. * Under Local disk encryption, from Key provider type dropdown list > Choose the default AWS KMS key or custom key provider.
        4.3 Click Create.
      5. In the navigation panel, under Amazon EMR, click Clusters to access your AWS EMR clusters.
      6. Select the EMR cluster that you want to reconfigure > Click on the Clone button from the dashboard top menu.
      7. Inside the Cloning dialog box > Choose Yes to include the steps from the original cluster into the cloned (new) cluster > Click Clone.
      8. On the Create Cluster page, in the Security Options section > Click Authentication and encryption.
      9. Select the name of the security configuration created at step #4 from the Security configuration dropdown list > Click Create Cluster to provision your new Amazon EMR cluster.
      10. Once you have moved the existing data and verified that your new EMR cluster is working with the new security configuration > Terminate the original cluster to stop incurring charges for it. To terminate the unencrypted, original AWS EMR cluster, please do the following steps:
        10.1 Go back to the navigation panel and under Amazon EMR > Choose Cluster list.
        10.2 Select the AWS EMR cluster that you want to shut down > Click on the Terminate button from the dashboard top menu.
        10.3 In the Terminate clusters confirmation box, review the original cluster details > Click Terminate.
    terraform_remediation:  |
      resource "aws_emr_cluster" "example_cluster" {
        ...
        security_configuration = aws_emr_security_configuration.emr_security_configuration
        ...
      }
      resource "aws_kms_key" "emr_kms_key" {
        description             = <key description>
        deletion_window_in_days = <key deletion window>
      }
      resource "aws_emr_security_configuration" "emr_security_configuration" {
        ...
        configuration = <<CONFIG
        {
          "EncryptionConfiguration": {
          "EnableAtRestEncryption": true
          }
        }
      CONFIG
      }
  - name: 5_02_aws_ssm_encryption_at_rest
    description: 5.2 - AWS Systems Manager (SSM) should have encryption at rest enabled
    sgs_wiki_link: https://wiki.wdf.sap.corp/wiki/x/-0JAc
    query: AwsSystemsManagerParameter with ParameterType = "SecureString" and not KmsKey
    score: 5.0
    allow_orca_score_adjustment: false
    enabled: true
    category: Best practices
    minerva_control_id: null
  - name: 5_03_aws_sns_subscription_https
    description: 5.3 - AWS SNS subscriptions should use HTTPS Delivery Protocol
    sgs_wiki_link: https://wiki.wdf.sap.corp/wiki/x/-0JAc
    query: AwsSnsSubscription with Protocol = 'http'
    score: 5.0
    allow_orca_score_adjustment: false
    enabled: true
    category: Best practices
    minerva_control_id: 5_03_sns_subscription_using_secure_protocol
    remediation_steps:  |
      1. Sign in to the AWS Management Console.
      2. Navigate to SNS dashboard (or search for SNS in the search bar).
      3. In the navigation panel, under SNS Dashboard, click Subscriptions.
      4. Click on the subscription ID that you want to change > Copy the Topic ARN value and the subscription Endpoint.
      5. Click Subscriptions > Click Create subscription button.
      6. Within Create subscription dialog box, please do the following steps:
        6.1 Inside the Topic ARN box, paste the SNS topic ARN that you copied at step #4.
        6.2 Select HTTPS from the Protocol dropdown list.
        6.3 Paste the URL endpoint that you copied at step #4 in the Endpoint box.
        6.4 Click Create Subscription to generate the new SNS subscription.
        6.5 Click Close.
      7. Once your new SNS subscription is confirmed, you can remove the original subscription by performing the following steps:
        7.1 Click the circle by the subscription ID that you want to delete.
        7.2 Click Delete.
        7.3 Inside the Delete dialog box, review the details > Click Delete.
    terraform_remediation:  |
      resource "aws_sns_topic_subscription" "example_subscription" {
        ...
        protocol = <protocol here>
        ...
      }
  - name: 5_03_aws_s3_bucket_secure_transport
    description: 5.3 - AWS S3 buckets must always use encrypted communication i.e. secure transfer must be enabled
    sgs_wiki_link: https://wiki.wdf.sap.corp/wiki/x/-0JAc
    query: AwsS3Bucket without BucketPolicy.PolicyStatements with Effect = 'Deny' and Condition['Bool']['aws:SecureTransport'] containing 'false'
    score: 8.0
    allow_orca_score_adjustment: false
    enabled: true
    category: Best practices
    minerva_control_id: 5_03_s3_secure_transport_enabled
    remediation_steps:  |
      1. Log in to the AWS Management Console.
      2. Search for S3 in the search bar.
      3. Select the S3 bucket mentioned in the alert.
      4. Click on the ‘Permissions’ tab.
      5. Under ‘Bucket Policy’ click edit to deny all access from anybody to Amazon S3 objects within an Amazon S3 bucket if they are not accessed through HTTPS. Below is the sample policy:
          {
            "Version": "2012-10-17",
            "Statement": [
              {
                "Effect": "Deny",
                "Principal": "*",
                "Action": "s3:*",
                "Resource": "<bucket arn>/*",
                "Condition": {
                  "Bool": {
                    "aws:SecureTransport": "false"
                  }
                }
              } 
            ]
          }
    terraform_remediation:  |
      resource "aws_s3_bucket_policy" "example_s3_bucket" {
        ...

        policy = <<POLICY
        {
          "Version": "2012-10-17",
          "Statement": [
            {
              "Effect": "Deny",
              "Principal": "*",
              "Action": "s3:*",
              "Resource": "<bucket arn>/*",
              "Condition": {
              "Bool": {
                  "aws:SecureTransport": "false"
              }
            }
          }
          ]
        }
      POLICY
      }
  - name: 5_04_aws_s3_bucket_object_versioning
    description: 5.4 - AWS S3 buckets object versioning should be enabled
    sgs_wiki_link: https://wiki.wdf.sap.corp/wiki/x/-0JAc
    query: AwsS3Bucket without BucketVersioningStatus = "Enabled"
    score: 1.0
    allow_orca_score_adjustment: false
    enabled: true
    category: Best practices
    minerva_control_id: null
  # Chapter 6
  - name: 6_01_01_aws_db_ports
    description: 6.1.1 - AWS Security Groups must not allow inbound traffic from the Internet to blocklisted Database (DB) ports
    sgs_wiki_link: https://wiki.wdf.sap.corp/wiki/x/-0JAc
    query: AwsEc2SecurityGroup with SecurityGroupRules with (CidrIpv4 = "0.0.0.0/0" or CidrIpv6 = "::/0") and not Egress and PortRange containing ( 5432 or 3306 or 4333 or 1521 or 27017 ) and not Tags ["sec-by-def-network-exception"] like ['PostgreSQL','MySQL','MSSQL','OracleSQL','MongoDB'][*]
    score: 8.0
    allow_orca_score_adjustment: false
    enabled: true
    category: Best practices
    minerva_control_id: 6_01_01_db_ports
    remediation_steps:  |
      1. Log into to the AWS Management Console > Go to Network & Security and select Security Groups (or search for Security Group in the search bar).
      2. Navigate to the security group for which the alert is raised.
      3. Navigate to the inbound rules > Click on Edit Inbound rules > Ensure CIDR block 0.0.0.0/0 or ::/0 is not bound to any of the following ports: 5432, 3306, 4333, 1521, 27017, OR any ports mentioned in [6.1.1 Firewall Rules for DB ports] SGS hardening guidelines > Save rules.
    terraform_remediation:  |
      resource "aws_security_group" "example_security_group" {
        ...
        vpc_id      = <vpc id of vpc to apply the security group to>
      }
      resource "aws_security_group_rule" "example_security_group_rule" {
        type      = "ingress"
        from_port = <relevant port>
        to_port   = <relevant port>
        protocol  = <specific protocol>
        cidr_blocks = <Specific IPv4 address range, not "0.0.0.0/0" or>
        ipv6_cidr_blocks = <Specific IPv6 address range (cannot be set at the same time as cidr_blocks), not "::/0">
        security_group_id = aws_security_group.example_security_group.id
      }
  - name: 6_01_02_aws_admin_ports
    description: 6.1.2 - AWS Security Groups must not allow inbound traffic from the Internet to blocklisted Administrative ports
    sgs_wiki_link: https://wiki.wdf.sap.corp/wiki/x/-0JAc
    query: AwsEc2SecurityGroup with SecurityGroupRules with (CidrIpv4 = "0.0.0.0/0" or CidrIpv6 = "::/0") and not Egress and PortRange containing ( 22 or 3389 or 135 or 5500 or 5900 ) and not Tags ["sec-by-def-network-exception"] like ['SSH','RDP','VNC','RPC'][*]
    score: 8.0
    allow_orca_score_adjustment: false
    enabled: true
    category: Best practices
    minerva_control_id: 6_01_02_admin_ports
    remediation_steps:  |
      1. Log into to the AWS Management Console > Go to Network & Security and select Security Groups (or search for Security Group in the search bar).
      2. Navigate to the security group for which the alert is raised.
      3. Navigate to the inbound rules > Click on Edit Inbound rules > Ensure CIDR block 0.0.0.0/0 or ::/0 is not bound to any of the following ports: 3389, 22, 5500, 5900, OR any ports mentioned in [6.1.2 Firewall Rules for ADMIN ports] SGS hardening guidelines > Save rules.
    terraform_remediation:  |
      resource "aws_security_group" "example_security_group" {
        ...
        vpc_id      = <vpc id of vpc to apply the security group to>
      }
      resource "aws_security_group_rule" "example_security_group_rule" {
        type      = "ingress"
        from_port = <relevant port>
        to_port   = <relevant port>
        protocol  = <specific protocol>
        cidr_blocks = <Specific IPv4 address range, not "0.0.0.0/0" or>
        ipv6_cidr_blocks = <Specific IPv6 address range (cannot be set at the same time as cidr_blocks), not "::/0">
        security_group_id = aws_security_group.example_security_group.id
      }
  - name: 6_01_03_aws_infra_ports
    description: 6.1.3 - AWS Security Groups should not allow inbound traffic from the Internet to blocklisted Infrastructure ports
    sgs_wiki_link: https://wiki.wdf.sap.corp/wiki/x/-0JAc
    query: AwsEc2SecurityGroup with SecurityGroupRules with (CidrIpv4 = "0.0.0.0/0" or CidrIpv6 = "::/0") and not Egress and PortRange containing ( 25 or 53 or 67 or 68 or 110 or 161 or 162 ) and not Tags ["sec-by-def-network-exception"] like ['DNS','POP3','SMTP','DHCP','SNMP'][*]
    score: 5.0
    allow_orca_score_adjustment: false
    enabled: true
    category: Best practices
    minerva_control_id: 6_01_03_infra_ports
    remediation_steps:  |
      1. Log into to the AWS Management Console > Go to Network & Security and select Security Groups (or search for Security Group in the search bar).
      2. Navigate to the security group for which the alert is raised.
      3. Navigate to the inbound rules > Click on Edit Inbound rules > Ensure CIDR block 0.0.0.0/0 or ::/0 is not bound to any of the following ports: 53, 110, 25, 67, 68, 161, 162 OR any ports mentioned in [6.1.3 Firewall Rules for Infrastructure ports] SGS hardening guidelines > Save rules.
    terraform_remediation:  |
      resource "aws_security_group" "example_security_group" {
        ...
        vpc_id      = <vpc id of vpc to apply the security group to>
      }
      resource "aws_security_group_rule" "example_security_group_rule" {
        type      = "ingress"
        from_port = <relevant port>
        to_port   = <relevant port>
        protocol  = <specific protocol>
        cidr_blocks = <Specific IPv4 address range, not "0.0.0.0/0" or>
        ipv6_cidr_blocks = <Specific IPv6 address range (cannot be set at the same time as cidr_blocks), not "::/0">
        security_group_id = aws_security_group.example_security_group.id
      }
  - name: 6_01_04_aws_fileshare_ports
    description: 6.1.4 - AWS Security Groups should not allow inbound traffic from the Internet to blocklisted File Share ports
    sgs_wiki_link: https://wiki.wdf.sap.corp/wiki/x/-0JAc
    query:  AwsEc2SecurityGroup with SecurityGroupRules with (CidrIpv4 = "0.0.0.0/0" or CidrIpv6 = "::/0") and not Egress and PortRange containing ( 139 or 445 or 21 or 69) and not Tags ["sec-by-def-network-exception"] like ['NetBIOS','SMB','FTP','TFTP'][*]
    score: 5.0
    allow_orca_score_adjustment: false
    enabled: true
    category: Best practices
    minerva_control_id: 6_01_04_fileshare_ports
  - name: 6_01_05_aws_telnet_rsh_ports_ingress
    description: 6.1.5 - AWS Security Groups must not allow inbound traffic from the Internet on Telnet or RSH ports
    sgs_wiki_link: https://wiki.wdf.sap.corp/wiki/x/-0JAc
    query: AwsEc2SecurityGroup with SecurityGroupRules with ( CidrIpv4 = "0.0.0.0/0" or CidrIpv6 = "::/0" ) and PortRange containing ( 23 or 514 ) and not Egress
    score: 8.0
    allow_orca_score_adjustment: false
    enabled: true
    category: Best practices
    minerva_control_id: 6_01_05_telnet_ports
    remediation_steps:  |
      1.  Log into to the AWS Management Console > Go to Network & Security and select Security Groups (or search for Security Group in the search bar).
      2.  Navigate to the security group for which the alert is raised.
      3.  Navigate to the inbound rules > Click on Edit Inbound rules > Ensure CIDR block 0.0.0.0/0 or ::/0 is not bound to any of the following ports:
          23 or 514 or all ports > Save rules.
    terraform_remediation:  |
        terraform destroy -target=aws_security_group.example_security_group
        terraform destroy -target=aws_security_group_rule.example_security_group_rule
  - name: 6_01_05_aws_telnet_rsh_ports_egress
    description: 6.1.5 - AWS Security Groups should not allow outbound traffic towards the Internet on Telnet or RSH ports
    sgs_wiki_link: https://wiki.wdf.sap.corp/wiki/x/-0JAc
    query: AwsEc2SecurityGroup with SecurityGroupRules with ( CidrIpv4 = "0.0.0.0/0" or CidrIpv6 = "::/0" ) and PortRange containing ( 23 or 514 ) and Egress
    score: 1.0
    allow_orca_score_adjustment: false
    enabled: true
    category: Best practices
    minerva_control_id: 6_01_05_telnet_ports
    remediation_steps:  |
      1.  Log into to the AWS Management Console > Go to Network & Security and select Security Groups (or search for Security Group in the search bar).
      2.  Navigate to the security group for which the alert is raised.
      3.  Navigate to the outbound rules > Click on Edit Outbound rules > Ensure CIDR block 0.0.0.0/0 or ::/0 is not bound to any of the following ports:
          23 or 514 or all ports > Save rules.
    terraform_remediation:  |
    
        terraform destroy -target=aws_security_group.example_security_group
        terraform destroy -target=aws_security_group_rule.example_security_group_rule
  - name: 6_02_aws_subnet_autoassign_publicIPv4
    description: 6.2 - AWS Subnets must have "auto-assign public IPv4 address" disabled
    sgs_wiki_link: https://wiki.wdf.sap.corp/wiki/x/-0JAc
    query: AwsSubnet with MapPublicIpOnLaunch != false
    score: 1.0
    allow_orca_score_adjustment: false
    enabled: true
    category: Best practices
    minerva_control_id: null
  - name: 6_03_aws_elb_access_logging
    description: 6.3 - AWS Elastic Load Balancers (Classic) access log should be enabled
    sgs_wiki_link: https://wiki.one.int.sap/wiki/x/-0JAc
    query: AwsEc2Elb with ( Listeners with Protocol = "SSL" ) and not AccessLogs
    score: 5.0
    allow_orca_score_adjustment: false
    enabled: true
    category: Best practices
    minerva_control_id: 6_03_elb_access_logging
    remediation_steps:  |
      1. Sign into the AWS console.
      2. Navigate to EC2 dashboard (or search for EC2 in the search bar).
      3. Click on Load Balancers on the left hand side of the screen > Click on the name of the Load Balancer that caused the alert.
      4. On the Description tab, click ‘Configure Access Logs’.
      5. On the ‘Configure Access Logs’ popup dialog, please do the following steps: 
        5.1 Select ‘Enable access logs’. 
        5.2 Choose Interval time; default is 60 minutes. 
        5.3 For S3 location, enter the name of your S3 bucket, including the prefix (for example, sap-loadbalancer-logs/my-app). You can enter the name of an existing bucket or enter a name for a new bucket. Please note: If the bucket does not exist, select ‘Create this location for me’. You must enter a name that is unique across all existing bucket names in Amazon S3 and it must also follow the DNS naming conventions. The new S3 bucket must be in the same region as the load balancer.
      6. Click ‘Save’.
    terraform_remediation:  |
      resource "aws_elb" "example_elb_access_log" {
        ...
        "access_logs" {
          bucket = <the logging bucket>
          enabled = true
        }
      }
  - name: 6_03_aws_elbv2_access_logging
    description: 6.3 - AWS Elastic Load Balancers v2 access log should be enabled
    sgs_wiki_link: https://wiki.one.int.sap/wiki/x/-0JAc
    query: AwsEc2Elbv2 with ( Listeners with Protocol = "TLS" ) and not AccessLogs
    score: 5.0
    allow_orca_score_adjustment: false
    enabled: true
    category: Best practices
    minerva_control_id: 6_03_alb_access_logging
    remediation_steps:  |
      1.  Sign into the AWS console.
      2. Navigate to EC2 dashboard (or search for EC2 in the search bar).
      3. Under LOAD BALANCING, click Load Balancers.
      4. Click the circle by the ELB mentioned in the alert.
      5. Click ‘Actions’.
      6. Click ‘Edit attributes’.
      7. In the ‘Edit load balancer attributes’ popup box, Click ‘Enable’ for ‘Access logs’ > Configure S3 location where you would to store ELB logs.
      8. Click ‘Save’.
    terraform_remediation:  |
      resource "aws_lb" "example_alb_access_log" {
        ...
        "access_logs" {
          bucket = <the logging bucket>
          enabled = true
        }
      }
  - name: 6_03_aws_elb_security_policies
    description: 6.3 - AWS Load Balancers (Classic) SSL listeners must use latest Security Policies
    sgs_wiki_link: https://wiki.wdf.sap.corp/wiki/x/-0JAc
    query: AwsEc2Elb with Listeners with SslSecurityPolicy with Name != "ELBSecurityPolicy-TLS-1-2-2017-01"
    score: 8.0
    allow_orca_score_adjustment: false
    enabled: true
    category: Best practices
    minerva_control_id: 6_03_elb_security_policies
    remediation_steps:  |
      1. Login to the AWS Management Console.
      2. Navigate to EC2 dashboard (or search for EC2 in the search bar).
      3. Under LOAD BALANCING, click Load Balancers.
      4. Click on the Elastic Load Balancer that you want to examine.
      5. Click on the Listeners tab.
      6. In the Cipher column of the HTTPS/SSL listener, click Change.
      7. In the Select a Cipher dialog box, check Predefined Security Policy checkbox and select the first policy available in the dropdown list, ELBSecurityPolicy-TLS-1-2-2017-01.
      8. Click Save.
    terraform_remediation:  |
      resource "aws_lb_listener" "example_lb_listener" {
        ...
        ssl_policy        = "ELBSecurityPolicy-TLS-1-2-2017-01"
        ...
      }
      resource "aws_elb" "example_elb" {
        ...
        listener {
          ...
          lb_port           = 443
          lb_protocol       = "https"
        }
      }
  - name: 6_03_aws_elbv2_security_policies
    description: 6.3 - AWS Application Load Balancers SSL listeners must use latest Security Policies
    sgs_wiki_link: https://wiki.wdf.sap.corp/wiki/x/-0JAc
    query: >
      AwsEc2Elbv2 with Listeners with (TlsSecurityPolicy and not TlsSecurityPolicy = ("ELBSecurityPolicy-TLS13-1-2-2021-06" or
      "ELBSecurityPolicy-TLS13-1-3-2021-06" or "ELBSecurityPolicy-TLS13-1-2-Res-2021-06" or "ELBSecurityPolicy-TLS13-1-2-Ext1-2021-06" or
      "ELBSecurityPolicy-FS-1-2-Res-2020-10" or "ELBSecurityPolicy-FS-1-2-Res-2019-08" or "ELBSecurityPolicy-TLS-1-2-2017-01")) or
      (Protocol = 'HTTP' and not (AwsEc2Elbv2Rules with AwsEc2Elbv2RuleActions with (ActionType = 'redirect' and
      RedirectConfig['Protocol'] = 'HTTPS' and not Conditions)))
    score: 8.0
    allow_orca_score_adjustment: false
    enabled: true
    category: Best practices
    minerva_control_id: 6_03_elb_security_policies
    remediation_steps:  |
      1. Login to the AWS Management Console.
      2. Navigate to EC2 dashboard (or search for EC2 in the search bar).
      3. Under LOAD BALANCING, click Load Balancers.
      4. Click on the Elastic Load Balancer that you want to examine.
      5. Click on the Listeners tab.
      6. In the Cipher column of the HTTPS/SSL listener, click Change.
      7. In the Select a Cipher dialog box, check Predefined Security Policy checkbox and select the first policy available in the dropdown list, ELBSecurityPolicy-TLS13-1-2-2021-06 or ELBSecurityPolicy-TLS13-1-3-2021-06 or ELBSecurityPolicy-TLS13-1-2-Res-2021-06 or ELBSecurityPolicy-TLS13-1-2-Ext1-2021-06 or ELBSecurityPolicy-FS-1-2-Res-2020-10 or ELBSecurityPolicy-FS-1-2-Res-2019-08 or ELBSecurityPolicy-TLS-1-2-2017-01.
      8. Click Save.
    terraform_remediation:  |
      resource "aws_lb_listener" "example_lb_listener" {
        ...
        ssl_policy        = "ELBSecurityPolicy-TLS13-1-2-2021-06 or ELBSecurityPolicy-TLS13-1-3-2021-06 or ELBSecurityPolicy-TLS13-1-2-Res-2021-06 or ELBSecurityPolicy-TLS13-1-2-Ext1-2021-06 or ELBSecurityPolicy-FS-1-2-Res-2020-10 or ELBSecurityPolicy-FS-1-2-Res-2019-08 or ELBSecurityPolicy-TLS-1-2-2017-01"
        ...
      }
      resource "aws_elb" "example_elb" {
        ...
        listener {
          ...
          lb_port           = 443
          lb_protocol       = "https"
        }
      }
  - name: 6_03_aws_rds_instance_backup
    description: 6.3 - AWS RDS instances automatic backup should be enabled
    sgs_wiki_link: https://wiki.one.int.sap/wiki/x/-0JAc
    query: AwsRdsDbInstance without BackupRetentionPeriod
    score: 5.0
    allow_orca_score_adjustment: false
    enabled: true
    category: Best practices
    minerva_control_id: 6_03_rds_instance_backup
    remediation_steps:  |
      1. Log into to the AWS Management Console.
      2. Search for RDS in the search bar.
      3. Select DB Instances > Navigate to the DB identifier mentioned in the alert.
      4. Select Maintenance & backups tab.
      5. Go to Backup section.
      6. Check Automated backups setting to see if it is Disabled. Note: Before applying the below step please ensure that the team responsible for the database in question is aware of this activity for any impact/outage.
      7. In order to enable automated backups setting please follow the step by step AWS RDS user guide: https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_WorkingWithAutomatedBackups.html#USER_WorkingWithAutomatedBackups.Enabling
    terraform_remediation:  |
      resource "aws_db_instance" "example_rds_instance" {
        ...
        backup_retention_period = <number of days to backup>
      }
  - name: 6_04_aws_vpn_secure_configuration
    description: 6.4 - AWS VPN IKEv1 protocol is outdated and must not be used
    sgs_wiki_link: https://wiki.one.int.sap/wiki/x/-0JAc
    query: AwsEc2VpnConnection with State = "available" and VpnTunnels with IkeVersions containing "ikev1"
    score: 8.0
    allow_orca_score_adjustment: false
    enabled: true
    category: Best practices
    minerva_control_id: 6_04_aws_secure_vpn_setup
    remediation_steps:  |
      1. Sign into the AWS console.
      2. Navigate to VPN connection dashboard.
      3. Remove IKEv1 from the advanced tunnel information
    terraform_remediation:  |
      resource "aws_vpn_connection" "example_vpn_configuration" {
        ...
        tunnel1_ike_versions = ["ikev2"] ## This array should not contain IKEv1 since it is outdated
        tunnel2_ike_versions = ["ikev2"] ## This array should not contain IKEv1 since it is outdated
      }
  - name: 6_05_aws_transit_gateway_autoacceptsharedattachments
    description: 6.5 - AWS Transit Gateways "AutoAcceptSharedAttachments" must be turned off, to ensure that only authorized VPC attachment requests are accepted (not automatically accept VPC attachment requests).
    sgs_wiki_link: https://wiki.one.int.sap/wiki/x/-0JAc
    query: AwsTransitGateway with IsSharedAttachmentsAutoAccepted
    score: 8.0
    allow_orca_score_adjustment: false
    enabled: true
    category: Best practices
    minerva_control_id: null
  # Chapter 7
  - name: 7_04_aws_eks_cluster_default_vpc
    description: 7.4 - AWS EKS clusters should not use the default VPC
    sgs_wiki_link: https://wiki.wdf.sap.corp/wiki/x/-0JAc
    query: AwsEksCluster with Vpc.IsDefault
    score: 5.0
    allow_orca_score_adjustment: false
    enabled: true
    category: Best practices
    minerva_control_id: 7_04_eks_cluster_using_default_vpc
    remediation_steps:  |
      Once an AWS EKS cluster VPC is created, it can’t be modified. In order to remediate this alert, please create a new cluster with a custom VPC, then move all of the required cluster data from the cluster mentioned in the alert to the new cluster and then delete the original Kubernetes cluster.
        1. Open the Amazon EKS dashboard (or search for EKS in the search bar).
        2. Click Add cluster > Click Create cluster.
        3. On the Create cluster page, complete the following fields:
          3.1 Cluster name
          3.2 Kubernetes version
          3.3 Role name
          3.4 VPC - Choose your new custom VPC.
          3.5 Subnets
          3.6 Security Groups
          3.7 Endpoint private access
          3.8 Endpoint public access
          3.9 Logging
        4. Click Create.
    terraform_remediation:  |
      resource "aws_eks_cluster" "example_cluster" {
        ...
        vpc_config {
          subnet_ids = <list of subnet IDs in non-default vpc>
          ...
        }
      }
  - name: 7_04_aws_eks_cluster_security_group_traffic_permissions
    description: 7.4 - AWS EKS cluster security groups must not be overly permissive to all traffic
    sgs_wiki_link: https://wiki.wdf.sap.corp/wiki/x/-0JAc
    query: AwsEksCluster with SecurityGroups with SgIpPermissions with not Egress and IpRanges containing ( '0.0.0.0/0' or '::/0' )
    score: 8.0
    allow_orca_score_adjustment: false
    enabled: true
    category: Best practices
    minerva_control_id: 7_04_eks_cluster_security_group_traffic_permissions
    remediation_steps:  |
      1. Log in to the AWS console.
      2. Navigate to the VPC service (or search for VPC in the search bar).
      3. Click on Security Groups > Click on the name of the security group mentioned in the alert > Click on Inbound Rules > Remove the rule which mentions the source value as 0.0.0.0/0 or ::/0.
    terraform_remediation:  |
      resource "aws_security_group" "example_eks_security_group" {
        name        = <your security group name>
        description = <your security group description>
        vpc_id = <id of your vpc>
      }
      resource "aws_security_group_rule" "eks_security_group_rule" {
        type      = "ingress"
        from_port = <starting port for a range, or a single port>
        to_port   = <ending port for a range, or a single port>
        protocol  = <relevant protocol>
        cidr_blocks = <list of allowed ipv4 IP CIDRs>
        ipv6_cidr_blocks = <list of allowed ipv6 IP CIDRs>
        security_group_id = aws_security_group.example_eks_security_group.id
      }
      resource "aws_eks_cluster" "example_cluster" {
        ...
        vpc_config {
          ...
          security_group_ids = [aws_security_group.eks_security_group.id]   
          ...
        }
      }
  - name: 7_12_aws_eks_cluster_private_node
    description: 7.12 - AWS EKS cluster endpoint public access should be disabled
    sgs_wiki_link: https://wiki.wdf.sap.corp/wiki/x/-0JAc
    query: AwsEksCluster with EndpointPrivateAccess = false or EndpointPublicAccess = true
    score: 5.0
    allow_orca_score_adjustment: false
    enabled: true
    category: Best practices
    minerva_control_id: 7_12_eks_cluster_api_publicly_accessible
    remediation_steps:  |
      1. Login to AWS Console.
      2. Navigate to the Amazon EKS dashboard.
      3. Choose the name of the cluster to display your cluster information.
      4. Click on the Configuration tab > Click on the Networking tab.
      5. Under Networking, click Manage networking.
      6. Select Private.
      7. Click Save Changes.
    terraform_remediation:  |
      resource "aws_eks_cluster" "example_cluster" {
        ...
        vpc_config {
          ...
          endpoint_private_access = true
          endpoint_public_access = false
        }
      }
  # Chapter 8
  - name: 8_01_aws_redis_cluster_encryption_in_transit
    description: 8.1 - AWS ElastiCache Redis cluster must have in-transit encryption enabled
    sgs_wiki_link: https://wiki.wdf.sap.corp/wiki/x/-0JAc
    query: AwsElasticacheRedisCluster without TransitEncryptionEnabled
    score: 8.0
    allow_orca_score_adjustment: false
    enabled: true
    category: Best practices
    minerva_control_id: 8_01_elasticache_cluster_in_transit_encryption
    remediation_steps:  |
      AWS ElastiCache Redis cluster in-transit encryption can be set when creating the cluster. In order to resolve the alert for this control, you will need to create a new cluster with in-transit encryption enabled, then migrate all required ElastiCache Redis cluster data from the ElastiCache Redis cluster that caused the alert to the new cluster and delete old ElastiCache Redis cluster.
      To create new ElastiCache Redis cluster with In-transit encryption set, please do the following:
        1. Sign into the AWS console > Select the specific region from region drop down on the top right corner, that caused the alert.
        2. Go to the ElastiCache Dashboard (or search for ElastiCache Dashboard in the search bar).
        3. In the left-hand menu, Click on Redis > Click on Create button.
        4. Select or enter the following information:
          4.1 Select ‘Redis’ cache engine type. b. Enter a name for the new cache cluster. c. Select Redis engine version from Engine version compatibility dropdown list. d. Click on Advanced Redis settings to expand the cluster advanced settings panel. e. Select Encryption in-transit checkbox to enable encryption along with other necessary options
        5. Click on Create button to start your ElastiCache Redis cluster.
      To delete reported ElastiCache Redis cluster, please do the following:
        1. Sign into the AWS console > Select the specific region from region drop down on the top right corner, that caused the alert.
        2. Go to the ElastiCache Dashboard (or search for ElastiCache Dashboard in the search bar).
        3. In the left-hand menu, Click on Redis.
        4. Select original Redis cluster.
        5. Click on Delete button.
        6. In the Delete Cluster dialog box, if you’d like to backup for your cluster, select Yes from the Create final backup dropdown menu, enter a name for the cluster backup > click on Delete.
    terraform_remediation:  |
      resource "aws_elasticache_replication_group" "example_rg" {
        ...
        transit_encryption_enabled    = true
        ...
      }
  - name: 8_01_aws_redis_cluster_encryption_at_rest
    description: 8.1 - AWS ElastiCache Redis cluster should have encryption for data at rest enabled
    sgs_wiki_link: https://wiki.wdf.sap.corp/wiki/x/-0JAc
    query: AwsElasticacheRedisCluster without AtRestEncryptionEnabled
    score: 5.0
    allow_orca_score_adjustment: false
    enabled: true
    category: Best practices
    minerva_control_id: 8_01_elasticache_cluster_at_rest_encryption
    remediation_steps:  |
      AWS ElastiCache Redis cluster at-rest encryption can be set only at the time of the creation of the cluster. In order to resolve the alert for this control, you will need to create a new cluster with at-rest encryption, then migrate all required ElastiCache Redis cluster data from the reported ElastiCache Redis cluster that caused the alert to the new cluster and delete old ElastiCache Redis cluster.
      To create new ElastiCache Redis cluster with In-transit encryption set, please do the following:
        1. Sign into the AWS console > Select the specific region from region drop down on the top right corner, that caused the alert.
        2. Go to the ElastiCache Dashboard (or search for ElastiCache Dashboard in the search bar).
        3. In the left-hand menu, Click on Redis > Click on Create button.
        4. Select or enter the following information:
          4.1 Select ‘Redis’ cache engine type. b. Enter a name for the new cache cluster. c. Select Redis engine version from Engine version compatibility dropdown list. d. Click on Advanced Redis settings to expand the cluster advanced settings panel. e. Select Encryption at-rest checkbox to enable encryption along with other necessary options.
        5. Click on Create button to start your ElastiCache Redis cluster.
      To delete reported ElastiCache Redis cluster, please do the following:
        1. Sign into the AWS console > Select the specific region from region drop down on the top right corner, that caused the alert.
        2. Go to the ElastiCache Dashboard (or search for ElastiCache Dashboard in the search bar).
        3. In the left-hand menu, click on Redis.
        4. Select the Redis cluster that caused the alert.
        5. Click on Delete button.
        6. In the Delete Cluster dialog box, if you’d like to backup for your cluster, select Yes from the Create final backup dropdown menu, enter a name for the cluster backup > click on Delete.
    terraform_remediation:  |
      resource "aws_elasticache_replication_group" "example_rg" {
        ...
        at_rest_encryption_enabled    = true
        ...
      }
  - name: 8_01_aws_elasticache_redis_support_patches
    description: 8.1 - AWS Elasticache Redis cluster software must be still supported with security patches (no active use of End of Life versions)
    sgs_wiki_link: https://wiki.wdf.sap.corp/wiki/x/-0JAc
    query: AwsElasticacheRedisCluster without EngineVersion like ( "6." or "7." )
    score: 8.0
    allow_orca_score_adjustment: false
    enabled: true
    category: Best practices
    minerva_control_id: null
    remediation_steps:  |
      1. Log into the AWS console.
      2. Navigate to the Elasticache service.
      3. Select the Redis cluster.
      4. Check the version of the Redis cluster software currently in use.
      5. If the version is End of Life, upgrade to a supported version.
      6. If the version is already supported, ensure that the cluster is configured to receive security patches automatically.
    terraform_remediation:  |
      Use the following Terraform code to upgrade the AWS Elasticache Redis cluster to a supported version (e.g., Redis 6.x, 7.x):
        resource "aws_elasticache_cluster" "example" {
        cluster_id           = "cluster-example"
        engine               = "redis"
        node_type            = "cache.m4.large"
        num_cache_nodes      = 1
        parameter_group_name = "default.redis7.x"
        engine_version       = "7.x"  # Change to "6.x" or "7.x" as needed
        port                 = 6379
        }
  - name: 8_01_aws_elasticache_memcached_support_patches
    description: 8.1 - AWS Elasticache Memcached cluster software must be still supported with security patches (no active use of End of Life versions)
    sgs_wiki_link: https://wiki.wdf.sap.corp/wiki/x/-0JAc
    query: AwsElasticacheMemcachedCluster without EngineVersion like "1.6."
    score: 8.0
    allow_orca_score_adjustment: false
    enabled: true
    category: Best practices
    minerva_control_id: null
    remediation_steps:  |
      1. Log in to the AWS console.
      2. Navigate to the Elasticache service.
      3. Select the Memcached cluster.
      4. Check the version of the Memcached cluster software.
      5. If the version is End of Life, upgrade to a supported version.
      6. Verify that the Memcached cluster software is now supported with security patches.
    terraform_remediation:  |
      Use the following Terraform code to upgrade the AWS Elasticache Memcached cluster to a supported version (e.g., Memcached 1.6.x):
        resource "aws_elasticache_cluster" "example" {
        cluster_id           = "example-memcached-cluster"
        engine               = "memcached"
        engine_version       = "1.6.x"
        node_type            = "cache.t2.micro"
        num_cache_nodes      = 1
        parameter_group_name = "default.memcached1.6.x"
        port                 = 11211
        subnet_group_name    = aws_elasticache_subnet_group.example.name
        vpc_security_group_ids = [aws_security_group.example.id,]
        }
  - name: 8_02_aws_elasticsearch_clusters_without_vpc_or_private_network
    description: 8.2 - AWS search clusters should be configured to ensure that the traffic between other (hyperscaler) services and the search cluster stays entirely within the hyperscaler internal (private) network, isolated from the public Internet
    sgs_wiki_link: https://wiki.wdf.sap.corp/wiki/x/-0JAc
    query: >
      [[AwsElasticSearch without (VPC and AccessPolicy)] or
      [AwsElasticSearch with AccessPolicy.PolicyStatements with (Effect = "Allow" and Condition['IpAddress']['aws:SourceIp'] containing ('0.0.0.0' or '0.0.0.0/0' or '::/0'))]]
    score: 5.0
    allow_orca_score_adjustment: false
    enabled: true
    category: Best practices
    minerva_control_id: 
      - 8_02_domain_in_vpc_or_access_based_on_ip_allow_list
      - 8_02_domain_in_vpc
    remediation_steps:  |
      Please follow these steps to remediate alert for control 8_02_domain_in_vpc_or_access_based_on_ip_allow_list:
        1. Log into AWS console.
        2. Go to the IAM Services (or search for IAM in the search bar).
        3. Click on Policies in the left-hand panel.
        4. Search for the policy which caused the alert to be generated > Click on the name of the policy.
        5. Under the Permissions tab, click on Edit policy.
        6. Under the Visual editor, for each of the Elasticsearch Service, click little arrow/triangle to expand and please do the following:
          6.1 Click to expand Request conditions.
          6.2 Under the Source IP, remove the row with the entry ‘0.0.0.0/0’ or ‘::/0’ > Add condition with restrictive IP ranges.
        7. Click on Review policy > Save changes.
      Please follow these steps to remediate alert for control 8_02_domain_in_vpc: 
        1. Sign into the AWS console.
        2. Navigate to Elasticsearch Service Dashboard (or search OpenSearch (aka Elasticsearch) in the search bar) > Click on Dashboard > Click on Create domain.
        3. On the ‘Define domain’ page, enter the Elasticsearch domain name, Elasticsearch version > Click Next.
        4. On the ‘Configure cluster’ page, enter the new domain options (which would be the same as the domain configuration that mentioned in the alert).
        5. On the ‘Set up access’ page, please do the following steps:
          5.1 Under ‘Network configuration’ section, select ‘VPC access (Recommended)’.
          5.2 Click on the desired VPC, Subnet and Security Group from the drop-down list > Click on ‘Next’.
        6. On the ‘Review’ page, double check and review the domain configuration details.
        7. Click ‘Confirm’.
        8. Once the new AWS ES domain is created, upload the data from the original domain to the new ES domain.
      To delete ES domain mentioned in the alert, please perform the following steps:
        1. Sign into the AWS console.
        2. Navigate to Elasticsearch Service Dashboard (or search OpenSearch (aka Elasticsearch) in the search bar).
        3. Choose Elasticsearch domain mentioned in the alert > Click ‘Delete Domain’.
        4. On ‘Delete Domain’ dialog popup, check the ‘Delete the domain’ > Click ‘Delete’.
    terraform_remediation:  |
      resource "aws_elasticsearch_domain" "example_domain_in_vpc" {
        ...
        vpc_options {
          subnet_ids = <array of subnets>
          security_group_ids = <array of applied security groups>
        }
      }
  - name: 8_02_aws_elasticsearch_domain_public_accessibility
    description: 8.2 - AWS Elasticsearch domain should not be publicly accessible
    sgs_wiki_link: https://wiki.wdf.sap.corp/wiki/x/-0JAc
    query: AwsElasticSearch with AccessPolicy.PolicyStatements with Effect = 'Allow' and Principal['AWS'] containing '*'
    score: 5.0
    allow_orca_score_adjustment: false
    enabled: true
    category: Best practices
    minerva_control_id: 8_02_domain_publicly_available
    remediation_steps:  |
      1. Login into the AWS Management Console.
      2. Navigate to Elasticsearch (OpenSearch) dashboard, which is now known as Amazon OpenSearch Service (successor to Amazon Elasticsearch) (or search for OpenSearch in the search bar).
      3. Click on the ES domain that caused the alert.
      4. On the reported domain description page > click the Modify access policy button from the dashboard top menu.
      5. On the Modify the access policy page for the domain in question > select one of the policy templates from the Set the domain access policy to dropdown list:
        5.1 Select Allow or deny access to one or multiple AWS accounts/IAM users and then provide the relevant AWS account ID/ARN or IAM user ARN to limit the access to a particular AWS account/IAM user.
        5.2 Select Allow access to the domain from specific IP(s) and enter an IP address (or multiple IP addresses, separated by commas) to limit the access to that particular IP address or multiple IP addresses.
        5.3 Select Copy an access policy from another domain and choose/enter another ES domain name to copy its access policy.
        5.4 Select Deny access to the domain to block all access to the selected ES domain.
      6. Click Submit.
      7. In the Change your access policy dialog box > click OK (The domain status should change from Active to Processing; it should then return to Active before your changed access policy takes effect).
    terraform_remediation:  |
      resource "aws_elasticsearch_domain_policy" "example_domain_policy" {
        domain_name = <your elasticsearch domain>

        access_policies = <<POLICIES
        {
          "Version": "2012-10-17",
          "Statement": [
            {
              "Effect": "Allow",
              "Principal": {
                "AWS": [
                  "<arn of a policy principal user>",
                  "<arn of another policy principal user>"
                ]
              },
              "Action": [
                "es:*"
              ],
              "Resource": "<arn of your elasticsearch domain>/*"
            }
          ]
      }
      POLICIES
      }
  - name: 8_02_aws_elasticsearch_encryption_at_rest
    description: 8.2 - AWS Elasticsearch clusters must have encryption for data at rest enabled
    sgs_wiki_link: https://wiki.wdf.sap.corp/wiki/x/-0JAc
    query: AwsElasticSearch without EncryptionAtRestEnabled
    score: 8.0
    allow_orca_score_adjustment: false
    enabled: true
    category: Best practices
    minerva_control_id: 8_02_domain_encrypted_at_rest
    remediation_steps:  |
      1. Login into the AWS Management Console.
      2. Navigate to Elasticsearch (OpenSearch) dashboard, which is now known as Amazon OpenSearch Service (successor to Amazon Elasticsearch) (or search for OpenSearch in the search bar).
      3. Click on the ES domain that caused the alert.
      4. On the domain configuration page, perform the following actions:
        4.1 Click on the Overview tab > Copy the domain configuration information (information like Instance count, Instance type, Dedicated master instance type, Dedicated master instance count, Storage Type, EBS volume type, EBS volume size, etc.).
        4.2 Click on the VPC tab > Copy the network configuration information (information like VPC ID, Security groups ID(s), IAM role name and AZs and Subnets IDs, etc.).
        4.3 Click on Modify access policy button from the dashboard top menu > Copy the entire policy document available in the Add or edit the access policy textbox.
      5. Go back to the AWS ElasticSearch (OpenSearch) service dashboard > Click Create new domain.
      6. On the Define domain page, please do the following steps:
        6.1 Enter a unique name for the new domain in the Elasticsearch domain name box.
        6.2 Choose the right version of the Elasticsearch engine from the Elasticsearch version dropdown list > Click Next.
      7. On the Configure cluster page, please do the following steps:
        7.1 Input/paste the new domain options using the configuration details copied at step #4.1
        7.2 Select Enable encryption at rest checkbox to enable data-at-rest encryption. In the KMS master key dropdown list > Choose your AWS KMS Key OR Select Enter a key ARN from the dropdown list and paste a new CMK ARN into the ARN / ID box > Click Next.
      8. On the Set up access page, configure the network access to the new domain by using the same factors copied at step #4b; paste the access policy copied at step #4c into the Add or edit the access policy textbox > Click Next.
      9. On the Review page, verify the domain configuration details > Click Confirm.
      10. Once the new AWS ES domain is created, upload the data from the original domain to the new ES cluster.
      11. You can now safely remove the original unencrypted ElasticSearch domain. To delete the unencrypted domain, please do the following steps:
        11.1 Click on the name of the domain that you want to remove.
        11.2 Click Delete domain.
        11.3 Within Delete domain dialog box, check Delete the domain > Click Delete.
    terraform_remediation:  |
      resource "aws_elasticsearch_domain" "example_encrypted_domain" {
        ...
        encrypt_at_rest {
         enabled = true
       }
      }
  - name: 8_02_aws_elasticsearch_support_patches
    description: 8.2 - AWS underlying cluster software (e.g. elasticsearch) should always be updated to the latest stable release
    sgs_wiki_link: https://wiki.wdf.sap.corp/wiki/x/-0JAc
    query: >
      [ [AwsElasticSearch with str_to_version(ElasticsearchVersion) < str_to_version('8')] or
      [AwsElasticSearch with ElasticsearchVersion ilike 'OpenSearch_1.' and ElasticsearchVersion != 'OpenSearch_1.3'] ]
    score: 5.0
    allow_orca_score_adjustment: false
    enabled: true
    category: Best practices
    minerva_control_id: null
  - name: 8_03_aws_rds_instance_cluster_default_vpc
    description: 8.3 - AWS RDS instances or clusters should not use the default VPC
    sgs_wiki_link: https://wiki.wdf.sap.corp/wiki/x/-0JAc
    query: >
      [ [ AwsRdsDbInstance with Vpc.IsDefault ] or [ AwsRdsDbCluster with VpcSecurityGroups with Name = "default" ] ]
    score: 5.0
    allow_orca_score_adjustment: false
    enabled: true
    category: Best practices
    minerva_control_id: null
  - name: 8_03_aws_rds_instance_public_subnet
    description: 8.3 - AWS RDS instances should not be deployed in a public subnet. Production databases should be located behind a DMZ in a private subnet with limited access.
    sgs_wiki_link: https://wiki.wdf.sap.corp/wiki/x/-0JAc
    query: AwsRdsDbInstance with PubliclyAccessible and VpcSecurityGroups with SgIpPermissions with (Ipv6Ranges containing '::/0' or IpRanges containing '0.0.0.0/0')
    score: 5.0
    allow_orca_score_adjustment: false
    enabled: true
    category: Best practices
    minerva_control_id: 8_03_rds_instance_in_public_subnet
    remediation_steps:  |
      In order to remediate this alert, you will need to redeploy RDS into a private RDS Subnet group.
      Please note: You can’t move an existing RDS instance from one subnet to another.
      To create a RDS Subnet group, please do the following steps:
        (A DB subnet group is a collection of subnets that you create for a VPC and then utilize for your DB instances.)
        1. Open the Amazon RDS console (or search for RDS in the search bar.
        2. In the navigation pane, choose Subnet groups.
        3. Click Create DB Subnet Group > Enter the Name of your DB subnet group.
        4. Enter a Description for your DB subnet group > Select your VPC > Select Availability Zones.
        5. In the Add subnets section, add your Private subnets related to the above VPC.
        6. Click Create.
      When creating your RDS DB, under Configure advanced settings, choose the Subnet group created above.
    terraform_remediation:  |
      resource "aws_db_instance" "example_rds_instance" {
        ...
        db_subnet_group_name = <name of subnet group>
      }
  - name: 8_03_aws_rds_instance_public_accessibility
    description: 8.3 - AWS RDS instances must not be publicly accessible
    sgs_wiki_link: https://wiki.wdf.sap.corp/wiki/x/-0JAc
    query: AwsRdsDbInstance with PubliclyAccessible
    score: 8.0
    allow_orca_score_adjustment: false
    enabled: true
    category: Best practices
    minerva_control_id: 8_03_rds_instance_publicly_accessible
    remediation_steps:  |
      1. Log into to the AWS Management Console.
      2. Search for RDS in the search bar.
      3. Click on Databases > Click on the DB identifier mentioned in the alert.
      4. Click Modify > Scroll down to Connectivity > Click on Additional configuration > Click Not publicly accessible.
      5. Click Continue > Click Modify DB Instance.
      6. Verify Changes and Save.
    terraform_remediation:  |
      resource "aws_db_instance" "example_rds_instance" {
        ...
        publicly_accessible  = false
      }
  - name: 8_03_aws_rds_instance_encryption
    description: 8.3 - AWS RDS instances must be encrypted
    sgs_wiki_link: https://wiki.wdf.sap.corp/wiki/x/-0JAc
    query: AwsRdsDbInstance with not Engine = "sqlserver-ex" and not StorageEncrypted  and not Tags [ "sec-by-def-rds-encryption-exception" ] = "enabled"
    score: 8.0
    allow_orca_score_adjustment: false
    enabled: true
    category: Best practices
    minerva_control_id: 8_03_rds
    remediation_steps:  |
      You can only enable encryption for an Amazon RDS DB instance when you create it, not after the DB instance is created.
        1. Log into to the AWS Management Console.
        2. Search for RDS in the search bar.
        3. Click on Databases > Click on the DB identifier mentioned in the alert > Click on the Configuration tab.
        4. Check the value for Encryption key under Storage section (i.e. Not enabled).
        5. Create a new DB instance with encryption enabled.
        6. Migrate all required data from existing non encrypted DB instance to new encrypted DB instance.
      To create RDS DB instance with encryption follow the AWS guide below, https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/Overview.Encryption.html
    terraform_remediation:  |
      resource "aws_db_instance" "example_rds_instance" {
        ...
        storage_encrypted    = true
      }
  - name: 8_03_aws_rds_cluster_storage_encryption
    description: 8.3 - AWS RDS cluster underlying data storage must be encrypted
    sgs_wiki_link: https://wiki.wdf.sap.corp/wiki/x/-0JAc
    query: AwsRdsDbCluster without StorageEncrypted
    score: 8.0
    allow_orca_score_adjustment: false
    enabled: true
    category: Best practices
    minerva_control_id: 8_03_enable_cluster_encryption
    remediation_steps:  |
      AWS DB clusters can only be encrypted when creating the database cluster. You can’t convert an unencrypted DB cluster into an encrypted one. You can restore an unencrypted Aurora DB cluster snapshot to a new encrypted Aurora DB cluster. To do that, you’ll need to specify a KMS encryption key when you restore from the unencrypted DB cluster snapshot.
        For AWS RDS:
          1. To create a ‘Snapshot’ of the unencrypted DB cluster, please follow the instructions listed in this link: https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/USER_CreateSnapshotCluster.html
              Please note that you can’t restore from a DB cluster snapshot to an existing DB cluster; instead a new DB cluster is created when you restore. Once the Snapshot status is showing as Available, delete the unencrypted DB cluster before restoring from the DB cluster Snapshot by performing the following steps:    
            1.1 Sign to the AWS Management Console > open the Amazon RDS console (or search for RDS in the search bar).
            1.2 In the left side navigation pane, click on Databases.
            1.3 In the list of DB instances, click on the bubble by the DB identifier you’d like to delete > Click Actions > Click Delete.
          2. To restoring the Cluster from a DB Cluster Snapshot, please follow the instructions listed in this link: https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/USER_RestoreFromSnapshot.html
        For AWS Document DB:
          1. To create a ‘Snapshot’ of the unencrypted DB cluster, follow the instructions listed in this link: https://docs.aws.amazon.com/documentdb/latest/developerguide/backup_restore-create_manual_cluster_snapshot.html
              Please note that you can’t restore from a DB cluster snapshot to an existing DB cluster; instead a new DB cluster is created when you restore. Once the Snapshot status is showing as Available, delete the unencrypted DB cluster before restoring from the DB cluster Snapshot by following below steps for AWS Document DB,
            1.1 Sign to the AWS Management Console > open the Amazon DocumentDB console (or search for DocumentDB in the search bar).
            1.2 In the navigation pane, Click Clusters.
            1.3 Click the checkbox of the cluster identifier that you’d like to delete > Click Actions > Click Delete.
          2. To restore the Cluster from a DB Cluster Snapshot, follow the instructions listed in this link: https://docs.aws.amazon.com/documentdb/latest/developerguide/backup_restore-restore_from_snapshot.html
    terraform_remediation:  |
      resource "aws_rds_cluster" "example_rds_cluster" {
        ...
        storage_encrypted       = true
      }
  - name: 8_03_aws_rds_snapshot_encryption
    description: 8.3 - AWS RDS snapshots must be encrypted
    sgs_wiki_link: https://wiki.wdf.sap.corp/wiki/x/-0JAc
    query: AwsRdsDbInstanceSnapshot with StorageEncrypted != true and Status like "available" and not Engine = "sqlserver-ex"
    score: 8.0
    allow_orca_score_adjustment: false
    enabled: true
    category: Best practices
    minerva_control_id: 8_03_rds_db_snapshot_encryption
    remediation_steps:  |
      1. Log into to the AWS Management Console.
      2. Search for RDS in the search bar.
      3. Go to Snapshots > Navigate to the DB snapshot mentioned in the alert listed under the Manual tab or the System tab.
      4. Click on the checkbox by the snapshot that caused the alert > Click Actions > Select copy snapshot > Fill the required fields.
      5. Ensure Encryption Enabled checkbox is ticked > Copy snapshot.
      6. The new (copied) snapshot is available under the Manual tab.
        Note: For system generated snapshots enable encryption at database, please refer to the following link: https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/Overview.Encryption.html
      7. Delete the non-compliant snapshots once the new encrypted snapshots are created and verified.
    terraform_remediation:  |
      resource "aws_db_instance" "example_rds_instance" {
        ...
        storage_encrypted       = true
      }
  - name: 8_03_aws_dms_public_accessibility
    description: 8.3 - AWS DMS replication instances must not be publicly accessible
    sgs_wiki_link: https://wiki.wdf.sap.corp/wiki/x/-0JAc
    query: AwsDmsReplicationInstance with PubliclyAccessible
    score: 8.0
    allow_orca_score_adjustment: false
    enabled: true
    category: Best practices
    minerva_control_id: null
  - name: 8_04_aws_route53_public_zone_private_records
    description: 8.4 - AWS Route53 must not have any private records configured in a public zone
    sgs_wiki_link: https://wiki.wdf.sap.corp/wiki/x/-0JAc
    query: >
      AwsRoute53HostedZone with not PrivateZone and (ResourceRecordSets with
      any_version_in_range(ResourceRecordValues, '10.0.0.0', '10.255.255.255') or
      any_version_in_range(ResourceRecordValues, '172.16.0.0', '172.31.255.255') or
      any_version_in_range(ResourceRecordValues, '192.168.0.0', '192.168.255.255'))
    score: 8.0
    allow_orca_score_adjustment: false
    enabled: true
    category: Best practices
    minerva_control_id: 8_04_public_zone_private_records
    remediation_steps:  |
      1. Log in to the AWS console.
      2. Go to Route 53 (or search for Route 53 in the search bar).
      3. Click Hosted zones > Click Create Hosted Zone. While creating the new private hosted zone, do the following:
        3.1 Enter the domain name that is misconfigured as public.
        3.2 Choose 'Private hosted zone' under 'Type'.
      4. In the newly created private zone, click 'Create record'. While creating the new record, do the following:
        4.1 Input the private records from the misconfigured public zone.
      5. In the original misconfigured public zone, delete the private records whose Type is other than NS or SOA, that have been created in the private zone. 
    terraform_remediation:  |
      1. To create a new private hosted zone with private records, use the following Terraform code:
            resource "aws_route53_zone" "example_private_zone" {
              name = "example.com"
              ...
            }
            resource "aws_route53_record" "example_private_record" {
              zone_id = <zone_id of example_private_zone>
              records = [<Private records from the misconfigured public zone>]
              ...
            }
      2. To remove the private records from the public hosted zone, use the following Terraform code:
            resource "aws_route53_record" "example_record" {
              zone_id = <zone_id of misconfigured_public_zone>
              records = [<Remove private records, or remove entire resource if not required>]
              ...
            }
  - name: 8_05_aws_cloudfront_tls_protocol
    description: 8.5 - AWS CloudFront Distribution must not use insecure SSL or TLS protocols for HTTPS communication
    sgs_wiki_link: https://wiki.wdf.sap.corp/wiki/x/-0JAc
    query: AwsCloudFront with OriginSslProtocols containing ("SSLv3" or "TLSv1" or "TLSv1.1")
    score: 8.0
    allow_orca_score_adjustment: false
    enabled: true
    category: Best practices
    minerva_control_id: 8_05_cloudfront_ssl_protocol
    remediation_steps:  |
      1. Go to the AWS console. 
      2. Go to CloudFront dashboard (or search for CloudFront in the search bar).
      3. Click on your distribution ID.
      4. Select the Origins tab.
      5. Click the origin you want to modify > Click Edit.
      6. Under Origin SSL Protocols, uncheck SSLv3 or TLSv1 or TLSv1.1.
      7. Select Yes > Edit.
    terraform_remediation:  |
      resource "aws_cloudfront_distribution" "example_distribution" {
        origin {
          ...
          custom_origin_config {
            ...
            origin_ssl_protocols = ["TLSv1.2"]
          }
        }
      }
  - name: 8_05_aws_cloudfront_access_logs
    description: 8.5 - AWS Cloudfront Distribution should have logging enabled
    sgs_wiki_link: https://wiki.wdf.sap.corp/wiki/x/-0JAc
    query: AwsCloudFront without LoggingBucket
    score: 5.0
    allow_orca_score_adjustment: false
    enabled: true
    category: Best practices
    minerva_control_id: 8_05_cloudfront_access_log_enabled
    remediation_steps:  |
      1. Go to the AWS console.
      2. Go to the CloudFront dashboard (or search for CloudFront in the search bar).
      3. Click your distribution ID.
      4. On the General tab, click Edit.
      5. On ‘Edit Distribution’ page, change Logging to On > Select a Bucket for Logs and Log Prefix.
      6. Click Yes > Edit.
    terraform_remediation:  |
      resource "aws_cloudfront_distribution" "example_cloudfront_distribution" {
        ...
        logging_config {
          bucket          = <logging bucket>
        }
      }
  - name: 8_05_aws_cloudfront_s3_origin_access
    description: 8.5 - AWS Cloudfront Distribution with S3 should not have origin access set to disabled
    sgs_wiki_link: https://wiki.wdf.sap.corp/wiki/x/-0JAc
    query: >
      [AwsCloudFront with CloudAccount.AwsS3Bucket] without OriginAccessIdentities
    score: 5.0
    allow_orca_score_adjustment: false
    enabled: true
    category: Best practices
    minerva_control_id: 8_05_cloudfront_s3_origin_access
    remediation_steps:  |
      1. Sign in to the AWS Management Console.
      2. Go to CloudFront (or search for CloudFront in the search bar).
      3. Click the reported Distribution.
      4. Click on ‘Origins’ tab.
      5. Select the S3 bucket and click on ‘Edit’.
      6. Under the ‘S3 bucket access’, select ‘Yes use OAI (bucket can restrict access to only CloudFront)’ > Choose the origin access identity > Select ‘Yes, update the bucket policy’.
      7. Click ‘Save changes’.
    terraform_remediation:  |
      resource "aws_cloudfront_origin_access_identity" "example" {}
      resource "aws_cloudfront_distribution" "example_distribution" {
        ...
        origin {
          ..
          s3_origin_config {
          origin_access_identity = aws_cloudfront_origin_access_identity.example.cloudfront_access_identity_path
        }
      }
  - name: 8_05_aws_cloudfront_viewer_protocol_policy
    description: 8.5 - AWS CloudFront Distribution viewer protocol policy should be in place and activated to enforce HTTPS-only communication
    sgs_wiki_link: https://wiki.wdf.sap.corp/wiki/x/-0JAc
    query: AwsCloudFront with PublicCacheBehaviors
    score: 5.0
    allow_orca_score_adjustment: false
    enabled: true
    category: Best practices
    minerva_control_id: 8_05_cloudfront_viewer_protocol_policy
    remediation_steps:  |
      1.  Go to the AWS console.
      2. Go to CloudFront dashboard (or search for CloudFront in the search bar).
      3. Click your distribution ID.
      4. Click on the Behaviors tab.
      5. Click on the behavior you want to modify > Click Edit.
      6. Under Viewer Protocol Policy, Choose HTTPS Only or Redirect HTTP to HTTPS.
      7. Select Yes > Edit.
    terraform_remediation:  |
      resource "aws_cloudfront_distribution" "example_distribution" {
        ...
        default_cache_behavior {
          ...
          viewer_protocol_policy = "https-only"
        }
      }
global_labels:
  - sap_aws
  - sap